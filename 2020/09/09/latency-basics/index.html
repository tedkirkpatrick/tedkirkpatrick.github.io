<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="description" content="Blog for A. E. Kirkpatrick and  Kirkpatrick Computing Services">
  <meta name="author" content="Arthur E. Kirkpatrick">
  <meta name="copyright" content="Arthur E. Kirkpatrick, 2018, 2019, 2020">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      The basics of latency percentiles &middot; All my marbles in one place
    
  </title>

    <!-- Asychronously-loaded JavaScript -->
    
    <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.0.0/es5/tex-chtml.js" integrity="sha384-j9ODZKtRF0+heKS/yKvP7oInOBmXb6YTVeyZsxRqp1u9DTFlO0RE5m34WHkrzPCN" crossorigin="anonymous"></script>
    

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66576928-4', 'auto');
  ga('send', 'pageview');
  </script>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Begin Jekyll SEO tag v2.2.3 -->
<meta property="og:title" content="The basics of latency percentiles" />
<meta name="author" content="Ted Kirkpatrick" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Designers of distributed systems obsess over service latency. They forecast latencies of proposed designs, stress-test the latencies of systems under development, equalize latencies of replicated services by load balancing, monitor latencies of production systems using instrumentation, and commit to latency targets in service level objectives and agreements. The most commonly-used representation of latency in these scenarios is percentiles. Percentiles are deceptively simple, a function from values between 0 and 1 (or equivalently 0% and 100%) to a response time. But the relation between percentiles and the distribution they describe is subtle: Formally, the percentile function is the inverse of the integral of the probability density of the distribution. The subtlety of this construction makes it easy to miss a step and become confused. Working through the basics in detail, gaining a clear understanding of how percentiles relate to other representations of latency, provides designers with a straightforward approach to reasoning about a fundamental concept in distributed systems design." />
<meta property="og:description" content="Designers of distributed systems obsess over service latency. They forecast latencies of proposed designs, stress-test the latencies of systems under development, equalize latencies of replicated services by load balancing, monitor latencies of production systems using instrumentation, and commit to latency targets in service level objectives and agreements. The most commonly-used representation of latency in these scenarios is percentiles. Percentiles are deceptively simple, a function from values between 0 and 1 (or equivalently 0% and 100%) to a response time. But the relation between percentiles and the distribution they describe is subtle: Formally, the percentile function is the inverse of the integral of the probability density of the distribution. The subtlety of this construction makes it easy to miss a step and become confused. Working through the basics in detail, gaining a clear understanding of how percentiles relate to other representations of latency, provides designers with a straightforward approach to reasoning about a fundamental concept in distributed systems design." />
<meta property="og:site_name" content="All my marbles in one place" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-09T00:00:00-07:00" />
<script type="application/ld+json">
{"@context":"http://schema.org","@type":"BlogPosting","headline":"The basics of latency percentiles","author":{"@type":"Person","name":"Ted Kirkpatrick"},"datePublished":"2020-09-09T00:00:00-07:00","dateModified":"2020-09-09T00:00:00-07:00","description":"Designers of distributed systems obsess over service latency. They forecast latencies of proposed designs, stress-test the latencies of systems under development, equalize latencies of replicated services by load balancing, monitor latencies of production systems using instrumentation, and commit to latency targets in service level objectives and agreements. The most commonly-used representation of latency in these scenarios is percentiles. Percentiles are deceptively simple, a function from values between 0 and 1 (or equivalently 0% and 100%) to a response time. But the relation between percentiles and the distribution they describe is subtle: Formally, the percentile function is the inverse of the integral of the probability density of the distribution. The subtlety of this construction makes it easy to miss a step and become confused. Working through the basics in detail, gaining a clear understanding of how percentiles relate to other representations of latency, provides designers with a straightforward approach to reasoning about a fundamental concept in distributed systems design.","mainEntityOfPage":{"@type":"WebPage","@id":"/2020/09/09/latency-basics/"},"url":"/2020/09/09/latency-basics/"}</script>
<!-- End Jekyll SEO tag -->

</head>


  <body class="theme-base-0c layout-reverse">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          All my marbles in one place
        </a>
      </h1>
      <p class="lead">A blog about course design, data display, C++, and Python.  Yes, these are related, at least as I see them.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/comment-policy/">Comment policy</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/credits/">Credits</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

    
        <div class="sidebar-tags">
        Tags:<br/>
        
	   
	    <a href="/tag/C++/">C++</a>,
	  
        
	   
	    <a href="/tag/Python/">Python</a>,
	  
        
	   
	    <a href="/tag/Course design/">Course design</a>,
	  
        
	   
	    <a href="/tag/Big data/">Big data</a>,
	  
        
	   
	    <a href="/tag/Soft skills/">Soft skills</a>,
	  
        
	   
	    <a href="/tag/Statistics/">Statistics</a>,
	  
        
	   
	    <a href="/tag/Experimental design/">Experimental design</a>,
	  
        
	   
	    <a href="/tag/Rhetoric/">Rhetoric</a>,
	  
        
	   
	    <a href="/tag/Admin/">Admin</a>,
	  
        
	  	    
            <a href="/tag/Distributed systems/">Distributed systems</a>
          
        
	</div>
      

    </nav>

    <p>&copy; 2020. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">The basics of latency percentiles</h1>
  <span class="post-date">09 Sep 2020
  
    <span class="tag-block">Tags: 
    
      
      <a href="/tag/Distributed systems">Distributed systems</a>
      
    
    </span>
  
  </span>
  
  <p>Designers of distributed systems obsess over service latency. They
forecast latencies of proposed designs, stress-test the latencies of
systems under development, equalize latencies of
replicated services by load balancing, monitor latencies of production
systems using instrumentation, and commit to latency targets in
service level objectives and agreements.</p>

<p>The most commonly-used representation of latency in these scenarios is
<a href="https://www.dynatrace.com/news/blog/why-averages-suck-and-percentiles-are-great/">percentiles</a>. Percentiles
are deceptively simple, a function from values between 0 and 1 (or
equivalently 0% and 100%) to a response time. But the relation between
percentiles and the distribution they describe is subtle: Formally,
the percentile function is the inverse of the integral of the
probability density of the distribution.</p>

<p>The subtlety of this construction makes
it easy to miss a step and become confused. Working through the
basics in detail, gaining a clear understanding of how percentiles relate to
other representations of latency, provides designers with a straightforward
approach to reasoning about a fundamental concept in distributed
systems design.</p>

<!--more-->

<h2 id="latency-distributions">Latency distributions</h2>

<p>Begin with distributions. The latency distributions of actual services
do not conform well to any of the widely-studied distributions
presented in statistical texts. Distributions of latencies are:</p>

<ol>
  <li>Positively skewed, with a heavy tail on the right</li>
  <li>Time-varying</li>
  <li>Multimodal</li>
  <li>Spiky</li>
  <li>Bounded below but not above.</li>
</ol>

<p>There is an interesting analysis to be done, showing these properties
as consequences of the underlying mechanisms in our systems. For this
article, I will simply note that these properties are widely-observed
in the distributions of actual systems, including
<a href="https://www.youtube.com/watch?v=lJ8ydIuPFeU">Gil Tene’s classic rant</a>
and Ben Sigelmen’s argument that
<a href="https://lightstep.com/blog/performance-is-a-shape-not-a-number/">“performance is a shape”</a>.</p>

<h2 id="representing-latency-by-a-density-function">Representing latency by a density function</h2>

<p>Designers typically envision latency as a density function, with
latency the horizontal axis, beginning at zero and unbounded in the
positive direction, while the vertical axis is an abstract nonzero
probability density.</p>

<p>The density function \(LD(t)\) for latencies has
the following properties:</p>

<ul>
  <li>\(LD(t) = 0, \quad t &lt;= 0\)</li>
  <li>\(0 &lt; LD(t), \quad t &gt; 0\)</li>
  <li>\(\lim_{t\to\infty} LD(t) = 0\quad(LD(t)\) is asymptotic to the
horizontal axis)</li>
  <li>\(\int_0^\infty LD(t) \,\mathrm{d}t = 1\quad\) (the area under
\(LD(t)\) is 1)</li>
</ul>

<h3 id="a-simplified-latency-distribution">A simplified latency distribution</h3>

<p>For purposes of this post, I will need an example distribution. I do
not propose this distribution as representing any
actual distribution but simply use it to represent some of the
complexities of actual latencies. Any description of actual latencies
will have to include these complexities at the least.</p>

<p>The example distribution is the mixture of two <a href="https://en.wikipedia.org/wiki/Log-normal_distribution">lognormal distributions</a>:</p>

<ul>
  <li>80% a lognormal density for a random variable whose log is a
Gaussian with mean 0 and standard deviation 1.0</li>
  <li>20% a lognormal density for a random variable whose log is a
Gaussian with mean 5 and standard deviation 0.5.</li>
</ul>

<p>The <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html#scipy.stats.lognorm">SciPy</a> code for this density function is:</p>

<div class="highlighter-rouge"><pre class="highlight"><code><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="o">.</span><span class="mi">8</span> <span class="o">*</span> <span class="n">stats</span><span class="o">.</span><span class="n">lognorm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span> <span class="o">+</span>
           <span class="o">.</span><span class="mi">2</span> <span class="o">*</span> <span class="n">stats</span><span class="o">.</span><span class="n">lognorm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="mf">5.0</span><span class="p">)</span>
</code></pre>
</div>

<p>and it has the following density function:</p>

<p><img src="/assets/images/Lognormal-mixture-density.png" alt="Bimodal density function for mixture of two lognormals" /></p>

<p>The resulting mixture matches several properties of actual latency
distributions:</p>

<ol>
  <li>Bounded below by 0</li>
  <li>Asymmetric, with a long positive tail</li>
  <li>Multimodal (in this case, bimodal)</li>
</ol>

<p>The density plot is likely what most designers have in mind when
imagining the latency distribution of an actual or prospective
service. How is this related to percentiles, the measure typically
used to characterize latencies?  The process is indirect, comprising
several steps, and it’s informative to walk through them in
detail.</p>

<h2 id="step-1-compute-the-cumulative-distribution">Step 1: Compute the cumulative distribution</h2>

<p>The first step is computing the cumulative distribution, \(LC(t)\).
Analytically, this is just the integral of the density:</p>

<p>\[ LC(t) = \int_0^t LD(x) \,\mathrm{d}x \]</p>

<p>The cumulative distribution has the same domain as the
density, a range of [0, 1), and an important additional property: For actual
latency distributions, it is strictly monotonically
increasing:</p>

<p>\[ \forall\: t1, t2, t1 &lt; t2 :\:  LC(t1) &lt; LC(t2) \]</p>

<p>(Although one can construct distributions whose
corresponding cumulative function is monotonic but not strict,
these are extremely rare in practice. If one should arise, there are
technical solutions to make its cumulative function strictly
monotonic.) This property is essential for computing the percentile,
as we will see in the next step.</p>

<p>For the sample distribution given above, the cumulative distribution
\(LC(t)\) is:</p>

<p><img src="/assets/images/Lognormal-mixture-cumulative.png" alt="Cumulative probability function for mixture of two lognormals" /></p>

<h2 id="step-2-compute-the-inverse-cumulative-distribution">Step 2: Compute the inverse cumulative distribution</h2>

<p>The percentile function, \(LP(p)\), is the inverse of the cumulative
distribution:</p>

<p>\[ LP(p) = LC(t)^{-1} \]</p>

<p>The strict monotonicity of \(LC(t)\) we described above ensures that its inverse is
well-defined. The following diagram illustrates how \(LP(.6)\) is
computed, drawing a ray from .6 on the range of \(LC(.6)\)
until it intersects the function, then dropping to 1.95 ms on the domain:</p>

<p><img src="/assets/images/Inverse-LC.png" alt="Inverting the cumulative distribution function" /></p>

<h3 id="heights-in-lp-are-areas-under-ld">Heights in \(LP\) are areas under \(LD\)</h3>

<p>I think it’s helpful to explicitly show the relationship between the percentile
\(LP\) and the density \(LD\). As the inverse of the integral, a height in
\(LP\)</p>

<p><img src="/assets/images/LC-height.png" alt="Heights of regions for LP(.6) threshold" /></p>

<p>corresponds to an area under \(LD\):</p>

<p><img src="/assets/images/LD-area.png" alt="Regions under the LD function corresponding to LP(.6) threshold" /></p>

<p>Those shapes are deceptive:  I had to run a numeric integration to
convince myself that the cyan area is in fact 50% larger than the magenta.</p>

<h2 id="using-the-tools-computing-effective-percentile-ep">Using the tools: Computing effective percentile \(EP\)</h2>

<p>Understanding the detailed construction of \(LP(p)\) helps explain the details of computing
<a href="/2020/07/24/extending-the-tail-at-scale/">effective percentiles</a>. Consider
the computation of \(EP(.6, 5)\), the effective percentile
corresponding to the slowest response of 5 calls to a service with
\(LP(.6) = 1.95\) ms. The effective percentile is \(EP(.6, 5)
= .078\). Graphically, the cumulative probability at 1.95 ms is
dropped from .600 to .078</p>

<p><img src="/assets/images/Computing-EC.png" alt="Dropping an LP down to its corresponding EP" /></p>

<p>producing an effective cumulative distribution \(EC(t, 5)\) (where 5
is the fanout):</p>

<p><img src="/assets/images/Lognormal-mixture-effective-cumulative.png" alt="Cumulative probability function for mixture of two lognormals---effective probabilities" /></p>

<p>This illustrates how the probability of high latencies has increased
due to five calls to the service. Where the original \(LC(1.95~\mathrm{ms})
= .6\), now we have to go up to 6.2 ms to get
\(EC(6.2~\mathrm{ms}, 5~\mathrm{calls}) = .6\):</p>

<p><img src="/assets/images/From-LC-to-EC.png" alt="From LC(.6) to EC(.6, 5)" /></p>

<p>Differentiating the cumulative function from time
\(t\) and fanout \(f\) \(EC(t, f)\) over \(t\) gives us the effective density \(ED(t, f)\):</p>

<p><img src="/assets/images/Lognormal-mixture-effective-density.png" alt="Effective density function for five service calls" /></p>

<p>The shape of this density function informs our intuition of the
effect of multiple calls to a service: We squeezed the left side of
the density, causing the right side to expand. For example, separating the density
into regions of .6 and .4 of the total area, we see how the density
has shifted right compared to the original density function
\(LD(t)\) shown above:</p>

<p><img src="/assets/images/LD-area.png" alt="Regions under the LD(t) function corresponding to LC(.6)" width="330" style="margin:0;
display: inline;" />
<img src="/assets/images/Areas-under-ED.png" alt="Regions under the ED(t,5) function corresponding to EP(.6, 5) threshold" width="330" style="margin:0;display: inline;" /></p>

<h2 id="summary">Summary</h2>

<p>Latency percentiles are simple but subtle. Understanding their
construction from the original density distribution clarifies
important concepts such as effective percentiles.</p>


</div>




<div id="disqus_thread"></div>
<script>

var disqus_config = function () {
this.page.url = "http://kirkpatricktech.com/2020/09/09/latency-basics/";
//this.page.identifier = "/2020/09/09/latency-basics";
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://kirkpatricktech-com.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

    </div>

  </body>
</html>
