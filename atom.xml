<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>All my marbles in one place</title>
 <link href="/atom.xml" rel="self"/>
 <link href="/"/>
 <updated>2020-05-27T16:50:23-07:00</updated>
 <id></id>
 <author>
   <name>Ted Kirkpatrick</name>
   <email></email>
 </author>

 
 <entry>
   <title>Flambloozlement and the student enthusiasm for crunch mode</title>
   <link href="/2020/04/03/flambloozlement/"/>
   <updated>2020-04-03T00:00:00-07:00</updated>
   <id>/2020/04/03/flambloozlement</id>
   <content type="html">&lt;p&gt;How do students assess the value of what they learn in class? On the
one hand, years of attending school have made them sophisticated
judges of teaching effectiveness: They know whether an approach is
working for their circumstances and purposes—although these
may diverge far from the instructor’s goals. At the same time, students
can harbour a curious enthusiasm for a course precisely because it
overhwelms them.  Why do they respond this way?&lt;/p&gt;

&lt;h2 id=&quot;when-are-students-fond-of-courses-in-which-they-dont-learn&quot;&gt;When are students fond of courses in which they don’t learn?&lt;/h2&gt;

&lt;p&gt;How many times have you heard a student say, with more enthusiasm
than irony, “That was a great course, though it was so far over my
head that I only learned a bit of the material”? Or its close
affiliate, “I considered myself lucky to get out with a C [or even a D]”? If
they didn’t learn much, why did they consider this a “great course”?&lt;/p&gt;

&lt;p&gt;Sometimes this gap between enthusiasm and benefit arose for
reasons outside the course: The student was ill-prepared or circumstances
distracted them.  These aren’t ideal outcomes but they do not indicate
any failing in the course design or instruction.  The student and the
instructor would agree that any failure to learn was due to issues in
the student’s life, not the course.&lt;/p&gt;

&lt;p&gt;But other times the student was prepared and spent enough time on task. In
fact, these are often cases where the student spent disproportionate
time on the course, at the expense of other courses, yet they learned
disappointingly little by both their standards and those of their instructor.&lt;/p&gt;

&lt;p&gt;What’s going on?&lt;/p&gt;

&lt;h3 id=&quot;a-caution-about-generalizing&quot;&gt;A caution about generalizing&lt;/h3&gt;

&lt;p&gt;I’ll say before I proceed that the following notions are my own, based
solely on anecdotal observation. I don’t recall any discussion of
quite this phenomenon in the teaching literature, including my
&lt;a href=&quot;/2018/09/19/three-evidence-based-books-for-better-teaching/&quot;&gt;three favourite books on teaching&lt;/a&gt;.
Though these books describe related topics, there appears to be a
specific, distinct motivation and approach to learning in the contexts
I’m about to describe. I also see some &lt;em&gt;a priori&lt;/em&gt; reasons why students
might respond this way, so this post is more than a list of
cherry-picked incidents.&lt;/p&gt;

&lt;p&gt;Given this argument’s informal nature, I will also avoid generalizing
it outside my experience of computing science classes. I expect
similar dynamics arise in other disciplines but I will leave their
description to instructors in those fields.&lt;/p&gt;

&lt;h2 id=&quot;flambloozlement&quot;&gt;Flambloozlement&lt;/h2&gt;

&lt;p&gt;I call this state, in which students are enthusiasts in their own
overwhelm, &lt;em&gt;flambloozlement&lt;/em&gt;. It’s the sense that there’s a lot of
material, it’s demanding in just the right way, and therefore it must
be important. Furthermore, any lack in the student’s accomplishment is
a mark of the student’s incapacity, not the way the material has been
presented.&lt;/p&gt;

&lt;p&gt;This is a situation where students are duped into believing that if they
were &lt;em&gt;only smart enough&lt;/em&gt; they could accomplish the projects in the
available time.  This in turn induces them to throw themselves into the
breach, risking body and mind and other course grades, to even get
close to mastering the material. These beliefs may be
affirmed at course’s end, when some students are found to have
succeeded at their final projects. The other students—and the instructor—will
likely ignore the degree to which the successful students began the
course already knowing a large fraction of the material.  Their
success was due more to a second encounter with concepts they had
already learned than to learning those concepts for the first time.&lt;/p&gt;

&lt;h2 id=&quot;the-common-attributes-of-these-courses&quot;&gt;The common attributes of these courses&lt;/h2&gt;

&lt;p&gt;I have seen students joyously pursue flambloozlement in courses with
the following attributes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;They perceive the material as core to their discipline.&lt;/li&gt;
  &lt;li&gt;The material includes a mass of technical details.&lt;/li&gt;
  &lt;li&gt;Success in the assignments requires attending to many of these
details. The exemplar in a computing science course is a large
final programming assignment. In a pinch, assignments requiring
extensive work with equations or proofs can induce similar student
behaviour.&lt;/li&gt;
  &lt;li&gt;The students perceive a monotonic relationship between hours of
effort and ultimate grade.&lt;/li&gt;
  &lt;li&gt;The assignments require little writing or reflection after the fact.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;When performing the assignment, students encounter details in an order entirely independent of
the systematic development of concepts core to the material.&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I think that last point is the dispositive one, with the preceding
points setting the context in which flambloozlement flourishes. I also
want to emphasize the importance of “perceive” in some of the
statements: Regardless of what the instructor or practitioners in the
field might argue, the students see the material in this light.&lt;/p&gt;

&lt;h2 id=&quot;a-sample-flambloozling-assignment&quot;&gt;A sample flambloozling assignment&lt;/h2&gt;

&lt;p&gt;Let’s see how this can play out. Imagine an operating system course
where the instructor assigns a final project with substantial
programming effort. The conditions for flambloozlement are independent
of whether the project is individual or group, so long as the effort
required from any individual student is large enough.  The project
could be any of the typical ones for such courses, from “extend a small
operating system”, to “add a device driver”, to “hack the Linux
kernel”.&lt;/p&gt;

&lt;p&gt;Such assignments have a common characteristic: They require students
to learn the interfaces of a substantial piece of software and to work
with professional-quality tools. Although these are desirable outcomes
in their own right, they are independent of the outcome of learning
operating system principles and lead students to adopt a &lt;a href=&quot;https://teaching.unsw.edu.au/sites/default/files/upload-files/deep_and_surface_learning.pdf&quot;&gt;shallow
approach to learning&lt;/a&gt; those principles.&lt;/p&gt;

&lt;p&gt;Consider what the students actually do while working on the
assignment. They primarily will solve many small problems in
sequence. Most students will have little experience working with
programs of this complexity. Few programming problems are “simple” for
programmers whose experience is too low for the software or tools they
are using. Instead of resolving their immediate dilemma by combining
familiar parts, the novice is reduced to slapping together pieces that
vaguely fit, proceeding to their next challenge without understanding
the solution to the last or even accepting a non-solution that appears
to be a fix.&lt;/p&gt;

&lt;h3 id=&quot;a-simple-problem-that-derails-a-novice&quot;&gt;A simple problem that derails a novice&lt;/h3&gt;

&lt;p&gt;Many of these problems will have nothing to do with operating systems
principles. For example, suppose they are using the
&lt;a href=&quot;https://microk8s.io/&quot;&gt;Microk8s&lt;/a&gt; Kubernetes distribution and wish to
determine how many &lt;code class=&quot;highlighter-rouge&quot;&gt;kubelet&lt;/code&gt; instances are running locally. They may
know that the &lt;code class=&quot;highlighter-rouge&quot;&gt;ps -eaf&lt;/code&gt; command will dump the process table.  If
they simply type that command they will get a tedious list of hundreds
of processes—460 on the system that I just tried.&lt;/p&gt;

&lt;p&gt;An experienced programmer would exclude most irrelevant lines via
piping the output through &lt;code class=&quot;highlighter-rouge&quot;&gt;grep&lt;/code&gt;, producing three extraneous hits in
addition to the correct one:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ ps -ef | grep kubelet
... The kubelet instance
... The API server, which included kubelet in its command-line arguments
... /bin/operator, which also included kubelet in its command-line arguments
... The &quot;grep kubelet&quot; command
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;or use &lt;code class=&quot;highlighter-rouge&quot;&gt;pgrep&lt;/code&gt; to combine listing and filtering and get just the
correct line:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;$ pgrep -a kubelet
... The kubelet instance
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;But a relative novice, unaccustomed to quick-and-dirty pipelines (the
first solution) and unaware of esoteric commands that produce more
precise results (the second solution), is likely to squander tens of
minutes just plucking the appropriate line out of the 460 produced by
a simple &lt;code class=&quot;highlighter-rouge&quot;&gt;ps -eaf&lt;/code&gt;. At this point, they have certainly forgotten why
they even wanted to find this item and will need to reconstruct their logic.&lt;/p&gt;

&lt;h2 id=&quot;the-instructors-goals-are-distant-from-actual-student-experience&quot;&gt;The instructor’s goals are distant from actual student experience&lt;/h2&gt;

&lt;p&gt;The students’ activity during such a programming project is a long
sequence of this sort of challenges, insignificant to a skilled
programmer but potentially derailing to a novice, in a distinct
sequence for every student.  I want to emphasize that the students
were not stalled by lack of knowledge of the course content, operating
systems principles. Rather, they were stalled by a lack of general
programming knowledge.&lt;/p&gt;

&lt;p&gt;Contrast the student experience of leaping over many short-term
programming hurdles with the experience the instructor intended
for the students. The instructor likely imagined the students having a
sequence of consolidations or even epiphanies, as they observed
operating system principles in action, such as the security provided
by the separation of user space and kernel space, the cost of context
switching, the benefit of an abstract file system interface in hiding
device specifics, and other principles.  In the actual course, the
students are up into the early morning struggling to diagnose and fix
the most basic problems.&lt;/p&gt;

&lt;p&gt;To the students, this stream of near-insuperable barriers appears to
be the point of the course. If they acknowledge the importance of the
overarching topic they will attach that importance to their many small
programming successes. Students enrolled in computer science courses
typically enjoy programming, so they are susceptible to believing that
programming is the most important lesson of the course when in fact
these experiences stand in the way of them actually learning the
primary content.&lt;/p&gt;

&lt;h2 id=&quot;using-the-same-words-with-entirely-different-intentions&quot;&gt;Using the same words with entirely different intentions&lt;/h2&gt;

&lt;p&gt;This combination, where students’ experiences forming the actual
learning lie in an entirely different realm and level of detail
from the intended course content, yet both students and instructor
apparently agree on the importance of the content, is the source of
the disconnect between student effort, student enthusiasm, and their
lack of success mastering the actual material. Both groups use the same
words to mean entirely different things.&lt;/p&gt;

&lt;h2 id=&quot;simply-adding-a-learning-outcome-doesnt-address-the-problem&quot;&gt;Simply adding a learning outcome doesn’t address the problem&lt;/h2&gt;

&lt;p&gt;Many instructors would be puzzled by this critique.  They might
claim to resolve the dilemma by adding another learning outcome to
our hypothetical course, something like “developing programming
skill”.&lt;/p&gt;

&lt;p&gt;This doesn’t solve the problem, it just makes the instructor’s denial
explicit.  A genuine learning outcome is more than another entry in a
list. It forms the express basis of a suite of course activities,
including teaching material and both formative and summative
student assessment. The learning outcome is demonstrated by the
dedication of significant course time to its achievement by the
students.&lt;/p&gt;

&lt;p&gt;If the instructor for our hypothetical operating systems course
removed a substantial portion of operating systems material to fit in
lessons on programming, perhaps with emphasis on aspects specific to
the sort of projects assigned in the course, then an outcome such as
“improve programming skill” could be legitimately included in the
course goals. But few, if any, instructors are willing to accept the
shift of course focus away from operating systems.&lt;/p&gt;

&lt;h2 id=&quot;no-easy-resolution&quot;&gt;No easy resolution&lt;/h2&gt;

&lt;p&gt;Flambloozlement is a reality of course design in a technical field
such as computing science. Student enthusiasm for a course may have
little connection to the actual material nor to how well they learned
that material. Although developing students’ proficiency in the detailed technical
skills of our field is an important goal, actually achieving that goal
requires exquisite care to keep the assignment workload
manageable. Only then will students actually learn the overarching
principles that form the main learning outcomes of our courses.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>How hard is it to implement replicated state machines?</title>
   <link href="/2020/03/08/difficulty-of-state-machines/"/>
   <updated>2020-03-08T00:00:00-08:00</updated>
   <id>/2020/03/08/difficulty-of-state-machines</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Note: Over the past eight months, I have been working with the code for
TenCent’s &lt;a href=&quot;https://github.com/Tencent/phxpaxos&quot;&gt;Phxpaxos&lt;/a&gt;, an
open-source implementation of replicated state-machines, with
consensus enforced by Paxos. I have learned a lot from studying this
code and from comparing it with the more focussed
&lt;a href=&quot;https://bitbucket.org/sciascid/libpaxos/src/master/&quot;&gt;libpaxos&lt;/a&gt;, which
does not include state machine code.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Recently I have isolated several topics well-adapted to the smaller size
of blog posts and I will be adding them here.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Distributed systems are often made highly available by implementing
them as replicated state machines, coordinating their operations via a
consensus algorithm such as Paxos. Two popular tutorials from the
1990s describe the basic theory but how hard is it to implement this
theory?  The code from the
&lt;a href=&quot;https://github.com/Tencent/phxpaxos&quot;&gt;Phxpaxos&lt;/a&gt; project suggests that
the general solution requires more work than it might seem.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;the-complexity-of-replicated-state-machine-implementations&quot;&gt;The complexity of replicated state machine implementations&lt;/h2&gt;

&lt;p&gt;The basic idea of replicated state machines was first sketched in
Lamport’s classic 1978 &lt;em&gt;CACM&lt;/em&gt; article,
&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/time-clocks-ordering-events-distributed-system/&quot;&gt;“Time, Clocks, and the Ordering of Events in a Distributed System”&lt;/a&gt;
(it’s easy to miss—see the left column of p. 562),
though many details remained to be developed by others.
More details are provided in two widely-cited surveys: Fred
Schneider’s 1990 &lt;em&gt;Computing Surveys&lt;/em&gt; article,
&lt;a href=&quot;https://www.cs.cornell.edu/fbs/publications/SMSurvey.pdf&quot;&gt;“Implementing Fault-Tolerant Services Using the State Machine Approach: A Tutorial”&lt;/a&gt;,
and Butler Lampson’s 1996 &lt;em&gt;Distributed Algorithms&lt;/em&gt; paper,
&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/how-to-build-a-highly-available-system-using-consensus/&quot;&gt;“How to Build Highly Available Systems Using Consensus”&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Schneider’s paper is an extremely general introduction, presuming an
arbitrary consensus algorithm, written when the theory was
well-established but few systems were in production.  As such, only a
small portion of the paper is pertinent to the Phxpaxos implementation.&lt;/p&gt;

&lt;p&gt;Lampson’s paper is primarily an introduction to specifying and
reasoning about replicated state machines.  He develops a notation
that he then uses to specify Paxos and informally argue for its
correctness. He says nothing about designing the state machines whose
sequence of operations will be established by Paxos.&lt;/p&gt;

&lt;p&gt;Schneider and Lampson’s scant coverage of the actual implementation of
state machines implies that it is straightforward, perhaps
trivial, once consensus is established. Yet the Phxpaxos code base
implements Paxos in 
5,184 lines, while implementing state machines in 2,207 lines:&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Directory&lt;/th&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Excluding / including files&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Lines of &lt;code class=&quot;highlighter-rouge&quot;&gt;.cpp&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;.h&lt;/code&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;src/algorithm&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Excluding &lt;code class=&quot;highlighter-rouge&quot;&gt;checkpoint_*&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5184&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Total Paxos&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;5184&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;src/sm-base&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;553&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;src/checkpoint&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;814&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;src/algorithm&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Including only &lt;code class=&quot;highlighter-rouge&quot;&gt;checkpoint_*&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;840&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;Total state machine&lt;/td&gt;
      &lt;td style=&quot;text-align: left&quot;&gt; &lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;2207&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The state machine code is 43% of
the line count for the Paxos code—anything but trivial. Although
line count is at best a rough indication of complexity, I think for
this case, comparing proportions of a single project writen by a
single, small team, it provides a reasonable guide to the relative
level of effort.&lt;/p&gt;

&lt;p&gt;Bear in mind that this code does not implement any particular state
machine, merely the abstract structure within which a state machine
will be implemented by inheriting from the abstract
classes.&lt;/p&gt;

&lt;p&gt;What makes the code for a general replicated state machine so complex,
even when the algorithm for sequencing client requests is handled
separately? There are several challenges:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The message lengths are arbitrary.&lt;/li&gt;
  &lt;li&gt;The abstract framework requires substantial boilerplate.&lt;/li&gt;
  &lt;li&gt;The system must provide a general checkpoint mechanism.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Addressing these challenges requires substantial code. This
implementation effort was not just in service of Phxpaxos’s users. The
Phxpaxos implementation of Paxos also uses the state machine framework
to solve two common problems in general Paxos, reconfiguration and
leader election. These algorithms do not require the full generality
of the Phxpaxos state machine framework, however. Much of the
framework is only useful for more complicated cases.&lt;/p&gt;

&lt;p&gt;I first describe the implementation complexities before turning to
the two state machines internal to the library.&lt;/p&gt;

&lt;h2 id=&quot;arbitrary-message-lengths&quot;&gt;Arbitrary message lengths&lt;/h2&gt;

&lt;p&gt;In the replicated state machine context, consensus algorithms
negotiate the “next operation” for the machines to perform. This
requires passing around the full value of the machine operations. For
systems such as replicated stores, the values may be large, even
unbounded. The consensus algorithm must be capable of efficiently
handling values of a megabyte or more. This complexity is not located
in the state machine code itself but spread through the consensus
code.&lt;/p&gt;

&lt;p&gt;Phxpaxos provides an option, &lt;code class=&quot;highlighter-rouge&quot;&gt;Options.bIsLargeValueMode&lt;/code&gt;, that when
set increases the timeouts used when waiting for message
responses. These longer timeouts are required because longer messages
take measurably longer to transmit. Timeouts appropriate for
shorter messages would yield too high a level of false positives,
decisions that a message was lost when it simply required longer
transmission time.&lt;/p&gt;

&lt;h2 id=&quot;the-abstract-state-machine-framework&quot;&gt;The abstract state machine framework&lt;/h2&gt;

&lt;p&gt;Though the framework for abstract state machines does not include any
actual state machine operations, it requires considerable logic in its
own right:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Because the system accepts an arbitrary number of state machines,
not just one, it requires logic for adding state machines to the
active list and locating a state machine’s address given its
identifier, via the state machine factory class,
&lt;code class=&quot;highlighter-rouge&quot;&gt;SMFac&lt;/code&gt;. Supporting multiple state machines is
not just an empty generality—as noted above, Phxpaxo’s algorithm
requires two state machines itself, on top of any defined by the
user of the library.&lt;/li&gt;
  &lt;li&gt;The state machines require a context data structure &lt;code class=&quot;highlighter-rouge&quot;&gt;SMCtx&lt;/code&gt; for
carrying any necessary state from the proposing client, through the
long sequence of asynchronous Paxos messages, to completion of the
Paxos instance and execution by the state machine, finally
returning the context, including any result code from the
operation, to the proposing client.&lt;/li&gt;
  &lt;li&gt;The framework must define method calls for multiple styles of
operation. State machine operations in Phxpaxos can be executed
singly or in batch, in active mode or checkpoint mode, requiring
support of four execution styles.&lt;/li&gt;
  &lt;li&gt;Generalized state machines complicate the Paxos message protocol (defined
in file &lt;code class=&quot;highlighter-rouge&quot;&gt;src/comm/commdef.h&lt;/code&gt;). The
basic Multi-Paxos protocol implemented by Phxpaxos (&lt;code class=&quot;highlighter-rouge&quot;&gt;enum PaxosMsgType&lt;/code&gt;) requires 10
message types. The checkpointing mechanism required to support
general state machines adds 2 more message types to that protocol
and introduces a separate protocol of 7 types (enumerated values
&lt;code class=&quot;highlighter-rouge&quot;&gt;CheckpointMsgType&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;CheckpointSendFileFlag&lt;/code&gt;, and
&lt;code class=&quot;highlighter-rouge&quot;&gt;CheckpointSendFileAckFlag&lt;/code&gt;). These message types and their flags
must all be handled in the main Paxos logic code in files
&lt;code class=&quot;highlighter-rouge&quot;&gt;src/algorithm/instance.cpp&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;src/algorithm/learner.cpp&lt;/code&gt;. This
makes the implementation harder to read than that of
a pure Paxos library such as &lt;code class=&quot;highlighter-rouge&quot;&gt;libpaxos&lt;/code&gt;, which does not include
state machine code. I explore the complexities of checkpointing in
more detail below.&lt;/li&gt;
  &lt;li&gt;The framework must provide callbacks to support state machines with
specialized requirements. Phxpaxos supports three such callbacks:
    &lt;ol style=&quot;list-style-type: lower-latin;&quot;&gt;
&lt;li&gt;
        &lt;p&gt;A callback executed after a value has been chosen by a Paxos
   instance and just before it is executed (&lt;code class=&quot;highlighter-rouge&quot;&gt;StateMachine.BeforePropose&lt;/code&gt;). This allows the state
   machine to update the value to reflect any changes that occurred
   during the Paxos rounds. This callback is used by the Phxpaxos
   implementation of a state machine for master election (file
   &lt;code class=&quot;highlighter-rouge&quot;&gt;src/master/master_sm.cpp&lt;/code&gt;).&lt;/p&gt;

        &lt;p&gt;This callback is potentially such a drag on performance of the
   main loop that it is only enabled when both a system-wide flag
   (&lt;code class=&quot;highlighter-rouge&quot;&gt;Options.bOpenChangeValueBeforePropose&lt;/code&gt;) is set and a state
   machine-specific function (&lt;code class=&quot;highlighter-rouge&quot;&gt;StateMachine.NeedCallBeforePropose&lt;/code&gt;)
   returns &lt;code class=&quot;highlighter-rouge&quot;&gt;true&lt;/code&gt;.&lt;/p&gt;
      &lt;/li&gt;
&lt;li&gt;
        &lt;p&gt;A callback executed after reconfiguration of Paxos node
   membership (&lt;code class=&quot;highlighter-rouge&quot;&gt;Options.pMembershipChangeCallback&lt;/code&gt;).&lt;/p&gt;
      &lt;/li&gt;
&lt;li&gt;
        &lt;p&gt;A callback executed upon election of a new master
   (&lt;code class=&quot;highlighter-rouge&quot;&gt;Options.pMasterChangeCallback&lt;/code&gt;).&lt;/p&gt;
      &lt;/li&gt;
&lt;/ol&gt;
  &lt;/li&gt;
  &lt;li&gt;The boilerplate state machine logic must account for the Phxpaxos
“group” feature. This establishes multiple independent Paxos
clusters running off the same network address, which can be used to
increase throughput. The &lt;code class=&quot;highlighter-rouge&quot;&gt;SMFac&lt;/code&gt; factory object and concrete
classes derived from &lt;code class=&quot;highlighter-rouge&quot;&gt;StateMachine&lt;/code&gt; accept a group index and must
select the appropriate state for the indicated cluster.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Taken together, these represent a substantial code base simply to
establish the basic framework from which application-specific
&lt;code class=&quot;highlighter-rouge&quot;&gt;StateMachine&lt;/code&gt; classes are derived. Yet this is only the smaller
portion of the state machine code. The largest portion 
implements a feature that only some state machines require and that is
infrequently executed: checkpoints. I turn to that feature next.&lt;/p&gt;

&lt;h2 id=&quot;general-checkpointing&quot;&gt;General checkpointing&lt;/h2&gt;

&lt;p&gt;The single most complex feature required by a general state machine
framework such as that of Phxpaxos is a mechanism for taking
checkpoints of a state machine and restoring from them as
necessary. This is complex code and many state machines do not need
such a mechanism—neither of the two required for Phxpaxos need
it—and those that do need checkpoints only use them in the case of
crashes that require the most extensive form of recovery.&lt;/p&gt;

&lt;p&gt;Checkpointing is complex, so complex in fact that I have moved the
details into one or more separate posts. For this post, I only provide
an overview.&lt;/p&gt;

&lt;h3 id=&quot;when-are-checkpoints-used&quot;&gt;When are checkpoints used?&lt;/h3&gt;

&lt;p&gt;Checkpoints are required in several situations, of which the
simplest case is bringing a freshly-added node up to date. This
typically arises when an existing node has crashed or is taken down
for maintenance and the operators want to maintain the cluster’s
fault-tolerance by bringing the node count back to its production
level.&lt;/p&gt;

&lt;p&gt;In this situation, checkpoints provide the history required to
jump-start a fresh machine. The Paxos log may not be a complete system
history because Phxpaxos garbage collects its logs, culling old values
no longer necessary for active decisions. Although Paxos does not need
these older values to proceed, those values are needed to bring fresh
state machines up to date.&lt;/p&gt;

&lt;h3 id=&quot;which-state-machines-require-checkpoints&quot;&gt;Which state machines require checkpoints?&lt;/h3&gt;

&lt;p&gt;The amount of data required to bring a newcomer up to date varies with
the state machine. In the case of Paxos itself, the newcomer can use
the most recent value of any active node. If the sender was not the
most current node, the regular synchronization protocol within Paxos
will bring both it and the newcomer up to date using the normal Paxos
messages.  (Phxpaxos message protocols include some shortcuts to
accelerate this process but the principle applies to basic Paxos as
well.)&lt;/p&gt;

&lt;p&gt;The same principle applies to the two internal state machines of
Phxpaxos, which record the current leader and current node
configuration. For these machines as well, the only values that matter
are the most recent settings. The history of previous leaders and
configurations is irrelevant.&lt;/p&gt;

&lt;p&gt;However for machines with more complex state, the history is
essential. Consider a key-value store. Each Paxos instance sets a
single key-value pair. (I will ignore reads as only the write history
matters in this discussion.) Although for the leader and configuration
machines the latest instance captures the entire state, for a
key-value store the instance only captures the most recent write. A
fresh instance of the key-value store potentially needs the complete
history, incorporating every write made to the store, to be brought up
to date. This complete history is provided by a checkpoint.&lt;/p&gt;

&lt;p&gt;To support arbitrary state machines, including those that need more
than the result of the last instance to become up to date, Phxpaxos
must support checkpoints.&lt;/p&gt;

&lt;h3 id=&quot;what-checkpointing-requires&quot;&gt;What checkpointing requires&lt;/h3&gt;

&lt;p&gt;You need the following to record a machine’s state and restore it from
a checkpoint:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A way for a node to detect when its current Paxos instance is far behind the
quorum’s and needs to be sent a checkpoint to bring it up to date. This
is always the case for fresh nodes added to the cluster but a subtle
algorithm is required for an active node that has simply
fallen far behind the others.&lt;/li&gt;
  &lt;li&gt;A way for a node that has determined it needs a checkpoint to request one.&lt;/li&gt;
  &lt;li&gt;A way for a node that has a recent checkpoint to decide to send it
to the requesting node.&lt;/li&gt;
  &lt;li&gt;A way for several eligible nodes with recent checkpoints to decide
which will send its checkpoint to the requesting node. Yes, this is
a consensus algorithm within the larger Paxos consensus.&lt;/li&gt;
  &lt;li&gt;A way for the current node to transmit its checkpoint to the
requesting node, accounting for potential message loss or
corruption by the network.&lt;/li&gt;
  &lt;li&gt;A way for the receiving node to reset the state of all its state
machines to their checkpointed values and then enter the Paxos
negotiations. Note that this may leave the node slightly behind
the latest quorum and it will need to use the standard Paxos
mechanisms for catching up to the quorum.&lt;/li&gt;
  &lt;li&gt;A way to ensure that once a node has completed restoring its state
machines from a checkpoint, it will be able to catch up to the
quorum using Paxos mechanisms and not be so far behind that it
needs a second checkpoint.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;It is worth emphasizing that all this is occurring &lt;em&gt;amidst the ongoing
regular Paxos negotiations&lt;/em&gt;.  Although there are no efficiency
concerns for the node receiving the checkpoint, there must be minimal
effects on the nodes activly participating in the Paxos cluster,
especially the one sending the checkpoint.&lt;/p&gt;

&lt;p&gt;The subtlety and complexity of the above requirements make it easier
to see why checkpointing code might be longer and harder to understand
than might appear at first glance.&lt;/p&gt;

&lt;h2 id=&quot;solving-two-common-paxos-problems&quot;&gt;Solving two common Paxos problems&lt;/h2&gt;

&lt;p&gt;The authors of Phxpaxos took advantage of their generalized state
machine code to solve two problems of generalized Paxos:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Master election: Phxpaxos uses a state machine &lt;code class=&quot;highlighter-rouge&quot;&gt;MasterStateMachine&lt;/code&gt;
(defined in &lt;code class=&quot;highlighter-rouge&quot;&gt;src/master/master_sm.{h,cpp}&lt;/code&gt;) to transition from one
elected master to another.&lt;/li&gt;
  &lt;li&gt;Reconfiguration: Phxpaxos uses a state machine &lt;code class=&quot;highlighter-rouge&quot;&gt;SystemVSM&lt;/code&gt; (defined
in &lt;code class=&quot;highlighter-rouge&quot;&gt;src/config/system_v_sm.{h,cpp}&lt;/code&gt;) to transition from one
configuration of nodes to another.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Both of these state machines are “memoryless”, in that their
most recent instance contains all the history they need to transition
to their next state, so neither of them requires the checkpoint
mechanism.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The abstract definition of replicated state machines is simple but a
production-quality implementation is subtle and complex. The Phxpaoxos
code, which implements Paxos and provides an abstract framework for
implementing replicated state machines whose operations are
coordinated by that Paxos algorithm, spends a third of its code
implementing the state machine framework.&lt;/p&gt;

&lt;p&gt;The state machine framework adds complexity to the Paxos algorithm as
well as adding new code for the abstract state machine classes. Additionally,
although not all state machine implementations require checkpointing,
supporting those that do need checkpoints adds a complicated
checkpoint protocol to the implementation.&lt;/p&gt;

&lt;p&gt;This analysis is not a criticism of the Tencent’s code for
Phxpaxos. Any implementation of general state machines would require
this. The complexity, inherent in the algorithms but concealed by the
abstraction of pseudocode, is revealed when those algorithms are
implemented in detail.&lt;/p&gt;

&lt;p&gt;There have been several alternative designs that aim to manage the
complexity by factoring the design along different lines:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Tencent developed a storage layer implementing a version
of Paxos based on optimistic concurrency. The design is described
in their &lt;a href=&quot;https://www.vldb.org/pvldb/vol10/p1730-lin.pdf&quot;&gt;PaxosStore paper&lt;/a&gt; and the
&lt;a href=&quot;https://github.com/Tencent/paxosstore&quot;&gt;PaxosStore project code&lt;/a&gt; is
open source.  Bear in mind though, that the state machine in
PaxosStore is a direct implementation of a restricted case and not
the general-purpose state machines supported by Phxpaxos.&lt;/li&gt;
  &lt;li&gt;The &lt;a href=&quot;https://raft.github.io/&quot;&gt;Raft consensus algorithm&lt;/a&gt; integrates
the state machine code into the consensus protocol.&lt;/li&gt;
  &lt;li&gt;The
&lt;a href=&quot;http://www.cs.cornell.edu/~taozou/sosp13/tangososp.pdf&quot;&gt;Tango Shared Log&lt;/a&gt;
is a new abstraction that supports implementing distributed data structures.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These alternatives may clarify the implementation of replicated state
machines by aligning the abstraction barriers at different angles but
the underlying complexity remains. Whichever approach you take to
implementing state machines, expect to spend considerable time getting
it correct for the many edge conditions and modes of partial failure.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Applying resilient design to my own systems</title>
   <link href="/2020/02/13/systems-resilience-in-daily-life/"/>
   <updated>2020-02-13T00:00:00-08:00</updated>
   <id>/2020/02/13/systems-resilience-in-daily-life</id>
   <content type="html">&lt;p&gt;When I teach a course in modern distributed systems design, I spend a
lot of time on topics such as engineering for resilience and
automating production processes. It turns out that applying those big
topics in the small matters of my life is a big challenge.&lt;/p&gt;

&lt;h2 id=&quot;some-big-good-ideas&quot;&gt;Some big, good ideas&lt;/h2&gt;

&lt;p&gt;I teach the usual things for such courses, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Test your system resilience and recovery procedures by inducing the failures you most fear
occurring (though Barry O’Reilly advocates &lt;a href=&quot;https://www.se-radio.net/2020/01/episode-396-barry-oreilly-on-antifragile-architecture/&quot;&gt;considering failures that seem impossible&lt;/a&gt;)&lt;/li&gt;
  &lt;li&gt;Establish build pipelines to automate routine procedures&lt;/li&gt;
  &lt;li&gt;Monitor system health and performance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Nothing especially surprising or novel, really.&lt;/p&gt;

&lt;h2 id=&quot;some-local-small-procedures&quot;&gt;Some local, small procedures&lt;/h2&gt;

&lt;p&gt;Within hours of finishing a class, I find myself in a situation in
which one or more of the above principles apply:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Transferring lecture recordings from my phone to the course server,
setting the necessary tags, and publishing the page with the links&lt;/li&gt;
  &lt;li&gt;Maintaining earthquake preparedness in my residence&lt;/li&gt;
  &lt;li&gt;Resorting to one-time backup passwords when my regular
authentication methods are unavailable for some important Web site&lt;/li&gt;
  &lt;li&gt;Configuring regular backups for my laptop&lt;/li&gt;
  &lt;li&gt;Automating the pipeline for taking a diagram from source form to publication&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and many other small-scale maintenance tasks.&lt;/p&gt;

&lt;h2 id=&quot;big-ideas-are-ill-fitted-to-small-slots&quot;&gt;Big ideas are ill-fitted to small slots&lt;/h2&gt;

&lt;p&gt;While uploading the backup, signing on to the important site, and all
those other small things, I hear myself advising my students in class
earlier that day. Really, shouldn’t I do in my own life the
things I counselled them to do in their profession?&lt;/p&gt;

&lt;p&gt;Most times though, the fit is awkward or even altogether impractical. The
reasons vary:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Possible but a lot of work: In the case of uploading lecture audio
files, I am slowly increasing the automation. By the end of the
semester, I might have it down to the absolute minimum of three
clicks and a single command.&lt;/li&gt;
  &lt;li&gt;Consumer tools lack the customization of production tools: The
software I use to record lectures on my phone and the software I
use to draw diagrams restrict my control over the names of files
they produce. Production tools such as logging libraries allow
filenames to be customized to a format that supports further
automated processing whereas the consumer tools require manual filename
adjustment to match conventions.&lt;/li&gt;
  &lt;li&gt;Testing a full disaster response is impractical: It’s one thing
to regularly test that I can restore individual files from backup
(and I do) but it’s impractical to test a full machine
restore. Though writing this post did suggest to me that I ought to
try living an entire day solely using my earthquake preparedness
supplies. That would probably demonstrate some gaps.&lt;/li&gt;
  &lt;li&gt;Why seek out inconvenience? The sheer number of items I would have
to test adds up to considerable effort. Do I want to pursue
even more disruption in my daily activities?&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;so-i-muddle-through&quot;&gt;So I muddle through&lt;/h2&gt;

&lt;p&gt;The principles of stress-testing and resilience engineering are
powerful and worth considering but actually applying them to the
smaller-scale processes of personal life often requires more
resources, of time, money, space, or computing power, than is
justified by the benefits. I adopt such principles as seem practical
and reconsider my choices every so often. Not pursuing these
principles in every applicable case, however small, is not hypocrisy,
rather it is acknowledging that the principles apply at larger scales
than much individual activity.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>"Distributed Systems" are not what they used to be</title>
   <link href="/2020/02/11/meaning-of-distributed-systems/"/>
   <updated>2020-02-11T00:00:00-08:00</updated>
   <id>/2020/02/11/meaning-of-distributed-systems</id>
   <content type="html">&lt;p&gt;The phrase “distributed systems” has had several meanings over the
last 50 years, from a mathematical topic to a style of
engineering practice to a suite of technologies. What can
we learn from these changes and how do we reconcile these
perspectives?&lt;/p&gt;

&lt;h2 id=&quot;the-early-days-1970--1995-algorithms&quot;&gt;The early days (1970–1995): Algorithms&lt;/h2&gt;

&lt;p&gt;The initial work on distributed systems had strong overlap with work
on concurrency and parallism. Indeed, from the perspective of
algorithm correctness, these topics share much in common. Nor was
there a widely-agreed definition of the phrase. The earliest
researchers were mapping this new territory, not altogether sure of
where they were going or how their maps would ultimately be used.&lt;/p&gt;

&lt;p&gt;Although early work included the implementation of groundbreaking
systems such as
&lt;a href=&quot;https://en.wikipedia.org/wiki/Semi-Automatic_Ground_Environment&quot;&gt;SAGE&lt;/a&gt;,
&lt;a href=&quot;https://en.wikipedia.org/wiki/Sabre_(computer_system)&quot;&gt;Sabre&lt;/a&gt;, and
&lt;a href=&quot;https://www.livescience.com/20727-internet-history.html&quot;&gt;ARPANet&lt;/a&gt;,
the work from that era most commonly characterized as
“distributed systems” is a series of classic papers focussed on
algorithms and their correctness. The literature, even in its early
stages, was large and beyond simple summary and I don’t have the
background to survey it fairly. Instead, I will list a few papers that
I have found powerful and influential. The list is not particularly
idiosyncratic, as these papers are also widely cited by others.&lt;/p&gt;

&lt;p&gt;In order of publication:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://lamport.azurewebsites.net/pubs/time-clocks.pdf&quot;&gt;“Time, Clocks, and the Ordering of Events in a Distributed System”&lt;/a&gt;,
Lamport (1978).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/byzantine-generals-problem/&quot;&gt;“The Byzantine Generals Problem”&lt;/a&gt;,
Lamport, Shostak &amp;amp; Pease (1982).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.computer.org/csdl/proceedings-article/focs/1983/542800403/12OmNvAAtFD&quot;&gt;“Randomized Byzantine Generals” (abstract only)&lt;/a&gt;,
Rabin (1983).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://lamport.azurewebsites.net/pubs/chandy.pdf&quot;&gt;“Distributed Snapshots: Determining Global States of Distributed Systems”&lt;/a&gt;,
Chandy &amp;amp; Lamport (1985).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf&quot;&gt;“Impossibility of Distributed Consensus with One Faulty Process”&lt;/a&gt;,
Fischer, Lynch &amp;amp; Paterson (1985).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://pmg.csail.mit.edu/papers/vr.pdf&quot;&gt;“Viewstamped Replication: A New Primary Copy Method to Support Highly-Available Distributed Systems”&lt;/a&gt;,
Oki &amp;amp; Liskov (1988).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cs.utexas.edu/~lorenzo/corsi/cs380d/papers/p225-chandra.pdf&quot;&gt;“Unreliable Failure Detectors for Reliable Distributed Systems”&lt;/a&gt;,
Chandra &amp;amp; Toueg (1996).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf&quot;&gt;“The Part-time Parliament”&lt;/a&gt;,
Lamport (Published 1998, submitted substantially earlier).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://pmg.csail.mit.edu/papers/osdi99.pdf&quot;&gt;“Practical Byzantine Fault Tolerance”&lt;/a&gt;, Castro &amp;amp; Liskov (1999).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This list is not intended to be complete, sufficient, nor up to date.
For learning the practical side of distributed systems, Henry Robinson
(who I wish would resume blogging) has developed a useful starter
guide,
&lt;a href=&quot;http://the-paper-trail.org/blog/distributed-systems-theory-for-the-distributed-systems-engineer/&quot;&gt;“Distributed systems theory for the distributed systems engineer”&lt;/a&gt;
(updated as of 2018).&lt;/p&gt;

&lt;p&gt;The papers can be grouped into categories that highlight their
distinct contributions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Papers that prove fundamental limits on distributed algorithms:
“Time, Clocks, and the Ordering of Events”, “Impossibility of
Distributed Consensus”, and “Unreliable Failure Detectors”.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Papers presenting fundamental algorithms: “Byzantine Generals
Problem”, “Distributed Snapshots”, and “Part-Time Parliament”.
Notably, every one of these was writtten or co-authored by Leslie
Lamport, who was awarded the &lt;a href=&quot;https://amturing.acm.org/award_winners/lamport_1205376.cfm&quot;&gt;2013 Turing Award&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Papers presenting first implementations solving important problems in
distributed systems: “Viewstamped Replication” and “Practical
Byzantine Fault Tolerance”. I think it is significant that both of
these were Ph.D. projects under the supervision of Barbara Liskov, who
was awarded the
&lt;a href=&quot;https://amturing.acm.org/award_winners/liskov_1108679.cfm&quot;&gt;2008 Turing Award&lt;/a&gt;
for these and other contributions.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In summary, during this first period, “distributed systems” referred
to a community concerned with defining fundamental limits, discovering
fundamental algorithms, and demonstrating the feasibility of these
methods via first implementations.&lt;/p&gt;

&lt;h2 id=&quot;the-middle-period-1995--2015-engineering-scalable-systems&quot;&gt;The middle period (1995–2015): Engineering scalable systems&lt;/h2&gt;

&lt;p&gt;Where the “early period” lasted roughly 25 years, the “middle period”
was much shorter, perhaps 10 years, with some overlap of the
“early period”.
The literature for this period is even more voluminous and although I
do believe I have a good knowledge of the key papers, there is neither
time nor space to provide a bibliography anything close to complete. I
will instead list a short sample of papers to illustrate the history
of its development:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://dl.acm.org/doi/book/10.5555/974938&quot;&gt;“A Note on Distributed Computing”&lt;/a&gt;,
Waldo, Wyant, Wallroth &amp;amp; Kendall (1994).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://people.eecs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf&quot;&gt;“Towards Robust Distributed Systems”&lt;/a&gt;,
Brewer (2000).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://static.googleusercontent.com/media/research.google.com/en//archive/mapreduce-osdi04.pdf&quot;&gt;“MapReduce: Simplified Data Processing on Large Clusters”&lt;/a&gt;,
Dean &amp;amp; Ghemawat (2004).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://research.google/pubs/pub33002/&quot;&gt;“Paxos Made Live”&lt;/a&gt;, Chandra,
Griesemer, &amp;amp; Redstone (2007).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.allthingsdistributed.com/2008/12/eventually_consistent.html&quot;&gt;“Eventually Consistent”&lt;/a&gt;,
Vogels (2008).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://www.slideshare.net/parallellabs/dean-keynoteladis2009jeffdean&quot;&gt;“Designs, Lessons, and Advice from Building Large Distributed Systems”&lt;/a&gt;,
Dean (2009).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;https://research.google/pubs/pub40801/&quot;&gt;“The Tail at Scale”&lt;/a&gt;, Dean
&amp;amp; Barroso (2013).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;During this period, attention shifted towards engineering large-scale,
failure-tolerant systems running in a global network of
datacentres. The abstract for the Waldo et al. technical report sets
the tone for the coming ten years:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;These failures
[to support basic requirements of robustness and reliability] have
been masked in the past by the small size of the distributed systems
that have been built. In the enterprise-wide distributed systems
foreseen in the near future, however, such a masking will be
impossible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Eric Brewer’s 2000 talk, a keynote address to the “Principles of
Distributed Computing” conference, emphasized that his company of the
time, an early Web search service, was&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;“Based on scalable cluster and parallel distributed computing
technology”&lt;/li&gt;
  &lt;li&gt;“But [made] very little use of classic DS [Distributed Systems] research”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The talk introduced the CAP “Theorem” but twelve years later Brewer emphasized that
&lt;a href=&quot;https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed/&quot;&gt;“its purpose … was to open the minds of designers to a wider range of systems and tradeoffs”&lt;/a&gt;
rather than to further distributed systems theory.&lt;/p&gt;

&lt;p&gt;The remaining papers sample the development of systems addressing the
interconnected engineering challenges of&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;failure tolerance,&lt;/li&gt;
  &lt;li&gt;geolatency—the lag for round-trip communications across long
distances,&lt;/li&gt;
  &lt;li&gt;consistency,&lt;/li&gt;
  &lt;li&gt;high scalability, and&lt;/li&gt;
  &lt;li&gt;high availability.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The systems in this period were purpose-built by organizations in the
grip of explosive growth. It is emblematic of the shift that
&lt;a href=&quot;https://cis.cornell.edu/career-conversation-tushar-chandra&quot;&gt;T. D. Chandra&lt;/a&gt;, first author of the 1996 paper establishing the
theory of weak failure detectors, is also the lead author of the 2007
paper on the challenges of implementing the Paxos distributed consensus
algorithm in production. Theory into practice, indeed.&lt;/p&gt;

&lt;h2 id=&quot;the-contemporary-view-2015--present-cowabunga-kubernetes&quot;&gt;The contemporary view (2015–present): Cowabunga Kubernetes!&lt;/h2&gt;

&lt;p&gt;The current phase is the inexorable next step, where commercial
organizations package, distribute, and support generalized versions of
the custom solutions from the previous phase. The experimentation of the
early days of large-scale datacentres has settled into established
practice, at least for some common use cases.&lt;/p&gt;

&lt;p&gt;The tool with broadest reach, virtually ubiquitous in both actual
datacentres and discussions about managing them, is Kubernetes. This
third-generation orchestration tool, successor to Google’s Omega and
Borg, manages applications organized around a similarly ubiquitous
technology, containers. Whereas Kubernetes is the clear market winner
to the point where it’s hard to even name an alternative, there are
many contending container technologies, aimed at different but related
levels of the underlying stack. As of this writing, the CNCF Landscape
&lt;a href=&quot;https://landscape.cncf.io/category=container-runtime&amp;amp;format=card-mode&amp;amp;grouping=category&quot;&gt;lists 12 container runtimes&lt;/a&gt;,
including containerd, cri-o, Firecracker, gVisor, and kata. (By the
way: Do their trademark staffs think they have to pay extra for
capital letters?)&lt;/p&gt;

&lt;p&gt;The choice of container runtime is mostly a matter for the platform and
operations staff as, the distinctions between runtimes are near-invisible
to application developers.&lt;/p&gt;

&lt;p&gt;Contemporary discussions of “distributed systems”
centre on the practices of architecting systems to run under
Kubernetes, managing Kubernetes clusters, and cooperating with legacy
systems that remain outside the cluster. Development work focuses on
building out those capacities not well-addressed by the current
release of Kubernetes and related tools.&lt;/p&gt;

&lt;p&gt;It’s a Kubernetes world and we just have to get used to living in it.&lt;/p&gt;

&lt;h2 id=&quot;why-does-this-matter&quot;&gt;Why does this matter?&lt;/h2&gt;

&lt;p&gt;What does this history suggest? On its face, it is a typical
progression from theory to early production use to commoditization as
a family of related products. But I think something has been lost in
the process: an understanding of the inescapable limits mapped by
the early theoretical papers. There is an easy tendency to focus on
the technology, with all its details and constant change, and assume
that it will in turn address those limits.&lt;/p&gt;

&lt;p&gt;That assumption is false. The technology provides mechanisms for
readily building, deploying, and operating such services but the
designs remain as bound as ever within the theoretical limits. That is
what makes these limits &lt;em&gt;fundamental&lt;/em&gt;, after all.&lt;/p&gt;

&lt;p&gt;Engineers often cite Brewer’s CAP Principle as an example of theory
that is widely-applied. Whether we define CAP in terms of Brewer’s
original formulation or the two theorems later
&lt;a href=&quot;https://dl.acm.org/doi/10.1145/564585.564601&quot;&gt;proven by Gilbert and Lynch&lt;/a&gt;,
I find CAP’s relationship to actual practice odd and will write a
future post analyzing that (heavily influenced by
&lt;a href=&quot;https://www.infoq.com/articles/cap-twelve-years-later-how-the-rules-have-changed/&quot;&gt;Brewer’s 2012 reflection&lt;/a&gt;
and &lt;a href=&quot;http://www.cs.umd.edu/~abadi/papers/abadi-pacelc.pdf&quot;&gt;Abadi’s PACELC framework&lt;/a&gt;). For this post, I only say that I do not
see CAP as a fundamental limit that must be explicitly
addressed by designs. Rather, &lt;a href=&quot;/2019/12/31/design-space-2020/&quot;&gt;current engineering practice&lt;/a&gt; will lead
the designer to accommodate CAP as a side-benefit.&lt;/p&gt;

&lt;p&gt;On the other hand, I do see the Fischer, Lynch, and Paterson (1985)
impossibility theorem as fundamental: On realistic distributed systems,
the latency of any consensus algorithm is unbounded. Unfortunately, the
theorem provides no constructive procedure to follow because it is
proved by contradiction. This is typical of impossibility results,
which essentially state that no how much you tweak your algorithm, it
will never match your specification. The FLP result is fundamentally
about reducing your expectations to realistic levels.&lt;/p&gt;

&lt;p&gt;The FLP result constrains the entire system design. When implementing
a system, it is seductive to see a given problem as a local issue,
fixable by local changes to the algorithm. But if the problem is in
fact that you are attempting to circumvent FLP, a local fix simply
pushes the problem elsewhere. The fix displaces the problem rather
than solving it.&lt;/p&gt;

&lt;p&gt;The abstraction and totality of this theorem make it easy to miss when
attending to implementation details. Yet it cannot be ignored. In
future posts, I want to work out how the limitations that the FLP
theorem guarantees in systems might appear as localized
problems and describe how seeing those problems as aspects of FLP can
produce better solutions.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>A strategy for more frequent posts</title>
   <link href="/2020/01/29/increasing-post-frequency/"/>
   <updated>2020-01-29T00:00:00-08:00</updated>
   <id>/2020/01/29/increasing-post-frequency</id>
   <content type="html">&lt;p&gt;I have many incomplete threads on distributed systems. How do I
balance my desire for complete and correct presentations with the need
to post more frequently?&lt;/p&gt;

&lt;p&gt;A year ago, I began two threads on distributed systems. The first
focused on using the TLC model checker (and by extension other model
checkers) to
&lt;a href=&quot;/2018/10/31/exploring-distributed-algorithm-failures-using-tla-toolbox/&quot;&gt;explore failures of distributed algorithms&lt;/a&gt;. Before
I could get far with that, I set it aside to begin a second on representing Howard and
Mortier’s work on generalized distributed consensus in
&lt;a href=&quot;/2019/05/29/distributed-consensus-intro/&quot;&gt;PlusCal and analyzing it using TLC&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I have a related thread that has taken months to begin, guiding
students through the code for
&lt;a href=&quot;/2020/03/08/difficulty-of-state-machines/&quot;&gt;TenCent’s implementation of Paxos&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This spring, teaching distributed systems to professional master’s
students led me to conceive a fourth thread refocusing attention away
from CAP and back to the
&lt;a href=&quot;https://kirkpatricktech.org/2020/02/11/meaning-of-distributed-systems/&quot;&gt;Fischer-Lynch-Paterson impossibility result&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;That’s a lot of dangling thread. Each would require many hours and
many posts. Instead of pursuing any one, I turned instead to writing
shorter, less dense and more tentative posts about topics of immediate
interest, particularly teaching, as that is my primary activity for
the next few months. I wanted to regain the freedom to think aloud,
which I had to restrain while writing posts that aimed for a more
complete statement. However many flaws remain in the published
versions of those posts, I removed many more by repeated passes before
publishing them. The result satisfied me but the process exhausted me
and was partly responsible for my five-month absence from posting.&lt;/p&gt;

&lt;p&gt;In coming posts, I aim to balance between these two styles. In
particular, I will return to those earlier threads but accept some
less precise expressions, in interest of producing drafts to develop
the ideas. Once I have collected enough draft sections, I
may return to do a more polished version, detailed and precise, a more
final form of those ideas.&lt;/p&gt;

&lt;p&gt;Or maybe not, if I judge the first drafts to be good enough. My
personally urgent task is to break my current deadlock by relaxing the
requirement that posts be as close to definitive as I can
make them and instead accepting imperfections as the price of timeliness.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>When are "motivating" images useful in a presentation?</title>
   <link href="/2020/01/25/motivating-images/"/>
   <updated>2020-01-25T00:00:00-08:00</updated>
   <id>/2020/01/25/motivating-images</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;I’m writing this post to clarify my thinking about an issue in
presentation design. I’m using a stream-of-consciousness format,
with little editing. You might want to skip this one if
you are looking for careful, reasoned arguments.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This post considers the style of figures and images that complement
the ones I discussed in the
&lt;a href=&quot;/2020/01/21/figure-failures/&quot;&gt;figure failures&lt;/a&gt; post. Where that post
considered figures that represent concepts geometrically, this post
considers images intended to surprise, inspire, and motivate the
audience. When should I use them? When shouldn’t I use them? Are they
of any use at all?&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;motivating-images&quot;&gt;“Motivating” images&lt;/h2&gt;

&lt;p&gt;Technical blog posts and presentations are rife with humourous
images. They may be popular memes, funny images, or simply beautiful
images such as a sunset. I think the originating examples were the
“Screen Bean” images,&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Screen-Bean-Stick-Figure-Clip-Art-N2.gif&quot; alt=&quot;Blobby abstract humanoid leaping and clicking its heels&quot; /&gt;&lt;br /&gt;
&lt;small&gt;Source:
&lt;cite&gt;&lt;a href=&quot;https://pixy.org/820926/&quot;&gt;Pixy#Org&lt;/a&gt;&lt;/cite&gt;. This version CCO Public Domain
(according to Pixy#Org).&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;which were
&lt;a href=&quot;https://www.newyorker.com/magazine/2001/05/28/absolute-powerpoint&quot;&gt;created by Cathleen Belleville&lt;/a&gt;
for  Microsoft PowerPoint and rapidly became
ubiquitous.&lt;/p&gt;

&lt;p&gt;A more recent (Fall of 2019) example was the “woman yelling at cat”
meme:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Woman-yelling-cat-meme.jpg&quot; alt=&quot;Woman in tears yelling at a cat seated at a dinner table. No, I'm not making this up.&quot; style=&quot;margin-bottom: 0pt;&quot; /&gt;&lt;br /&gt;
&lt;small&gt;Left to right: &lt;a href=&quot;https://www.oprahmag.com/entertainment/a29739536/cat-meme-taylor-armstrong-explained/&quot;&gt;Taylor Armstrong&lt;/a&gt;, Kyle Richards,
&lt;a href=&quot;https://www.instagram.com/smudge_lord/?hl=en&quot;&gt;Smudge The Cat&lt;/a&gt;.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;These images serve serveral rhetorical purposes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;They draw the audience’s eye. Large changes in the visual field
are salient, focussing attention on the locale of the change.&lt;/li&gt;
  &lt;li&gt;They establish a lighthearted mood. This may be particularly
valuable in a context such as conferences where the audience may be
hearing many presentations in a short period.&lt;/li&gt;
  &lt;li&gt;When the images are drawn from a culture shared by both speaker and
audience, they increase the audience’s trust of the speaker.&lt;/li&gt;
  &lt;li&gt;They categorize the slide’s speech act in the manner of question or
explanation marks.&lt;/li&gt;
  &lt;li&gt;They provide visual variety, in contrast to a wall of text.&lt;/li&gt;
  &lt;li&gt;They engage neurological channels distinct from the
language-processing centres, reinforcing the spoken words with
minimal mental overload.&lt;/li&gt;
  &lt;li&gt;They enhance emotional impact.&lt;/li&gt;
  &lt;li&gt;When the audience expects a presentation to have this feature, the
speaker is meeting community norms and establishing membership
in that community.&lt;/li&gt;
  &lt;li&gt;Establish personal style or brand. Some speakers use consistent
themes for images. After multiple presentations, audiences
associate that style with the speaker. Such a style sets a tone for
the talk.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In short, these images are intended to motivate and
inspire the audience rather than inform them.&lt;/p&gt;

&lt;p&gt;For this post, I am going to assume the presenter is using a
slide-based presentation, created by such tools as Microsoft PowerPoint, Apple
Keynote, or OpenOffice Impress.  I acknowledge other formats—I do
not use slides in my own presentations—but the presentations I see
in computing fora are overwhelmingly in the slide style.&lt;/p&gt;

&lt;h2 id=&quot;they-also-pose-risks&quot;&gt;They also pose risks&lt;/h2&gt;

&lt;p&gt;Some items in the above list are guaranteed to occur because they
exploit basic properties of human perception and cognition. Others are
socially mediated. As such, they pose risks for the presenter because
the image may not engender the desired response:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Members of the audience may respond very differently to an image
than the speaker expected. The audience may find an image dated,
inappropriate, or mismatched to the occasion.  The Screen Beans were
widely adopted in part because they removed many cultural
signifiers and reduced the human form to a basic shape.&lt;/li&gt;
  &lt;li&gt;The image may distract the audience by suggesting topics wholy
unrelated to the presentation. This risk is particularly high
because these images are deliberately selected for their
visceral impact, which can be far more engaging than the more
abstruse topics presented by the speaker.&lt;/li&gt;
  &lt;li&gt;They consume lots of slide space, leaving little room for anything
else. A talk format such as the canonical TED Talk, with each
slide featuring an image and single point, may work fine for
emotional or inspirational presentations but is ill-suited to the
more detailed, linear arguments of the technical realm.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;my-current-practice&quot;&gt;My current practice&lt;/h2&gt;

&lt;p&gt;In presentations to class, to professional groups, and in my writing
here, I virtually never use these images. In fact, I didn’t have an
&lt;code class=&quot;highlighter-rouge&quot;&gt;assets/images&lt;/code&gt; subdirectory until the last post, the first that
incorporated inline images.&lt;/p&gt;

&lt;p&gt;My presentations invariably fall in the category of detailed technical
arguments. This is partly because I think that’s where I can best
contribute but is also because I don’t find the inspirational style
very interesting. I’m inherently skeptical of presentations at
technical fora that claim that any single technology or method will
“change everything”. Yet that claim is depressingly common at
conferences.  Everyone wants to be a prophet, few want to redesign
the schedule for cleaning trash from the office. For the same reasons,
I’ve never found much value in TED Talks.&lt;/p&gt;

&lt;p&gt;People reply to me, “So use diagrams that are technically appropriate
but also beautiful”. That is certainly possible, as exemplified by
Eamonn Maguire’s diagrams that I
&lt;a href=&quot;/2020/01/21/figure-failures/&quot;&gt;highlighted in the previous post&lt;/a&gt;, but
that same post also emphasized how difficult it is to create a
representation that is both clear and beautiful under the actual
conditions in which we create presentations.&lt;/p&gt;

&lt;h2 id=&quot;drawing-the-audiences-attention---but-to-what&quot;&gt;Drawing the audience’s attention—but to what?&lt;/h2&gt;

&lt;p&gt;The size of these images, the screen space they occupy, mitigates the
attentional benefits from displaying them. When they are displayed,
the abrupt change in the visual field is sure to get the audience’s
attention. In fact, those moments are the times when the presenter
has, however briefly, the attention of almost everyone in the
audience.&lt;/p&gt;

&lt;p&gt;The image has done its job by pulling the audience away from their
consideration of their imminent lunch or that attractive person in the
next row but what is the audience &lt;em&gt;attending to&lt;/em&gt; in that moment?
Perhaps a vision of a sunset or a meme excerpted from popular
entertainment, with a key transitional phrase, such as, “We can’t have
it both ways!”  or “How do we resolve this?” For audience members
whose minds had drifted from the presentation and were returned by
the sudden visual change, there is no indication of what “both ways”
are in conflict or what we need to “resolve”. Punctuation for an empty
paragraph, vacuous as a row of commas and exclamation points without
intervening words.&lt;/p&gt;

&lt;p&gt;While the audience puzzle over what they may have missed in the prior
slides, the speaker moves on to their next point, the grand resolution
of the dilemma they presented earlier. But the audience members’ minds
are in overload, assimilating the missing past points, the
current point, and whatever relevance a picture of a sunset or
the Jack Nicholson
&lt;a href=&quot;https://www.youtube.com/watch?v=WDpipB4yehk&quot;&gt;“Here’s Johnny!” moment&lt;/a&gt;
might have to the actual topic.&lt;/p&gt;

&lt;p&gt;The presenter used the audience’s eyes to get their minds—but the
power of an image over speech can set those minds off in a direction
unrelated to the presenter’s spoken argument.&lt;/p&gt;

&lt;h2 id=&quot;other-issues&quot;&gt;Other issues&lt;/h2&gt;

&lt;p&gt;Some thoughts in no particular order.&lt;/p&gt;

&lt;h3 id=&quot;images-can-stale-quickly&quot;&gt;Images can stale quickly&lt;/h3&gt;

&lt;p&gt;It takes time to find the right image and it may not stay current for
long. Memes and other topical
references are flimsy—few things have a shelf life as
short as a pop cultural moment. The image that wow’ed em six months
ago might be a tired joke today:&lt;/p&gt;

&lt;script type=&quot;text/javascript&quot; src=&quot;https://ssl.gstatic.com/trends_nrtr/2051_RC11/embed_loader.js&quot;&gt;&lt;/script&gt;
&lt;script type=&quot;text/javascript&quot;&gt; trends.embed.renderExploreWidget(&quot;TIMESERIES&quot;, {&quot;comparisonItem&quot;:[{&quot;keyword&quot;:&quot;mad queen&quot;,&quot;geo&quot;:&quot;US&quot;,&quot;time&quot;:&quot;2019-01-25 2020-01-25&quot;}],&quot;category&quot;:0,&quot;property&quot;:&quot;&quot;}, {&quot;exploreQuery&quot;:&quot;q=mad%20queen&amp;geo=US&amp;date=today 12-m&quot;,&quot;guestPath&quot;:&quot;https://trends.google.com:443/trends/embed/&quot;}); &lt;/script&gt;

&lt;p&gt;And if you have to think a bit to recover the common referent of “mad
queen” in the second week of May, 2019—well, that’s the point.&lt;/p&gt;

&lt;h3 id=&quot;gatling-gun-image-sequences&quot;&gt;Gatling-gun image sequences&lt;/h3&gt;

&lt;p&gt;An image-heavy presentation entails a rapid-fire succession of
disruptions of the primary visual focus. I think the effect will vary
widely across audience members. On the one hand, such presentations
will likely have less focused, coherent content, making them
better-suited to blowsy conference attendees. On the other hand, so
many interruptions would likely disrupt the audience’s tentative
understanding of a subtle, serial line of reasoning.&lt;/p&gt;

&lt;h3 id=&quot;pauses-give-time-to-assimilate&quot;&gt;Pauses give time to assimilate&lt;/h3&gt;

&lt;p&gt;One useful role for a slide with an image and simple text is to pause,
providing an opportunity for the audience to assimilate the material
so far. Creating such a moment requires a delicate touch. The
presenter must keep speaking, stay on topic, yet not say anything so
complex that audience members must spend all their attention on
understanding the speaker, preventing assimilation. For similar
reasons, the displayed slide must also be minimally distracting—with
the definition of “distracting” highly specific to the
context. Finally, the pause should not go on too long, lest the
audience’s attention wander.&lt;/p&gt;

&lt;p&gt;Getting such pauses right is part of the performance aspect of
speaking, requiring in-the-moment decisions.&lt;/p&gt;

&lt;h3 id=&quot;why-speak-rather-than-write&quot;&gt;Why speak rather than write?&lt;/h3&gt;

&lt;p&gt;Ultimately, why do we present ideas orally rather than in writing or
to complement writing? The entirety of this topic would require
several books to unpack and has millenia’s worth of analysis by
writers more qualified than I but I want to consider the localized
issue of how this broader purpose influences the choice to use
“motivating” images.&lt;/p&gt;

&lt;p&gt;A partial list of motivations for speaking:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Shared focus and experience&lt;/li&gt;
  &lt;li&gt;Generate enthusiasm for the written presentation&lt;/li&gt;
  &lt;li&gt;Create an opportunity for interaction&lt;/li&gt;
  &lt;li&gt;Adjust presentation of difficult or commonly-misunderstood topics
in response to audience&lt;/li&gt;
  &lt;li&gt;Reach audiences who won’t read&lt;/li&gt;
  &lt;li&gt;The chance to be the focus of attention&lt;/li&gt;
  &lt;li&gt;Engage the audience through performance&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I am struck by the diversity of these purposes. They emphasize how
different a spoken argument is from a written one. On balance, I think
they argue for the use of “motivating” images, as they highlight
speaking as a performance, which relies on emotional appeal at least
as much as intellectual rigor.&lt;/p&gt;

&lt;h2 id=&quot;synthesis-matching-performance-to-reach&quot;&gt;Synthesis: Matching performance to reach&lt;/h2&gt;

&lt;p&gt;I could continue writing, expanding my scope of consideration
indefinitely. This isn’t a question that can really be answered in any
final way. I think this is enough for now. I’m sure to have
many &lt;em&gt;esprit d’escalier&lt;/em&gt; moments in the weeks after I press “Publish”.
I may make this a thread of posts.&lt;/p&gt;

&lt;p&gt;At this point, I suggest this partial synthesis:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Emotionally persuasive methods such as “motivating” images are
useful so long as they clearly stay within the reach of the original
argument.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;By “reach” I mean the implications supported by the plain argument if
it were presented dispassionately on the page without the supporting
emotional machinery. My complaint against many uses of these
images—again, my canonical example is TED Talks—is that they
exploit the emotional content to extend the speaker’s argument far
beyond any reasonable implication of their original observations. A
partial solution is framed as a total solution. Everyone leaves
feeling better because the monster has apparently been slain when in
fact it has only slowed or shrunk.  These are fine outcomes, more
important than sweeping claims that ultimately prove vacuous, but they
lack the sizzle of supposedly complete solutions.&lt;/p&gt;

&lt;p&gt;It is inappropriate to use motivating images to bait and switch the
audience to accepting an unsupported claim, while they can
appropriately be used to arouse enthusiasm for a more circumscribed
but well-grounded result.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Figure failures (and successes!)</title>
   <link href="/2020/01/21/figure-failures/"/>
   <updated>2020-01-21T00:00:00-08:00</updated>
   <id>/2020/01/21/figure-failures</id>
   <content type="html">&lt;p&gt;Well-designed figures are invaluable for presenting technical detail,
including architectural diagrams, timing diagrams, data visualizations,
category hierarchies, and many other forms. Yet the simplicity and
directness of a successful figure belies the complexity of all the
design decisions underlying it. Those decisions were specific to the
original context. Pulling a figure from that context and inserting it
into a very different context such as lecture slides will likely
fail. This short post lists the many ways that such
appropriation can fail.&lt;/p&gt;

&lt;h2 id=&quot;the-context-preparing-a-talk&quot;&gt;The context: Preparing a talk&lt;/h2&gt;

&lt;p&gt;The need is common, the situation urgent: I am preparing a lecture
on a slippery, abstract concept. A figure’s just the thing for giving
my audience an overview.  But there’s so little time! Preparing a
figure from scratch will take too long.&lt;/p&gt;

&lt;p&gt;No problem. There’s an enormous library of figures on the Internet
already.  Just grab the closest one, drop it at the appropriate point
in the lecture. Problem solved, right?&lt;/p&gt;

&lt;p&gt;Unfortunately, it’s not nearly that simple. A figure that was entirely
adequate in one context may fail when imported into the context of a
lecture.&lt;/p&gt;

&lt;h2 id=&quot;the-problems-figure-failures&quot;&gt;The problems: Figure failures&lt;/h2&gt;

&lt;p&gt;Some ways that figures can fail:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Poor representation of material
    &lt;ul&gt;
      &lt;li&gt;Poor original design&lt;/li&gt;
      &lt;li&gt;Simply wrong&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Poor readability
    &lt;ul&gt;
      &lt;li&gt;Too small fonts or features&lt;/li&gt;
      &lt;li&gt;Insufficient contrast&lt;/li&gt;
      &lt;li&gt;Poor resolution&lt;/li&gt;
      &lt;li&gt;Too large for display&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Unsuited to this context
    &lt;ul&gt;
      &lt;li&gt;Too much detail&lt;/li&gt;
      &lt;li&gt;Wrong focus, aim, goal for this purpose&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Inconsistent with rest of presentation or course
    &lt;ul&gt;
      &lt;li&gt;Inconsistent notation&lt;/li&gt;
      &lt;li&gt;Inconsistent visual style&lt;/li&gt;
      &lt;li&gt;Different definition of terms or concepts&lt;/li&gt;
      &lt;li&gt;Different analytic perspective&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Legally or ethically inappropriate
    &lt;ul&gt;
      &lt;li&gt;Copyright misuse / ownership / difficulty of attribution&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Of course, all these problems could also occur in figures created
expressly for the current presentation, particularly issues of
representation and readability. Representing concepts in a figure is
hard, requiring a multitude of choices whose implications might not be
apparent when they were originally made. Few instructors have training
in graphic design methods and tools and they often have to create
course material in very little time. Maintaining consistency from
class to class and week to week is particularly hard.&lt;/p&gt;

&lt;p&gt;Yet all those problems also arise when choosing a previously-created
figure and are compounded by the additional issues of context,
consistency, and ethics.&lt;/p&gt;

&lt;h2 id=&quot;no-easy-solutions&quot;&gt;No easy solutions&lt;/h2&gt;

&lt;p&gt;I see no ready solutions to this dilemma but I think it is beneficial
to bear these limitations in mind. A figure appropriated from a
different context may introduce more confusion than clarity in the
audience. An image that is insufficiently readable may just be a waste
of time and bore the audience. Be alert to the risks and only use an
appropriated figure when the benefits likely exceed the risks.&lt;/p&gt;

&lt;p&gt;Simple, hand-drawn figures, photographed with a phone or digitized
some other way, may be superior to a more visually polished figure
from another context that risks diluting your message. I am seeing an
increase of hand-drawn figures in presentations, such as the
slide figures of Daniel Smith:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Daniel-Smith-hand-drawn-slide.png&quot; alt=&quot;Hand-drawn slide showing data transfer between Kubernetes client and API Server&quot; /&gt;&lt;br /&gt;
&lt;small&gt;—Slide 17 from &lt;cite&gt;&lt;a href=&quot;https://static.sched.com/hosted_files/kccnceu18/36/Kubernetes-style%20APIs%20of%20the%20future%20draft%205.pdf&quot;&gt;Kubernetes-style APIs of the Future&lt;/a&gt;&lt;/cite&gt;, Daniel Smith,
&lt;a href=&quot;https://events19.linuxfoundation.org/events/kubecon-cloudnativecon-europe-2018/&quot;&gt;Kubecon 2018&lt;/a&gt;.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Note how &lt;em&gt;simple&lt;/em&gt; Smith’s slide is.&lt;/p&gt;

&lt;p&gt;The increased use of hand-drawn figures has lead in turn to the use of
machine-rendered figures and fonts that &lt;em&gt;appear&lt;/em&gt; hand-drawn.  For
example, this figure from
&lt;a href=&quot;https://www.datadoghq.com/blog/the-power-of-tagged-metrics/&quot;&gt;DataDog’s post on tagged metrics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/DataDog-hand-drawn-esthetic.png&quot; alt=&quot;Annotated metric from log, identifying tags&quot; /&gt;&lt;/p&gt;

&lt;p&gt;appears hand-drawn but if you compare occurrences of the same glyph,
such as ‘M’ or ‘A’, they are identical. It is a machine-rendered font designed
with a hand-drawn esthetic. This is fine in its own context but it has
the paradoxical effect of making actual hand-drawn figures appear less
attractive because they cannot match the regularity of their
machine-drawn cousins.&lt;/p&gt;

&lt;h2 id=&quot;an-example-of-good-figure-design&quot;&gt;An example of good figure design&lt;/h2&gt;

&lt;p&gt;I’ll end this post with a shout-out to a shining example of the
benefit of figures drawn expressly to compare and organize the
concepts of an entire book. Tamara Munzner’s principles of
visualization design in
&lt;a href=&quot;https://www.cs.ubc.ca/~tmm/vadbook/&quot;&gt;&lt;em&gt;Visualization Analysis and Design&lt;/em&gt;&lt;/a&gt;
are organized and illustrated by a marvellous sequence of figures by
Eamonn Maguire.  For example, Chapter 3 is introduced by this
visual table:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/Munzner-Visualization-Analysis-and-Design-by-Eamonn-Maguire-fig3-1.png&quot; alt=&quot;Table of Actions (Analyze, Search, and Query) and Targets (All Data, Attributes, Network Data, Spatial Data)&quot; /&gt;&lt;br /&gt;
—&lt;small&gt;Fig. 3.1 from &lt;cite&gt;&lt;a href=&quot;https://www.cs.ubc.ca/~tmm/vadbook/&quot;&gt;Visualization Analysis and
Design&lt;/a&gt;&lt;/cite&gt;. Tamara Munzner, with illustrations by Eamonn Maguire. A K
Peters Visualization Series, CRC Press, 2014. Figure CC BY 4.0 license.&lt;/small&gt;&lt;/p&gt;

&lt;p&gt;Maguire’s figures develop a consistent visual language for the entire
book and her figures brilliantly illustrate Munzner’s ideas without
extraneous detail. Maguire’s name is deservedly on the book’s cover.&lt;/p&gt;

&lt;p&gt;Unfortunately, most of us have neither the resources to hire an
excellent illustrator nor Maguire’s skill to do it
ourselves. Nonetheless, I return to this example again and again for
inspiration of how powerful purpose-built figures can be. Even if I
never match this quality, or never even come close, it is worth aiming
for.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>A class is a story: Fitting content to sessions</title>
   <link href="/2020/01/16/class-as-story/"/>
   <updated>2020-01-16T00:00:00-08:00</updated>
   <id>/2020/01/16/class-as-story</id>
   <content type="html">&lt;p&gt;Any given class is a story. It has a beginning, middle, and end. It
arcs toward a conclusion.  The story can be deliberate and designed or
it can be inadvertent and confused. Ultimately, the story will be
different for everyone in the room. The best that I can do as
instructor is the best any performer can do: Create an environment in
which the audience can participate, hoping that their outcomes
approximate those I had in mind. But what do I do with a prior “story”
when the class I designed for an hour and a half session last year is
scheduled this year for a sesssion of one hour?&lt;/p&gt;

&lt;p&gt;This happens fairly often. Although a fixed-credit class always has
the same number of class hours per week, the layout of those hours
into individual sessions can vary. For a professional graduate class
at the university where I’m currently teaching, the week may be
structured as one three-hour session, two sessions of one and a half
hours, or two asymmetric sessions (two hours followed by one hour,
or one followed by two). Each of these takes the melody of the semester
and inserts rests at different points.&lt;/p&gt;

&lt;p&gt;When I began teaching, I tended to think of a course as a long melody,
from Week 1 to Week 14, the material building from basic
concepts to final, integrative activities. I imagined that I could
slice that melody wherever I needed, fitting it to any particular
year’s class schedule. If I hadn’t done everything I wanted by the end
of one class, I simply resumed the topic at the start of the next.&lt;/p&gt;

&lt;h2 id=&quot;limitations-of-the-long-melody-notion&quot;&gt;Limitations of the “long melody” notion&lt;/h2&gt;

&lt;p&gt;The limitation of my “long melody” notion is that I presumed that the
material could be cut at any point with no loss of learning
outcomes. But now that I’m thinking in terms of the arc of a class, I
see that where I cut makes a big difference. For example, a class
might begin with a question and end with an answer. A good question is
easy to state, readily understood by students at this point in the
course, and yield a memorable answer to wrap up the class with a sense
of completion.&lt;/p&gt;

&lt;p&gt;In this approach, when structuring the class the first time, I would
design the question and class activities together. The question would
shape the material, both topics and level of detail, while the need
to stay true to the material would constrain the choice of
question. If all goes well in the actual class, it would travel from a
sense of curiousity to a feeling of satisfaction.&lt;/p&gt;

&lt;p&gt;Now imagine that the next year, the class session was twice as long. I
could just juxtapose two of the earlier classes. The resulting class
wouldn’t be terrible but it would feel slightly off, particularly at
the join, where there would be a natural end point but the class would
in fact continue, introducing a new question. The sense of completion
from answering the first question would be muted by immediately
introducing a new curiousity. The two questions and their answers
could become confused by the students.&lt;/p&gt;

&lt;p&gt;On the other hand, if the new year required splitting a longer class
into two sessions, the damage would be even worse. There might be no
natural break at the halfway point of the original and at class’s end
the question would only be incompletely answered.&lt;/p&gt;

&lt;h2 id=&quot;how-this-affects-course-design&quot;&gt;How this affects course design&lt;/h2&gt;

&lt;p&gt;These effects are modest but real. I suspect they worsen as the
original class structure is stronger. A mushy class structure will be
less damaged than one with a clear arc. This has the paradoxical
outcome of advantaging weak class designs—whatever their other
limitations, they are the most resistant style to arbitrary changes in
class length.&lt;/p&gt;

&lt;p&gt;I do not have a solution to this. There is much more I could write
about the underlying topics. This post is simply to clarify my
thoughts about an issue that is much in my thoughts as I convert a
course structured around equal-length classes to an asymmetric
structure.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Roles vs. Silos, Contribution vs. Technology</title>
   <link href="/2020/01/14/roles-vs-silos/"/>
   <updated>2020-01-14T00:00:00-08:00</updated>
   <id>/2020/01/14/roles-vs-silos</id>
   <content type="html">&lt;p&gt;With the developing maturity of chaos engineering techniques, I see
people taking the job title, “Chaos Engineer”. Although I think chaos
engineer&lt;em&gt;ing&lt;/em&gt; is a truly useful field based upon important principles,
I am wary of defining one’s job in those terms. It confuses technology
with contribution, creates a silo where we want a role. I prefer a
title like Site/Service Reliability/Resilience Engineer, which
emphasizes the bearer’s contribution to the organization. An SRE may
very well have training in chaos engineering and spend much of their
time using those methods but their role is to improve system
reliability.&lt;/p&gt;

&lt;h2 id=&quot;the-role-of-a-role-framing-activity-as-contribution&quot;&gt;The role of a role: Framing activity as contribution&lt;/h2&gt;

&lt;p&gt;An individual’s role in an organization is defined in terms of the
contribution their activity makes towards the organization’s goals.
The role of a salesperson is to sell a company’s products,
contributing to its profitability. The role of a human resources
professional is to ensure that their organization’s policies are fair
in principle and applied in practice, contributing to an effective
workforce. And the role of someone who uses chaos engineering methods
is certainly not to increase the chaos and dysfunction in their
organization but to inject chaos in a controlled manner, detecting
weak points in the system. Those weak points in turn will be
proactively fixed, reducing the organization’s risk of critical
systems failure.&lt;/p&gt;

&lt;h2 id=&quot;defining-a-job-title-by-techniques-makes-it-a-silo&quot;&gt;Defining a job title by techniques makes it a silo&lt;/h2&gt;

&lt;p&gt;In contrast to defining a job title as a role, defining it by
techniques used and the knowledge required for those techniques
creates a silo.  Only employees with the requisite knowledge can have
that job and the job exists independently of changes in the
organization’s goals. Requirements for prior knowledge can become,
consciously or unconsciously, protective walls for those currently
holding the title, restricting entry by newcomers.&lt;/p&gt;

&lt;p&gt;Such job titles can also confine the employee. If their job title is
one type of technique but they want to expand into using another type,
they must somehow categorize the new type as a variant of the first.&lt;/p&gt;

&lt;h2 id=&quot;the-job-description-matters-more-the-title&quot;&gt;The job description matters more the title&lt;/h2&gt;

&lt;p&gt;In actual practice, the key issue is the job’s description more than
its title. There is a strong path dependence and context specificity
to job titles. New employees enter work in progress and change is
gradual. Whatever the title, I believe that writing the job
description in terms of its underlying purpose, the way this role
contributes to organizational success, is better than a focus on the
bundle of techniques the person in that position uses. Role-based
descriptions serve both organization and employee best.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>What genres of readings should be assigned to Prof. MSc. students?</title>
   <link href="/2020/01/10/readings-in-prof-masters/"/>
   <updated>2020-01-10T00:00:00-08:00</updated>
   <id>/2020/01/10/readings-in-prof-masters</id>
   <content type="html">&lt;p&gt;What sort of materials should students read in a professional MSc.
course in computing science? Journal articles? Research conference
papers? Systems-oriented conference papers? Articles from
practitioner-oriented magazines? Blog posts? Wikipedia entries?
Ultimately, what is the purpose of the readings?&lt;/p&gt;

&lt;p&gt;I use a broad, eclectic range of sources in such courses. In this
post, I articulate my rationale for my choices. The outcome driving
them is preparing the students for the activities and audiences
that they will perform after graduation.&lt;/p&gt;

&lt;h2 id=&quot;activities-graduates-are-preparing-to-perform&quot;&gt;Activities graduates are preparing to perform&lt;/h2&gt;

&lt;p&gt;I think the essential distinction between the goals of an CS
undergraduate degree and those of a CS professional MSc. is what each
strives to develop in their students. Whereas the undergraduate
degree emphasizes development of &lt;em&gt;professional technique&lt;/em&gt;, the
graduate degree emphasizes development of &lt;em&gt;professional judgement&lt;/em&gt;.
Although the majority of such a professional’s time may be spent
exercising techniques, building and testing systems, the majority of
their &lt;em&gt;contribution&lt;/em&gt;—the reason they were hired—will result from
decisions informed by expertise gained through graduate study.&lt;/p&gt;

&lt;h3 id=&quot;activities-exercising-professional-judgement&quot;&gt;Activities exercising professional judgement&lt;/h3&gt;

&lt;p&gt;The activities in which graduates of a CS professional MSc.
program might exercise judgement include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Analyzing prospective designs&lt;/li&gt;
  &lt;li&gt;Assessing the suitability of products (which might well include
open-source products) for current needs&lt;/li&gt;
  &lt;li&gt;Diagnosing malfunctions in current systems&lt;/li&gt;
  &lt;li&gt;Defining requirements and designing systems to address those
requirements&lt;/li&gt;
  &lt;li&gt;Documenting the rationale for an existing design&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The key skills are &lt;em&gt;analyzing&lt;/em&gt; and &lt;em&gt;justifying&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;audiences-for-presentations-of-professional-judgement&quot;&gt;Audiences for presentations of professional judgement&lt;/h3&gt;

&lt;p&gt;The results of the above activities will be presented to one or more
of the following audiences:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Other members of their technical team&lt;/li&gt;
  &lt;li&gt;Technical specialists outside the team, potentially including
outside the organization altogether at fora such as conferences&lt;/li&gt;
  &lt;li&gt;Generalists and specialists in other areas, often including higher
management at the speaker or writer’s own organization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The key presentation skills include providing the &lt;em&gt;right level of
detail&lt;/em&gt; for the audience and &lt;em&gt;addressing the audience’s concerns&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;In addition to the above outward-facing activities, professionals must
also perform the inward-facing activity of ongoing professional
development, staying abreast of recent developments in computing.&lt;/p&gt;

&lt;h2 id=&quot;what-readings-will-prepare-students-for-these-activities-and-audiences&quot;&gt;What readings will prepare students for these activities and audiences?&lt;/h2&gt;

&lt;p&gt;The activities and audiences listed above suggest that the most
appropriate readings will be those focused on the analysis and design
of actual systems, systems in production rather than the smaller
research systems used in research to validate a theoretical construct.
The distinction hinges on the paper scope and intent, not the forum in
which it was published. Many conferences will feature a mix of
academic research that elucidates general principles and papers
describing the design of production systems. Both types can reasonably
be called “research papers” but only one seems appropriate as readings
for a professional master’s course.&lt;/p&gt;

&lt;h3 id=&quot;basic-research-is-ill-matched&quot;&gt;Basic research is ill-matched&lt;/h3&gt;

&lt;p&gt;Basic research in the more systems-oriented areas of computing
science, typically done in universities, most often takes the form of
proposing a design principle that will improve software quality by
some metric (latency, reliability, security, and so forth),
constructing a proof of concept system, and evaluating that system in
a controlled environment. This work is difficult and requires a team
of research assistants, often graduate students, to develop the
software, both the demonstration system and its evaluation
environment. Such projects can often consume one or more
programmer-years.&lt;/p&gt;

&lt;p&gt;Unfortunately, the research papers produced by such projects are not
well-matched to preparing students for professional work. The mismatch
arises on multiple levels:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;em&gt;audience&lt;/em&gt; for these papers is fellow researchers in the same
specialist community. Such communities have specific questions of
interest and specialized practices for answering those questions.&lt;/li&gt;
  &lt;li&gt;The &lt;em&gt;contribution&lt;/em&gt; of these papers is advancing the scientific and
engineering principles for system design.&lt;/li&gt;
  &lt;li&gt;The &lt;em&gt;goal&lt;/em&gt; of these papers is to persuade the audience of
researchers that the contribution is a substantial and validated
advancement of the community’s understanding.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The &lt;em&gt;structure&lt;/em&gt; of the papers requires a comprehensive survey of prior
results, both to demonstrate the authors’ membership in the
community and to justify the novelty of the paper’s
contribution.&lt;/p&gt;

    &lt;p&gt;The structure also requires a formal evaluation under controlled
or at least well-measured and documented conditions.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These are in stark contrast to the activities that the
graduates of a professional master’s program will perform:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Their &lt;em&gt;professional community&lt;/em&gt; is primarily concerned with
delivering software within constraints of time, budget, and team
expertise.&lt;/li&gt;
  &lt;li&gt;Their &lt;em&gt;professional contribution&lt;/em&gt; is meeting the design criteria
within acceptable tolerances.&lt;/li&gt;
  &lt;li&gt;Their &lt;em&gt;success critera&lt;/em&gt; are almost exclusively budget and schedule.&lt;/li&gt;
  &lt;li&gt;The &lt;em&gt;genre&lt;/em&gt; of their proposals and reports is focused on
presenting decision-makers with a select group of the most viable
options, often only two or three options. The author has winnowed
out the obscure, overly risky, or fantastic options. There is no
requirement of comphrehensiveness. Indeed, the overarching goal is
the minimization or management of risk.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Some academic research papers break the mold, pursuing a more
observational approach, such as the University of Toronto team that
&lt;a href=&quot;https://www.usenix.org/system/files/conference/osdi14/osdi14-paper-yuan.pdf&quot;&gt;categorized the sources of failures&lt;/a&gt;
in long-running systems. Such efforts aim to characterize the
strengths and weaknesses of production systems, knowledge that can
directly inform future practice without any period of adaptation from
a proof-of-concept study.&lt;/p&gt;

&lt;h3 id=&quot;system-design-reports-are-a-better-match&quot;&gt;System design reports are a better match&lt;/h3&gt;

&lt;p&gt;Conferences such as the
&lt;a href=&quot;https://www.usenix.org/conferences&quot;&gt;Usenix series&lt;/a&gt; or
&lt;a href=&quot;https://www.vldb.org/&quot;&gt;VLDB&lt;/a&gt; include many contributions from teams
building and running production systems.  These papers typically
include substantial contributions from teams at a large vendor. Some
examples of papers that I have assigned to the benefit of professional
graduate students include:&lt;/p&gt;

&lt;dl class=&quot;dl-indented&quot;&gt;
  &lt;dt&gt;&lt;a href=&quot;http://dl.acm.org.proxy.lib.sfu.ca/citation.cfm?id=1281100.1281103&quot;&gt;Paxos Made Live&lt;/a&gt;&lt;/dt&gt;
  &lt;dd&gt;The complexities of implementing the Paxos algorithm in a
high-volume production environment (Google).&lt;/dd&gt;
  &lt;dt&gt;&lt;a href=&quot;https://www.allthingsdistributed.com/files/p1041-verbitski.pdf&quot;&gt;Amazon Aurora: Design Considerations for High Throughput Cloud-Native Relational Databases&lt;/a&gt;&lt;/dt&gt;
  &lt;dd&gt;Adapting a database design for a managed, high-throughput cloud
environment (Amazon).&lt;/dd&gt;
  &lt;dt&gt;&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=3359656&quot;&gt;File Systems Unfit as Distributed Storage Backends: Lessons From 10 Years of Ceph Evolution&lt;/a&gt;&lt;/dt&gt;
  &lt;dd&gt;The limitations of operating system file stores as backends for a
distributed file system and the advantages of backends purpose-built
to support distributed files (Red Hat).&lt;/dd&gt;
  &lt;dt&gt;&lt;a href=&quot;https://arxiv.org/pdf/1901.04452&quot;&gt;FoundationDB Record Layer: A Multi-Tenant Structured Database&lt;/a&gt;&lt;/dt&gt;
  &lt;dd&gt;A record layer for a database with a huge number of cotenants (Apple).&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;The particular advantage of this genre over reports of principle-driven
basic research is that the authors are reflecting after implementing a
full system, with all the complexities of supporting high throughput,
tolerating faults in both software and hardware, and production
deployment cycles.  The authors are reporting the most salient
lessons from the entire process.&lt;/p&gt;

&lt;p&gt;Such processes of development, deployment, measurement, and hardening
against failure are the processes for which students in a professional
master’s program are being trained and reading “after-action” reports
about actual systems focuses and sharpens the students’
judgement. These papers also exemplify the pinnacle of the writing genre
the students will perform in their career.&lt;/p&gt;

&lt;p&gt;Reading papers such as these is good preparation for the audiences and
activities with which the students will professionally engage.&lt;/p&gt;

&lt;h3 id=&quot;blog-posts-and-long-form-discussion-replies-are-also-valuable&quot;&gt;Blog posts and long-form discussion replies are also valuable&lt;/h3&gt;

&lt;p&gt;A third possible reading source is blog posts, which may be published
on corporate sites such as the
&lt;a href=&quot;https://aws.amazon.com/blogs/architecture/&quot;&gt;AWS Architecture Blog&lt;/a&gt;,
personal sites such as this one,
&lt;a href=&quot;https://pages.github.com/&quot;&gt;GitHub Pages&lt;/a&gt;, or
&lt;a href=&quot;https://medium.com/&quot;&gt;Medium&lt;/a&gt;. A closely-related format is long-form
answers on discussion fora such as &lt;a href=&quot;https://www.quora.com/&quot;&gt;Quora&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;As a genre, blog posts are less complete, less authoritative, more
tentative, and not necessarily as well written as published systems
papers published in reviwed fora. They are written in a personal voice
(though this may be tempered when the author writes on behalf of an
organization) and viewed by both authors and audience not as
authoritative statements but as a first draft of ideas. The audience
is typically from the same community as the author and posts have a
“within-the-family” feel, which can include the sort of nasty
arguments that arise in families.&lt;/p&gt;

&lt;p&gt;Though these qualities impose a higher interpretative burden on the
reader in the form of cross-checking claims and accounting for the
open bias of frankly opinionated writing, posts such as these provide
information unavailable in other formats. They are timely, specific to
context, yet paradoxically in the hands of informed authors can also
provide background and overview lacking in more formal genres that
emphasize novelty and rigour of contribution over informed
recommendation.&lt;/p&gt;

&lt;p&gt;This genre is also likely forms in which students will write
during their careers. Blog posts often serve as an initial form that
builds an author’s confidence and leads to publishing in more formal contexts.&lt;/p&gt;

&lt;h3 id=&quot;articles-in-the-trade-press-and-vendor-white-papers-orient-students&quot;&gt;Articles in the trade press and vendor white papers orient students&lt;/h3&gt;

&lt;p&gt;Articles in the trade press and white papers by product vendors
represent another genre, characterized by a tone of hyperbole and the expectation
of great things to come. Their content can be limited, their charged
language tiring, but they can be useful for orienting students to
current industrial concerns, defining terms, and mapping the
contemporary technical landscape. They can also counterbalance the
longer-term focus of research articles by revealing the more mundane
and dated concerns of production systems outside the charmed circles
of well-funded industrial leaders.&lt;/p&gt;

&lt;h3 id=&quot;discussion-threads-alert-students-to-hot-questions-and-topics&quot;&gt;Discussion threads alert students to “hot” questions and topics&lt;/h3&gt;

&lt;p&gt;Finally, threads in Twitter and Reddit can be limited use. These fora
may more often promote confusion than clarity but they do have merit
for pointing students to recent longer articles of interest and
familiarizing them with current debates.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;There are many sources of readings that can prepare students for
careers as professionals exercising informed judgement. Of these
sources, the genre of a classic research paper incrementally advancing
long-term scientific knowledge, though a staple of academic writing
and reading, is the most poorly-adapted. Refereed reports of system
designs and expert opinions in longer unrefereed fora such as blogs
are a closer match to the reasoning, audience, and concerns to which
graduates of these programs will devote their time. These genres are
also the most likely forms in which the graduates will ultimately
contribute back to their profession. I think such forms should form
the bulk of the assigned readings for students in professional
MSc. programs.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The service design space (2020 Edition)</title>
   <link href="/2019/12/31/design-space-2020/"/>
   <updated>2019-12-31T00:00:00-08:00</updated>
   <id>/2019/12/31/design-space-2020</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Post in an ongoing series on the issues constraining service design
 for datacentres. A previous post presented 2019’s
 version,
 &lt;a href=&quot;/2018/10/13/data-engineering-design-space/&quot;&gt;a design space for data engineering&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Starting January 2020, I will teach a course on service design for
datacentres. The roster indicates that nearly all students will be in
a professional master’s program. Most will be in their second semester
of a program in Big Data, some will be in their fifth semester
(including a two-semester paid internship), with a few in other
programs. What are the key principles that should structure such a course?&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;This will be a revision of the course that I taught in
Spring 2019. I was generally satisfied with that version and do
not want to mess it up through excessive
revision. &lt;a href=&quot;https://robertgreiner.com/the-second-system-effect/&quot;&gt;“Second System Effect”&lt;/a&gt;
is as much an issue in course design as it is in system design.&lt;/p&gt;

&lt;h2 id=&quot;defining-the-course-focus-as-service-design-for-datacentres&quot;&gt;Defining the course focus as “service design for datacentres”&lt;/h2&gt;

&lt;p&gt;I want this course to provide students with the essential skills for
designing and analyzing service-based architectures that will run in
contemporary datacentre environments. This goal is broad, encompassing
both practice using exemplary technologies and the underlying principles.&lt;/p&gt;

&lt;p&gt;I have taught variations of this topic since 2014.  Each year, I have
struggled to define a succinct characterization. There doesn’t seem to
be an accepted term for this material in either the academic or
industrial literatures. Most troubling, I have not found a phrase that
both appeals to students and accurately indicates what they are going
to learn.&lt;/p&gt;

&lt;p&gt;Calling it &lt;strong&gt;“cloud computing”&lt;/strong&gt; sets the wrong expectation. Cloud
computing typically refers to managed services offered by such
providers as Alibaba, Amazon, Google, or Microsoft. These services are
often categorized according to the
&lt;a href=&quot;https://www.bmc.com/blogs/saas-vs-paas-vs-iaas-whats-the-difference-and-how-to-choose/&quot;&gt;Infrastructure-as-a-service (IaaS), Platform-as-a-Service (PaaS), and Application-as-a-Service (AaaS) model&lt;/a&gt;. A
cloud computing course would emphasize that designers should first
consider all the managed service offerings from their chosen provider,
as well as aftermarket providers, before designing a custom
solution. Why build and operate a data store in-house when DynamoDB,
BigTable, or Azure Store could meet your needs?  By contrast, this
course is concerned with how you connect services together and how you
will know when you need to purpose-build your own.&lt;/p&gt;

&lt;p&gt;Calling it &lt;strong&gt;“distributed systems”&lt;/strong&gt; misleads in a different way. Such
courses focus on the design of distributed systems in general, often
with a focus on the correctness and complexity of distributed
algorithms. Nancy Lynch’s 1996
&lt;a href=&quot;https://groups.csail.mit.edu/tds/distalgs.html&quot;&gt;&lt;em&gt;Distributed Algorithms&lt;/em&gt;&lt;/a&gt;
is a common text. This theory provides the essential underpinning of
the material I want to teach but it would take an entire semester to
cover in its own right and the material is not of strong interest to
students in a professional master’s program. This course focuses
instead on the implications of the above theoretical results for actual
system design.&lt;/p&gt;

&lt;p&gt;Last year, I attempted to make the material relevant to Big Data
students by framing it in terms of &lt;strong&gt;“data engineering”&lt;/strong&gt;. This now
seems incomplete to me.  Although descriptions of data engineering
include core concepts from this course:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Most of the issues that you’ll run into will be around reliability
and distributed systems. … you’ll need a system that can
automatically scale your server count up and down … data engineering is about learning to deal with scale and efficiency.&lt;br /&gt;
—&lt;cite&gt;&lt;small&gt;&lt;a href=&quot;https://www.dataquest.io/blog/what-is-a-data-engineer/&quot;&gt;What is a Data Engineer?&lt;/a&gt;&lt;/small&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;[Data engineers] need some understanding of distributed systems in general and
how they are different from traditional storage and processing
systems.&lt;br /&gt;
—&lt;cite&gt;&lt;small&gt;&lt;a href=&quot;https://www.oreilly.com/ideas/data-engineering-a-quick-and-simple-definition&quot;&gt;Data Engineering: A Quick and Simple Definition&lt;/a&gt;&lt;/small&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;the descriptions also list many other topics:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A good data engineer has extensive knowledge on databases and best
engineering practices. These include … building
human-fault-tolerant pipelines, …
knowledge of database administration, maintaining data cleaning,
and ensuring a deterministic pipeline.&lt;br /&gt;
—&lt;cite&gt;&lt;small&gt;&lt;a href=&quot;https://blog.insightdatascience.com/data-science-vs-data-engineering-62da7678adaa&quot;&gt;Data Science vs. Data Engineering&lt;/a&gt;&lt;/small&gt;&lt;/cite&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I would now say that this course is more about the infrastructure
underlying data engineering than data engineering itself.&lt;/p&gt;

&lt;p&gt;Ultimately, I am left with the phrase, &lt;strong&gt;“service design for
datacentres”&lt;/strong&gt;. It has the merit of precisely specifying the course
focus but the oh-so-considerable demerit of being opaque to everyone
else, both prospective students and fellow faculty.&lt;/p&gt;

&lt;h3 id=&quot;the-topic-phrase-comprises-theory-and-practice&quot;&gt;The topic phrase comprises theory and practice&lt;/h3&gt;

&lt;p&gt;So what does “service design for datacentres” imply? Broadly, it is
the design of services intended to run on a network of large-scale
datacentres. A high proportion of modern software involves the
design of such services, from edge computing in embedded devices, to
middleware that processes and stores the data relayed from the edge,
to the interfaces by which end users interact with that data and
administrators manage the services. In the near future, it is likely
that virtually every program written will provide a service interface
to other programs and call other programs through their service
interface, all mediated by networks.&lt;/p&gt;

&lt;p&gt;Most of these programs will
run inside large datacentres. This execution context has major
constraints for the architecture running upon it:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A service will scale by adding or removing replicas&lt;/li&gt;
  &lt;li&gt;A service will need to tolerate failures of services it calls&lt;/li&gt;
  &lt;li&gt;A service will need to be able provide degraded or approximate
service to its callers when it
fails partially&lt;/li&gt;
  &lt;li&gt;A service will have performance objectives, the most important of
which will typically specify permissible latencies&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;service-interface-but-not-necessarily-micro-service&quot;&gt;Service interface but not necessarily &lt;em&gt;micro&lt;/em&gt;-service&lt;/h3&gt;

&lt;p&gt;This does not necessarily imply a microservice architecture. Although
that is an important design choice in contemporary systems, and one
that will be covered in the course, it is ultimately an internal
choice, one of several defensible designs for a given application. The
key points that will characterize virtually all designs are that they
expose their functionality through a service-based interface, hide
their internal decisions behind that interface, and communicate over
a network. The granularity of those components is an implementation choice.&lt;/p&gt;

&lt;h2 id=&quot;student-background&quot;&gt;Student background&lt;/h2&gt;

&lt;p&gt;Most of the students will fit the following profile:&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;Program entry requirements&lt;/dt&gt;
  &lt;dd&gt;Bachelor’s degree in CS or related field.&lt;/dd&gt;
  &lt;dt&gt;Courses students took in prior semesters&lt;/dt&gt;
  &lt;dd&gt;In their first semester, students will already have taken a course
on machine learning and a lab introducing them to technologies of
large-scale data analysis, including HDFS, Hadoop, Spark, Cassandra,
and HBase. Some may have taken electives in visualization or natural
language processing.

    &lt;p&gt;Students taking the course in their second year will have at least
two academic semesters and a two-semester internship behind them.
This group will have taken a range of electives in their second semester.&lt;/p&gt;
  &lt;/dd&gt;
  &lt;dt&gt;Courses students take concurrently&lt;/dt&gt;
  &lt;dd&gt;Concurrently with the data engineering course, they will be taking a
second lab, focussed on applied statistical analysis and machine
learning. They will also be taking an algorithms course including
Paxos and the Gilbert/Lynch CAP Theorem.&lt;/dd&gt;
&lt;/dl&gt;

&lt;h2 id=&quot;approach&quot;&gt;Approach&lt;/h2&gt;

&lt;p&gt;Given the lengthy topic list that follows, the course can only provide
a broad survey, not deep understanding but if the students become
comfortable with these concepts, they will be prepared for a broad
range of roles in modern computing environments.&lt;/p&gt;

&lt;p&gt;The course runs on two tracks:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A tool-based track, introducing  a specific
implementation approach, running
&lt;a href=&quot;https://www.openshift.com/&quot;&gt;Docker&lt;/a&gt; containers on the
&lt;a href=&quot;https://www.openshift.com/&quot;&gt;OpenShift&lt;/a&gt; distribution of
&lt;a href=&quot;https://kubernetes.io/&quot;&gt;Kubernetes&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The principles of designing distributed, resilient services for a
datacentre environment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The tools track is neither in-depth nor exhaustive. It simply
introduces one very large suite of components that is widely used for
implementing services on a datacentre. It is far from the only
approach but the widespread use of Docker and Kubernetes means that
there is a good likelihood that students will be able to immediately
apply their course experiences in their internships that immediately
follow this course.&lt;/p&gt;

&lt;p&gt;The design principles are organized into the following design space.&lt;/p&gt;

&lt;h2 id=&quot;the-design-space-of-cloud-services&quot;&gt;The design space of cloud services&lt;/h2&gt;

&lt;p&gt;Designs can be analyzed according to a variety of criteria. Taken
together, these criteria establish a &lt;em&gt;design space&lt;/em&gt; within which to
evaluate and contrast designs. These properties also establish
measures of system success.&lt;/p&gt;

&lt;p&gt;These properties can be applied to the system as a whole; many also
characterize system components.&lt;/p&gt;

&lt;h2 id=&quot;metrics---measured-properties-of-the-system&quot;&gt;Metrics—measured properties of the system&lt;/h2&gt;

&lt;p&gt;Metrics are measurable properties of the system. They reflect the
match between system architecture and use.&lt;/p&gt;

&lt;p&gt;In addition to learning the following concepts, students need to become familiar
with representing the distributions of metrics via key percentiles
(50th, 75th, 90th, …). Students also need to understand the impact
of “long tail” high percentiles, such as the 99th, on aggregate system
performance.&lt;/p&gt;

&lt;p&gt;Metrics can be part of &lt;a href=&quot;#objectives&quot;&gt;objectives&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;system-performance-metrics&quot;&gt;System performance metrics&lt;/h3&gt;

&lt;p&gt;These metrics characterize the system itself, running on a
representative workload:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency&lt;/li&gt;
  &lt;li&gt;Throughput&lt;/li&gt;
  &lt;li&gt;Scalability&lt;/li&gt;
  &lt;li&gt;Availability&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-centre-fabric-metrics&quot;&gt;Data centre fabric metrics&lt;/h3&gt;

&lt;p&gt;These metrics characterize the design of the data centre:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Processor performance&lt;/li&gt;
  &lt;li&gt;Clock variability&lt;/li&gt;
  &lt;li&gt;Bisection bandwidth&lt;/li&gt;
  &lt;li&gt;Likelihood of component failures&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inter-data-centre-round-trip-metrics&quot;&gt;Inter-data centre round trip metrics&lt;/h3&gt;

&lt;p&gt;For systems running on multiple data centres, perhaps in different
continents, we need to consider the round trip times:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Between availability zones in one region&lt;/li&gt;
  &lt;li&gt;Between regions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;business-metrics&quot;&gt;Business metrics&lt;/h3&gt;

&lt;p&gt;As described in
&lt;a href=&quot;https://www.oreilly.com/webops-perf/free/chaos-engineering.csp&quot;&gt;Chaos Engineering, pp. 22–23&lt;/a&gt;,
business metrics are specific to your application. They measure how
successfully the application is serving clients and meeting its
purpose. The measurement is often indirect, using some metric as a
proxy for the actually desired indicator, such as “real time customer
satisfaction”.  For example, Netflix measures the number of times the
“start” button is pressed per second.  As their service ultimately is
about streaming video, an unexpected drop in start presses indicates
the service is not meeting its purpose.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Specific to application, measuring “service success” or “client
satisfaction” (often indirectly)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;guarantees-and-invariants-inherent-properties-of-the-systems-design&quot;&gt;Guarantees and invariants: Inherent properties of the system’s design&lt;/h2&gt;

&lt;p&gt;Whereas metrics are measurable attributes of a system that can vary with
such factors as system load, properties are fundamental to the
system’s design. For example, the design either replicates durable
data or it does not.&lt;/p&gt;

&lt;h3 id=&quot;data-durability&quot;&gt;Data durability&lt;/h3&gt;

&lt;p&gt;Durable data is stored by the system on behalf of the users, typically
on disk or solid-state storage. What sort of guarantees does the
system provide on this data?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Replication for durability&lt;/li&gt;
  &lt;li&gt;Replication for availability&lt;/li&gt;
  &lt;li&gt;Synchronous vs. asynchronous writes&lt;/li&gt;
  &lt;li&gt;Consistency guarantees&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In principle, consistency guarantees can be made for ephemeral data that only
ever resides in memory but in most cases only eventual consistency
is provided, minimizing processing cost.&lt;/p&gt;

&lt;h3 id=&quot;data-security-and-privacy&quot;&gt;Data security and privacy&lt;/h3&gt;

&lt;p&gt;When a service stores data, the designers must consider what
techniques they will adopt to ensure its security and
privacy. Although these concepts are related and partially overlap, it
is useful to distinguish techniques for each:&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;Security&lt;/dt&gt;
  &lt;dd&gt;Techniques that ensure that data will only be accessed by
authorized individuals and services.&lt;/dd&gt;
  &lt;dt&gt;Privacy&lt;/dt&gt;
  &lt;dd&gt;Techniques that ensure that that data will only be used for
the purposes for which it was granted to the storing service.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;For example, if you provide your address to a service for them to ship
you a product, the service’s &lt;em&gt;security guarantees&lt;/em&gt; would ensure that only
employees in the shipping department could see that address, while
their &lt;em&gt;privacy guarantees&lt;/em&gt; would ensure that the employees who can see your
address would only use it to ship the product, not to send harassing
mail.&lt;/p&gt;

&lt;p&gt;Security and privacy methods include both technical choices and
organizational policy. Ultimately, while the technology can guarantee
that the data will be processed according to rules such as “all
records on persistent storage will be encrypted”, and the policies can
limit access, perfect security and privacy are ideals that can ony be
approached, never achieved. A design establishes barriers to misuse
but sufficiently dedicated individuals with sufficient resources will
always be able to circumvent those barriers.&lt;/p&gt;

&lt;h4 id=&quot;data-security-techniques&quot;&gt;Data security techniques&lt;/h4&gt;

&lt;p&gt;Security techniques include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Encryption, at rest and in transit&lt;/li&gt;
  &lt;li&gt;Key management&lt;/li&gt;
  &lt;li&gt;Key revocation&lt;/li&gt;
  &lt;li&gt;Access roles and rules&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;data-privacy-techniques&quot;&gt;Data privacy techniques&lt;/h4&gt;

&lt;p&gt;Privacy techniques include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Differential privacy&lt;/li&gt;
  &lt;li&gt;Cell size&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;instrumentation&quot;&gt;Instrumentation&lt;/h3&gt;

&lt;p&gt;How well does the system support monitoring its current state and
diagnosing problems:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Logs&lt;/li&gt;
  &lt;li&gt;Traces&lt;/li&gt;
  &lt;li&gt;Dashboards&lt;/li&gt;
  &lt;li&gt;Probes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fault-tolerance&quot;&gt;Fault tolerance&lt;/h3&gt;

&lt;p&gt;How well does the system tolerate failure of its own components and
the services and data centre fabric upon which it depends:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tolerance of component failures within the system&lt;/li&gt;
  &lt;li&gt;Tolerance of failure of external services upon which this depends&lt;/li&gt;
  &lt;li&gt;Tolerance of larger system failures (availability zone, region,
transoceanic partition, …)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How well does it support failure, diagnosis, repair, and restart:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Diagnostic logs&lt;/li&gt;
  &lt;li&gt;Canary deployments&lt;/li&gt;
  &lt;li&gt;Admission control&lt;/li&gt;
  &lt;li&gt;Feature switches&lt;/li&gt;
  &lt;li&gt;Approximate results&lt;/li&gt;
  &lt;li&gt;Other engineering techniques&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;business-logic-invariants&quot;&gt;Business logic invariants&lt;/h3&gt;

&lt;p&gt;Business logic invariants are the business property counterparts to
business metrics:  The guarantees the system makes for entities that
the system’s clients care about.  For example, banks maintain the
invariant that if you transfer money between two accounts, the amount
taken from one equals the amount added to the other.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.researchgate.net/publication/220476881_CAP_Twelve_years_later_How_the_Rules_have_Changed&quot;&gt;Eric Brewer notes&lt;/a&gt;
that many business invariants are only implicitly specified for
single-processor systems, which typically guarantee strong
consistency.  When consistency guarantees are loosened (see
“Properties of durable data” above) to migrate the system to a
distributed implementation, the business invariants need to be
specified explicitly.&lt;/p&gt;

&lt;p&gt;Business invariants often must specify a mitigation procedure, to
resolve any violations (see the Brewer article cited above). For
example, what is the process for redressing an error in an account’s
balance, whether due to system defect or human error?&lt;/p&gt;

&lt;h3 id=&quot;automated-deployment&quot;&gt;Automated deployment&lt;/h3&gt;

&lt;p&gt;In addition to readying the initial release for production, the
service will require automated support for deploying updates.&lt;/p&gt;

&lt;h2 id=&quot;objectives&quot;&gt;Indicators and objectives&lt;/h2&gt;

&lt;p&gt;The above metrics, guarantees, and invariants shape the design space of the
architecture for modern cloud systems.  As such, they are
direct concerns of the the development and operations staff. In
addition, they may be exposed to clients as indicators and
even contractual obligations. 
As defined in
&lt;a href=&quot;https://landing.google.com/sre/book/chapters/service-level-objectives.html&quot;&gt;Site Reliability Engineering, Ch. 4&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Service Level Indicators (SLI)&lt;/li&gt;
  &lt;li&gt;Service Level Objectives (SLO)&lt;/li&gt;
  &lt;li&gt;Service Level Agreements (SLA)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;development-process-metrics&quot;&gt;Development process metrics&lt;/h2&gt;

&lt;p&gt;The above metrics and properties characterize the system’s design and
performance. Other metrics characterize the development process:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Velocity of feature development (&lt;a href=&quot;https://www.oreilly.com/webops-perf/free/chaos-engineering.csp&quot;&gt;Chaos Engineering, p. 9&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;inherent-limitations-of-distributed-systems&quot;&gt;Inherent limitations of distributed systems&lt;/h2&gt;

&lt;p&gt;Decades of study and practice in distributed systems have yielded
principles and rules of thumb characterizing all such
systems. As modern cloud systems are a species of
distributed system, their designers must account for how these issues
arise in this context.&lt;/p&gt;

&lt;p&gt;Properties of distributed systems that must be accounted for (from
&lt;a href=&quot;http://www.cs.mcgill.ca/~navindra/kde-devel/kwn-18/smli_tr-94-29.ps.gz&quot;&gt;Waldo et al., 1994&lt;/a&gt;):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency&lt;/li&gt;
  &lt;li&gt;Message-passing architecture (no shared memory)&lt;/li&gt;
  &lt;li&gt;True concurrency&lt;/li&gt;
  &lt;li&gt;Partial failure (process, service, and machine failure)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;No common system clock
(&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/time-clocks-ordering-events-distributed-system/&quot;&gt;Lamport, 1978&lt;/a&gt;):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Systems must use some variant of &lt;a href=&quot;https://queue.acm.org/detail.cfm?id=2917756&quot;&gt;logical clocks&lt;/a&gt;, vector clocks, or
interval clocks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing&quot;&gt;“The Eight Fallacies of Distributed Computing”&lt;/a&gt;
(rephrased below as statements about how distributed systems &lt;strong&gt;actually&lt;/strong&gt;
work):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The network is unreliable (messages can be out of order or lost, or
connectivity may be dropped altogether).&lt;/li&gt;
  &lt;li&gt;Latency is non-zero.&lt;/li&gt;
  &lt;li&gt;Bandwidth is finite.&lt;/li&gt;
  &lt;li&gt;The network is insecure.&lt;/li&gt;
  &lt;li&gt;Topology changes.&lt;/li&gt;
  &lt;li&gt;There are multiple administrators.&lt;/li&gt;
  &lt;li&gt;Transport cost is non-zero.&lt;/li&gt;
  &lt;li&gt;The network is heterogenous.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The design space for production cloud-based data services is huge. The
service architect and implementation team must trade off between many
conflicting goals and build a service that integrates well with the
operations of the organization as a whole. This design process turns a
robust, accurate data model—the kernel of a service but not an
actual service—into a production service.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>"Awareness" outcomes as preparation for internships</title>
   <link href="/2019/12/16/awareness-outcomes/"/>
   <updated>2019-12-16T00:00:00-08:00</updated>
   <id>/2019/12/16/awareness-outcomes</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; &lt;em&gt;Outside activities interrupted my posting here. Where did those five
months go? I did generate a lot of potential posts on distributed
systems, which I’ll discuss in coming posts. This post focusses
instead on course design, addressing an issue of immediate interest to
me.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I recently discussed course design with some colleagues developing a
required course for a professional masters program. They wanted the course
to address a common concern for such programs: How to increase the
core CS technical skills of students in a program focused on a
specialization outside that core. Of particular concern were students
who do not have undergraduate CS degrees. Although such students bring
valuable experience from other domains, it is at the cost of lacking
the skills developed by long-term, broad study of CS. Even students
who do have such background can benefit from revisiting these
topics. How can we cover so much material in the limited time of a
single course?&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;disentangling-an-overstuffed-course&quot;&gt;Disentangling an overstuffed course&lt;/h2&gt;

&lt;p&gt;The range of possible topics for such a course is far too broad to fit
into a single semester of graduate study but that is the maximum time that
can be spared from the program.
In the interest of confidentiality, I am not going to enumerate the
detailed topic list my colleagues presented. I can say that it
included many of the topics you would expect on a list of
“essential knowledge underlying a professional Master’s in CS”.&lt;/p&gt;

&lt;p&gt;Clearly, there was too much material for detailed instruction in all
topics. We began considering which ones were less important and
might be cut. For example, given five broad areas of concern, focus on
only three and not pursue the two others.&lt;/p&gt;

&lt;p&gt;After some discussion, I proposed an alternative approach: Keep at
least some of the lower-priority topics but define their learning
outcomes to be &lt;em&gt;awareness&lt;/em&gt; rather than &lt;em&gt;competence&lt;/em&gt;.&lt;/p&gt;

&lt;h2 id=&quot;if-we-dont-require-competence-are-we-just-tolerating-in-competence&quot;&gt;If we don’t require “competence” are we just tolerating “in-competence”?&lt;/h2&gt;

&lt;p&gt;What do I mean by not setting some measure of “competence” as a
learning outcome? Am I just setting the tolerance low enough to accept
“incompetent” performance? I believe that rather than a lowering of
standards, my proposal adjusts the course outcomes to take
advantage of two opportunities:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The co-op context of this master’s program, and&lt;/li&gt;
  &lt;li&gt;Stepping outside the
limits imposed by frameworks such as the Bloom taxonomies.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I’m not entirely sure what I mean by these statements. This post is
my attempt to clarify them.&lt;/p&gt;

&lt;h3 id=&quot;building-on-the-benefits-of-co-op&quot;&gt;Building on the benefits of co-op&lt;/h3&gt;

&lt;p&gt;The program under discussion includes a required co-op semester
between the first and second years. A “co-op” semester, short for
“co-operative education semester”, is a three- or six-month salaried
internship at some organization, whether locally in Vancouver or
elsewhere in Canada or the world. This sort of semester, under various
names, is common in professional master’s programs. The semester spent
in a professional work environment is intended to meet several goals:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Students will practice what they have learned in their first year,
applying their skills to actual production systems.&lt;/li&gt;
  &lt;li&gt;Students will learn some rather broadly-defined skills of
“professional practice”.  For this program, such practices include
project management, data governance, and other practices of
individual engineers and engineering organizations.&lt;/li&gt;
  &lt;li&gt;Students will begin a professional network in the organization
and city of their internship, a network that they can build upon when
looking for work after graduation.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These goals are of necessity broad, even to the point of vagueness.
The actual lessons and their effectiveness will vary widely, depending
upon the student and the specific internship. But all internships
provide an important context that is typically impossible in a
classroom: Students will work on projects that existed before
their arrival, that will continue after they leave, that are
integrated with and answerable to the larger goals of an organization,
and whose success has real consequences for that organization.&lt;/p&gt;

&lt;p&gt;That organizational context seems to be an underexploited
resource. Although much of what transpires in a student’s co-op
semester is idiosyncratic and outside the educational institution’s
control, the project context itself, that students will be stepping
into a stream already in flow, is consistent. If we can determine the
parts inherent to that experience and base an educational exercise
on them, we can offload some of the learning outcomes from the core
course to the co-op semester.&lt;/p&gt;

&lt;p&gt;Given that the common elements of all co-ops are organizational, with
wide variation across the technical specifics, these new learning
outcomes should focus on software engineering project practice rather
than the technical specializations of the course work. The
ongoing nature of the project context provides a learning environment
with distinct advantages over the bounded context of a single
classroom semester.&lt;/p&gt;

&lt;p&gt;The program under design already uses the complementary natures of
classroom and co-op experience to provide more rounded learning
outcomes but these outcomes remain broad. How might we focus them to
offload some of the software engineering material from the proposed
core course to the co-op semester?&lt;/p&gt;

&lt;h2 id=&quot;defining-and-assessing-awareness-based-outcomes&quot;&gt;Defining and assessing “awareness”-based outcomes&lt;/h2&gt;

&lt;p&gt;I propose that the core course and the co-op semester be coordinated
to achieve some combined learning outcomes in software engineering and
project management. The core course would prepare the students to be
alert to or aware of selected issues. They would then watch for and
observe these issues as they arise within the context of their co-op
projects. At the conclusion of their co-op, they would write a
structured report, consolidating their observations into insights for
future practice.&lt;/p&gt;

&lt;p&gt;This design requires that the outcomes for each topic be written in
complementary pairs. The outcomes for the core course would prepare
the students to critically observe, while the outcomes for the co-op
report would specify the ultimate learning goals for the topic.&lt;/p&gt;

&lt;p&gt;Although the co-op outcomes could be written using whatever conventions
the design team preferred, such as Bloom’s taxonomy, the
outcomes for the core course seem different, ill-matched to Bloom.
We are not specifying a degree of understanding so much as a degree
of &lt;em&gt;preparedness to observe&lt;/em&gt;.  What form might such outcomes take?&lt;/p&gt;

&lt;h3 id=&quot;working-backwards-from-the-ultimate-outcomes&quot;&gt;Working backwards from the ultimate outcomes&lt;/h3&gt;

&lt;p&gt;The learning outcomes for the co-op semester would set the goals for
the entire sequence. The sequence comprises these distinct activities:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Core course: Do some brief, topic-specific preparation.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Co-op semester: Observe the context of the projects to which they
contribute.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Followup (either at end of co-op or start of following semester):
Reflect on their observations, according to a specified structure.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Given the structured reflection to be performed in Step 3, what
kind of observations in the co-op semester (Step 2) will provide students the
best material? And to prepare for those observations, what activities
do students need to perform in the core course (Step 1)?&lt;/p&gt;

&lt;p&gt;For the co-op experience to provide material for deeper insights,
students should first be prepared to actively observe the practices of
their organization. Such observation must prepare them to notice
missing components as well as those that are present.&lt;/p&gt;

&lt;p&gt;Observation is most effective when active, not passive. Students will
benefit from periodically recording their observations, setting up new
rounds of questions. On the other hand, given that the primary purpose
of the co-op is to deliver value to their employer there are
constraints on what we might expect students to do. Their observations
should:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Not disrupt their assigned projects.&lt;/li&gt;
  &lt;li&gt;Not violate confidentiality requirements.&lt;/li&gt;
  &lt;li&gt;Not intrude on activities of other team members.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In light of these constraints, individual reflection seems the best
approach. Students might fill out periodic checklists or
questionnaires or keep a structured diary. The biggest challenge is
ensuring some form of oversight so that students do the activities at
their scheduled time, rather than deferring them until the end of their co-op.&lt;/p&gt;

&lt;h2 id=&quot;example-data-governance-framework&quot;&gt;Example: Data governance framework&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://searchdatamanagement.techtarget.com/definition/data-governance&quot;&gt;Data governance&lt;/a&gt;
is a topic that is both important to cover and difficult to teach
within the constraints of a classroom, where lessons can readily devolve to
recitation of categories and best practices. Although an instructor
can attempt to provide more direct engagement with the material by
asking the students to analyze case studies, such exercises suffer
from the necessity of presenting the entire context in written form
and lack the urgency of actual stakes.&lt;/p&gt;

&lt;p&gt;By contrast, the co-op semester provides an environment that directly
complements these restrictions because its context is tacit, requiring the
learner to draw it out, and its projects have substantive
consequences.&lt;/p&gt;

&lt;p&gt;Pointing out these differences is nothing new; they form the heart
of longstanding rationales for internships. In this post I am simply
considering what specific style of learning outcomes in the preceding
course will focus the learner’s observations in the co-op semester.&lt;/p&gt;

&lt;h3 id=&quot;data-governance-components&quot;&gt;Data governance components&lt;/h3&gt;

&lt;p&gt;TechTarget’s &lt;a href=&quot;https://searchdatamanagement.techtarget.com/definition/data-governance&quot;&gt;definition
of a data governance framework&lt;/a&gt; includes several components:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;A data governance framework consists of the rules, processes,
organizational structures and technologies that are put into place
as part of a governance program.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The co-op semester provides an opportunity for the learner to practice
identifying these in an actual organization. This identification is
subtle, as some components may be named differently from the names
used in the literature or they may be partial or altogether absent. If
a student were asked to locate these components in the organization in
which they worked their co-op semester, the student might just submit
a rote list of boxes in the organizational chart and policies in the
manual. The student would miss the deeper issues, such as how policies
are enforced and extended or what technological checks enforce the
policies.&lt;/p&gt;

&lt;h3 id=&quot;co-op-activities-to-learn-data-governance&quot;&gt;Co-op activities to learn data governance&lt;/h3&gt;

&lt;p&gt;A simple approach to learning the components of data governance is
least likely to disrupt a student’s co-op schedule.  We might group
the learning into three phases, with one activity in each phase:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Early co-op: Checklist or category list, identifying the components
of the data governance program at the employing organization. The
student identifies the &lt;em&gt;de jure&lt;/em&gt; structure.&lt;/li&gt;
  &lt;li&gt;Middle co-op: Short answers to questions about how the components
work in practice.  The student identifies the &lt;em&gt;de facto&lt;/em&gt; structure.&lt;/li&gt;
  &lt;li&gt;Post co-op: Group discussion, moderated by an instructor, amongst
students after they have returned to campus.  The student
synthesizes the two above, identifying the &lt;em&gt;whole&lt;/em&gt; structure.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;derived-outcomes-for-the-core-course&quot;&gt;Derived outcomes for the core course&lt;/h2&gt;

&lt;p&gt;The activities students will perform during their co-op semester in
turn drive the outcomes for the core course that precedes it. To
prepare for co-op activities such as those suggested above, the core
course outcomes would be straighforward capacities to define and
recognize the components.&lt;/p&gt;

&lt;p&gt;The actual time spent on data governance in the core course would
therefore be small, such as readings of basic governance structure and
a few activities practicing with the checklists and questionnaires
that they will use in the co-op.&lt;/p&gt;

&lt;p&gt;Do these outcomes fit well within the Bloom taxonomy?  On the one
hand, the taxonomy is broad enough that anything can be pressed into
its structure. On the other hand, these outcomes have a distinct quality
resulting from the process that produced them. Rather than defining
outcomes in terms of actions students might take in their ultimate
career, we defined them in terms of the &lt;em&gt;learning activities&lt;/em&gt;
students would perform in the next course. The core course merely
prepares the students for the actual learning that will occur in the
co-op.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Process-oriented topics such as professional practice are ill-matched
to classroom courses. They can consume undue time for too little
benefit. Programs that require a co-op or internship experience might
have better results while consuming less class time by adding
structured activities to the co-op instead of the classroom. The
students would prepare for these activities in a core course before
they begin co-op and reflect on their experience in another course upon
their return. The key point is to define multi-step learning
outcomes, with the actual outcomes defined for the co-op, while the
core course defines outcomes in terms of preparation to learn.&lt;/p&gt;

&lt;p&gt;There are administrative issues that I have not addressed here. The
co-op semesters already have some activities defined by the co-op
department. Adding new activities must be done in cooperation with
that department. The proposed activities further require that someone
review student assignments to ensure timely submission and sincere
attempts. Finally, scheduling a joint return discussion may be
difficult if the students do not all have a common required course upon
return.&lt;/p&gt;

&lt;p&gt;These administrative issues will need careful consideration and
resolving them may require modifying the proposed structure. Those
efforts seem warranted however, as the alternative appproach of
stuffing everything into a single core course is certain to be less
effective.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Why is distributed consensus so hard?</title>
   <link href="/2019/06/12/why-consensus-is-hard/"/>
   <updated>2019-06-12T00:00:00-07:00</updated>
   <id>/2019/06/12/why-consensus-is-hard</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Second in a series describing Howard &amp;amp; Mortier’s generalization of distributed consensus, expressed in PlusCal. The first entry &lt;a href=&quot;/2019/05/29/distributed-consensus-intro/&quot;&gt;introduced the source papers&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Updated &lt;strong&gt;May 27, 2020&lt;/strong&gt; to incorporate points from
  &lt;a href=&quot;https://arxiv.org/abs/2004.05074&quot;&gt;Howard and Mortier (2020)&lt;/a&gt; and
  &lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0304397512009097&quot;&gt;Santos and Schiper (2013)&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I begin this series on distributed consensus by stepping back from
the details, considering why the problem seems so hard and
specifically why literature on the problem is so difficult to read.
This ultimately results from the breadth of issues that must
be addressed by any solution. “Distributed consensus” isn’t a single
problem so much as a class of problems, with related but distinct
solutions. Before describing the specific focus of
Howard and Mortier’s paper, I want to set the broader context. This context
will help readers who want to apply these results to different forms
of consensus.&lt;/p&gt;

&lt;p&gt;So why is distributed consensus so hard, not just to solve, but to even
describe?  Turns out there’s a &lt;em&gt;lot&lt;/em&gt; of reasons.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2 id=&quot;you-cant-get-what-you-really-want&quot;&gt;1. You can’t get what you really want&lt;/h2&gt;

&lt;p&gt;The
&lt;a href=&quot;https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf&quot;&gt;Fischer, Lynch, and Paterson (1985) paper&lt;/a&gt;
presents a fundamental limitation on distributed consensus
algorithms: For realistic levels of reliability, no algorithm can be
guaranteed to complete. In consequence, the algorithms can only make a less
powerful guarantee: Although processes are not guaranteed to complete,
any that do will agree on the same value. In the language of
concurrent programming, the algorithms guarantee &lt;em&gt;safety&lt;/em&gt; but not &lt;em&gt;liveness&lt;/em&gt;.
Careful reliability engineering can make the probability of completion
high but never 100%.&lt;/p&gt;

&lt;h2 id=&quot;the-scope-matters&quot;&gt;2. The scope matters&lt;/h2&gt;

&lt;p&gt;Writers assume different scopes for their articles. Some only consider
the consensus-making processes. Others include the processes that
consume the consensus results. Still others distinguish between
processes that request a consensus and those that consume the results.
Some versions include the option of backup processes whose only role
is to observe and track the decisions but not participate in making
them.&lt;/p&gt;

&lt;h2 id=&quot;there-are-many-ways-of-defining-roles&quot;&gt;3. There are many ways of defining roles&lt;/h2&gt;

&lt;p&gt;Paxos is typically described in terms of a collection of a concurrent,
replicated roles. Each role executes a specific algorithm, typically
comprising an infinite loop consuming messages from
the other roles and sending them replies.&lt;/p&gt;

&lt;p&gt;These roles have been defined in many ways. Some particularly common
roles have been assigned different names, even by the same author at
different times.  For example, in her dissertation Howard names the two key
roles Proposer and Acceptor, while her paper with Mortier names those
same roles Client and Server. Lamport’s
&lt;a href=&quot;https://lamport.azurewebsites.net/pubs/paxos-simple.pdf&quot;&gt;“Paxos Made Simple”&lt;/a&gt;
separates Howard’s Proposer (AKA Client) role into distinct Proposer and
Learner roles.&lt;/p&gt;

&lt;p&gt;The number and names of roles is also affected by the author’s scope.
Altınbüken and van Renesse’s
&lt;a href=&quot;http://paxos.systems/&quot;&gt;“Paxos Made Moderately Complex”&lt;/a&gt; expands the
scope to include Replicas, which consume the consensus results to
execute a replicated state machine algorithm&lt;/p&gt;

&lt;p&gt;The following table correlates the distinct names several authors have
used for similar roles:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Paxos_(computer_science)&quot;&gt;Wikipedia&lt;/a&gt;&lt;/th&gt;
      &lt;th&gt;&lt;a href=&quot;https://understandingpaxos.wordpress.com/&quot;&gt;Cacogne&lt;/a&gt;&lt;/th&gt;
      &lt;th&gt;&lt;a href=&quot;http://paxos.systems/how.html&quot;&gt;Altınbüken &amp;amp; van Renesse&lt;/a&gt;&lt;/th&gt;
      &lt;th&gt;&lt;a href=&quot;https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf&quot;&gt;Lamport (1998)&lt;/a&gt;&lt;/th&gt;
      &lt;th&gt;&lt;a href=&quot;https://lamport.azurewebsites.net/pubs/paxos-simple.pdf&quot;&gt;Lamport (2001)&lt;/a&gt;&lt;/th&gt;
      &lt;th&gt;&lt;a href=&quot;https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-935.pdf&quot;&gt;Howard&lt;/a&gt;&lt;/th&gt;
      &lt;th&gt;&lt;a href=&quot;https://arxiv.org/abs/1902.06776&quot;&gt;Howard &amp;amp; Mortier (2019)&lt;/a&gt;&lt;/th&gt;
      &lt;th&gt;&lt;a href=&quot;https://arxiv.org/abs/2004.05074&quot;&gt;Howard &amp;amp; Mortier (2020)&lt;/a&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Client&lt;/td&gt;
      &lt;td&gt;—&lt;/td&gt;
      &lt;td&gt;Client&lt;/td&gt;
      &lt;td&gt;Citizen&lt;/td&gt;
      &lt;td&gt;—&lt;/td&gt;
      &lt;td&gt;—&lt;/td&gt;
      &lt;td&gt;—&lt;/td&gt;
      &lt;td&gt;—&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Proposer&lt;/td&gt;
      &lt;td&gt;Suggester&lt;/td&gt;
      &lt;td&gt;Leader (including Commander and Scout)&lt;/td&gt;
      &lt;td&gt;President&lt;/td&gt;
      &lt;td&gt;Proposer&lt;/td&gt;
      &lt;td&gt;Proposer&lt;/td&gt;
      &lt;td&gt;Client&lt;/td&gt;
      &lt;td&gt;Leader&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Acceptor&lt;/td&gt;
      &lt;td&gt;Voter&lt;/td&gt;
      &lt;td&gt;Acceptor&lt;/td&gt;
      &lt;td&gt;Priest&lt;/td&gt;
      &lt;td&gt;Acceptor&lt;/td&gt;
      &lt;td&gt;Acceptor&lt;/td&gt;
      &lt;td&gt;Server&lt;/td&gt;
      &lt;td&gt;Follower&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Learner&lt;/td&gt;
      &lt;td&gt;Arbiter&lt;/td&gt;
      &lt;td&gt;Replica&lt;/td&gt;
      &lt;td&gt;—&lt;/td&gt;
      &lt;td&gt;Learner&lt;/td&gt;
      &lt;td&gt;—&lt;/td&gt;
      &lt;td&gt;—&lt;/td&gt;
      &lt;td&gt;—&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Many of the authors also designate a specific
Proposer/Suggester/Client as the “Leader”. The Leader designation
simply indicates priority amongst otherwise identical processes; any
member of that class may be promoted to Leader if the current one
falls short.
Howard &amp;amp; Mortier’s (2020)
reformulation of Paxos using the Raft roles includes a Leader role
of this type, as well as a Candidate role for Followers striving
to become Leaders.
Note however that only one of Altınbüken &amp;amp; van Renesse’s
“Leader”s is a Leader in this sense.&lt;/p&gt;

&lt;p&gt;The correspondences above are not necessarily exact, due to the
differing ways the authors separate Paxos into
roles, but they are close.&lt;/p&gt;

&lt;h2 id=&quot;the-fundamental-concepts-have-multiple-names&quot;&gt;4. The fundamental concepts have multiple names&lt;/h2&gt;

&lt;p&gt;Several times, the consensus literature has suffered the fate of defining
perfectly good terms for basic concepts, only to have the field later
select those same terms to mean something completely different. For
example, Lamport’s original Paxos papers defined “instance” to mean a
single consensual decision. This worked well in the 1990s but in the
intervening years, “instance” has more commonly come to mean
individual virtual machines (such as Amazon EC2 instances) or
individual copies of replicated services. Given that consensus is now
most often used in environments based on cloud technology or
replicated services, this formerly straightforward
nomenclature is now ambiguous.&lt;/p&gt;

&lt;p&gt;Combining these historical redefinitions with the multiplicity of role
names (Point 3 above), we get a nomenclature that is
several times larger than the actual number of concepts it describes.&lt;/p&gt;

&lt;h2 id=&quot;the-basic-algorithm-leaves-many-key-decisions-to-implementation&quot;&gt;5. The basic algorithm leaves many key decisions to implementation&lt;/h2&gt;

&lt;p&gt;The basic consensus algorithm makes a single decision (called “instance” in
the literature), runs on a fixed
set of processes, and makes no guarantee of ever completing. Actual
implementations typically include extensions to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ensure a high probability of completion&lt;/li&gt;
  &lt;li&gt;handle a sequence of decisions, typically using slots or epochs&lt;/li&gt;
  &lt;li&gt;reconfigure the set of participating processes as members fail&lt;/li&gt;
  &lt;li&gt;restore the state of processes recovering from a crash and
initialize the state of
processes added to the configuration&lt;/li&gt;
  &lt;li&gt;garbage collect counters that would otherwise increase without bound&lt;/li&gt;
  &lt;li&gt;reduce message traffic&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0304397512009097&quot;&gt;batch and pipeline&lt;/a&gt; 
requests for lower latency and higher throughput.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Variants of consensus include more or less of these implementation
choices.&lt;/p&gt;

&lt;h2 id=&quot;there-are-several-metrics-of-efficiency&quot;&gt;6. There are several metrics of efficiency&lt;/h2&gt;

&lt;p&gt;The metrics for the efficiency of a consensus algorithm typically
count the number of hops (often counted as round-trips) required to
complete a single decision, rather than its computation or memory
requirements. Within this broad definition remains plenty of room for
variation.&lt;/p&gt;

&lt;p&gt;For example, the scope affects the round trip count. If the scope
includes the ultimate client (which I will refer to in this series as
the “service client”), then the count will include the round trip from
that client to the service endpoint. Including the service client has
more subtle implications than just concatening an extra trip on the
count of a more basic algorithm. Some algorithms, such as Lamport’s
&lt;a href=&quot;http://research.microsoft.com/pubs/64624/tr-2005-112.pdf&quot;&gt;Fast Paxos&lt;/a&gt;,
are designed to allow the service client to bypass the Leader and
propose values directly to the Acceptors, reducing the round
trip count.&lt;/p&gt;

&lt;p&gt;In some use cases, there are different types of round trips, with
different expected latencies.  For example, trips between regions,
with their longer geographic distances, are typically much slower than
trips between datacentres within a region, which in turn are longer
than trips within a single datacentre. For high availability, services
that require consensus algorithms may well use a mix of intra- and
inter-datacentre processes. For these systems, a design might aim to
minimize the more expensive round trips between datacentres.&lt;/p&gt;

&lt;h3 id=&quot;latency-versus-throughput&quot;&gt;Latency versus throughput&lt;/h3&gt;

&lt;p&gt;Performance analysis of consensus algorithms can emphasize latency or
throughput. Latency is directly correlated to the number of
hops on the path of a single request from a service client through
consensus and back—more hops increases the latency. Throughput, on
the other hand, is inversely correlated to the number of messages sent
between participating processes. An algorithm that requires messages
be sent between every participating process will have lower throughput
than one that only requires intercommunication between a fraction of
them, even if both algorithms have the same number of hops in their
paths and hence the same latency.&lt;/p&gt;

&lt;p&gt;Message throughput is limited by network bandwidth and the concurrent
traffic on the same links for other services. Where latency’s limiting
factor, the number of hops, is inherent to the algorithm’s design,
message throughput can be purchased by increasing network capacity or
reducing concurrent traffic.&lt;/p&gt;

&lt;p&gt;In organizational terms, latency and throughput are often different
types of concerns, with latency being a team’s service target and
network bandwidth being a cost they spend to reach that target.&lt;/p&gt;

&lt;h3 id=&quot;coalesced-roles-improve-latency-and-throughput&quot;&gt;Coalesced roles improve latency and throughput&lt;/h3&gt;

&lt;p&gt;Both the latency and throughput of consensus are improved by
coalescing the multiple roles onto single processors. For example,
every role other than “Client” in the Wikipedia column of the above
table may be coalesced onto multiple threads on a processor or even
(using asynchronous, nonblocking IO) a single thread. This eliminates
the messages between roles on that processor but does not reduce the
diameter or complexity of the algorithm, which arise from the
requirement to communicate decisions between the designated Leader and
the Acceptors running on different processors.&lt;/p&gt;

&lt;h3 id=&quot;persistent-writes-may-limit-performance&quot;&gt;Persistent writes may limit performance&lt;/h3&gt;

&lt;p&gt;In addition to message-passing, consensus may be limited by the rate
of persistent writes. Most practical implementations are designed so
that when an Acceptor crashes, it restarts and rejoins the
consensus process. In order to restart, each Acceptor must retain an
essential part of its state in persistent storage. This typically
means writing that state before sending any reply to a request
from the Leader. Cacogne notes (see his
&lt;a href=&quot;https://understandingpaxos.wordpress.com/&quot;&gt;“Constituent Components”&lt;/a&gt;
section) that this is “far and away the biggest performance bottleneck
for most implementations”.&lt;/p&gt;

&lt;p&gt;Most descriptions of consensus algorithms specifically designate the
portion of the Acceptor state that must be persistently retained for
implementations that support restarting after a crash.&lt;/p&gt;

&lt;h3 id=&quot;cpu-utilization-may-limit-performance&quot;&gt;CPU utilization may limit performance&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://www.sciencedirect.com/science/article/pii/S0304397512009097&quot;&gt;Santos and Schiper&lt;/a&gt;
present data (Fig. 7a, Sect. 5.2.1) that for the combination
of small request sizes and relatively high-latency networks (such as
in wide-area networks), the CPU cost of consensus can limit
performance. However, this case seems rarer than those where the
latency of the network or persistent storage limits performance.&lt;/p&gt;

&lt;h2 id=&quot;there-are-several-definitions-of-fault-tolerant&quot;&gt;7. There are several definitions of “fault-tolerant”&lt;/h2&gt;

&lt;p&gt;Distributed consensus is typically used for its fault-tolerance.  But
what kinds of faults must it tolerate?&lt;/p&gt;

&lt;h3 id=&quot;tolerating-crashes&quot;&gt;Tolerating crashes&lt;/h3&gt;

&lt;p&gt;The most basic form of reliability is tolerating crashes. The
classical consensus algorithms tolerate &lt;em&gt;crash-stop&lt;/em&gt; failure, in which
a process either runs correctly or it crashes, never to participate
again. Consensus algorithms are parameterized by &lt;em&gt;f&lt;/em&gt;, the maximum
number of processes that can crash without preventing consensus from
progressing.&lt;/p&gt;

&lt;p&gt;A related but independent form of fault tolerance is &lt;em&gt;crash recovery&lt;/em&gt;:
If a process crashes, it can restart, recover its prior state, and
rejoin the consensus process. If the recovery is fast enough, the
other processes may only observe a longer message reply time. Crash
recovery is not a property of an algorithm, but of its implementation.
As noted above, the choice to support crash recovery makes throughput
of persistent storage a potential performance bottleneck.&lt;/p&gt;

&lt;h3 id=&quot;tolerating-network-errors&quot;&gt;Tolerating network errors&lt;/h3&gt;

&lt;p&gt;Modern networks are well-engineered but
&lt;a href=&quot;https://github.com/aphyr/partitions-post&quot;&gt;outages nonetheless occur&lt;/a&gt;.
There are several types of errors:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Delayed delivery&lt;/li&gt;
  &lt;li&gt;Message loss&lt;/li&gt;
  &lt;li&gt;Out of order delivery&lt;/li&gt;
  &lt;li&gt;Partition: The cluster is divided into two parts that cannot
communicate with each other&lt;/li&gt;
  &lt;li&gt;Duplicate delivery&lt;/li&gt;
  &lt;li&gt;Forgery: A message purports to
originate from a process other than its actual sender&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Classical consensus algorithms are designed to tolerate all of these
but the last. They assume an asynchronous network model, which permits
arbitrarily long message delivery times, which implies not only
delays but also subsumes message loss (the message was delayed long
enough for the prospective recipient to give up) and out of order
delivery (the message sent later had a shorter delay than the one sent
earlier). Although tolerance of duplicate delivery may not be
explicitly specified, widely-used consensus algorithms tolerate them
as well.&lt;/p&gt;

&lt;p&gt;The final sort of network errors, forged messages, are only
correctly handled by the Byzantine-tolerant algorithms described next.&lt;/p&gt;

&lt;h3 id=&quot;tolerating-incorrect-or-hijacked-processes&quot;&gt;Tolerating incorrect or hijacked processes&lt;/h3&gt;

&lt;p&gt;The standard definition of fault tolerance does not protect against a
misbehaving process, which due to a bug or control by malicious
hackers can violate safety requirements. It also does not protect
against message forgery.&lt;/p&gt;

&lt;p&gt;Consensus algorithms that perform reliably in the presence of buggy or
deliberately malicious processes are called &lt;em&gt;Byzantine fault-tolerant&lt;/em&gt;.
&lt;a href=&quot;https://lamport.azurewebsites.net/tla/byzsimple.pdf&quot;&gt;Byzantine fault-tolerant versions of Paxos&lt;/a&gt;
have been developed but they have longer latencies, sustain lower
throughput, and require more processors to achieve a given level of
availability. Unless specifically stated to be so,
consensus algorithms are not Byzantine fault-tolerant.&lt;/p&gt;

&lt;h2 id=&quot;there-is-a-tension-between-clarity-and-practicality&quot;&gt;8. There is a tension between clarity and practicality&lt;/h2&gt;

&lt;p&gt;Descriptions of consensus have to trade off between elegant proofs and
practical algorithms. For example,
&lt;a href=&quot;https://lamport.azurewebsites.net/pubs/lamport-paxos.pdf&quot;&gt;Lamport’s original paper&lt;/a&gt;
develops Paxos sequentially:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mathematicians derived the Synod protocol in a series of steps.
First, they proved results showing that a protocol satisfying
certain constraints would guarantee consistency and allow progress.
A &lt;em&gt;preliminary protocol&lt;/em&gt; was then derived directly from these
constraints. A restricted version of the preliminary protocol
provided the &lt;em&gt;basic protocol&lt;/em&gt; that guaranteed consistency, but not
progress. The complete Synod protocol, satisfying the consistency
and progress requirements, was obtained by restricting the basic
protocol. [pp. 136–137; emphasis in original]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the final step, he extends the Synod protocol into the Parliamentary
protocol, what we now call Multi-Paxos.&lt;/p&gt;

&lt;p&gt;Such sequential reasoning makes for an elegant proof, with the
safety invariants driving the development of the algorithm. But it has
the disadvantage of spreading the logic of the algorithm across
multiple representations. If your goal is to locate an algorithm
suitable for production use, you have to work through the sequence
when what you actually want is the final algorithm, combined with a
systematic presentation of its invariants.&lt;/p&gt;

&lt;h2 id=&quot;descriptions-emphasize-safety-but-not-liveness&quot;&gt;9. Descriptions emphasize safety but not liveness&lt;/h2&gt;

&lt;p&gt;The core purpose of consensus algorithms is ensuring safety: All
processes that complete should agree on a single value. Ensuring
liveness, that the processes are very likely to progress to
completion, is secondary (recall that the FLP Theorem states that no
algorithm can &lt;em&gt;guarantee&lt;/em&gt; completion in the presence of processes
crashing). There are multiple approaches for supporting progress, within
the constraint that they not compromise the invariants upon
which safety depends.&lt;/p&gt;

&lt;p&gt;This provides useful flexibility for the implementor, who can choose
methods most appropriate to their use case. But it can make
descriptions of consensus algorithms incomplete, as a paper may focus
on the safety guarantees and leave techniques for ensuring
progress up to the reader.&lt;/p&gt;

&lt;p&gt;When combined with the clarity/practicality tension described above,
the result can be descriptions that leave the reader far from ready to
implement a system.&lt;/p&gt;

&lt;p&gt;For the sake of completeness, I note that proponents of the Raft
variant of distributed consensus argue that it is more understandable
in part because it
&lt;a href=&quot;https://container-solutions.com/raft-explained-part-1-the-consenus-problem/&quot;&gt;directly incorporates features that are essential for practical use&lt;/a&gt;.
As my goal in this series is to represent ideas from
&lt;a href=&quot;https://arxiv.org/abs/1902.06776&quot;&gt;Howard and Mortier’s paper&lt;/a&gt;, which
focuses on Paxos, I am not going to enter this debate.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Distributed consensus is a rich, complex topic with a long history.
For any single paper the authors must make specific choices of emphasis, from the
scope of functionality, to how the algorithm will be separated into
roles, to how progress will be ensured (if at all), to which
performance metrics will be emphasized, to which faults will be
tolerated, to the number of implementation details described.&lt;/p&gt;

&lt;p&gt;Authors will make different choices, with the result that many papers
describe similar but not quite the same algorithms. Even papers
describing the same algorithm may use different terms and roles,
obscuring their common basis. To best understand a paper, locate the
authors’ context, the choices they have made on the above topics. This
will help connect this paper to others on the topic.&lt;/p&gt;

&lt;p&gt;With the broad context of consensus laid out, in the next post I turn
to the specific goals of Howard and Mortier’s paper.&lt;/p&gt;

&lt;h2 id=&quot;acknowledgements&quot;&gt;Acknowledgements&lt;/h2&gt;

&lt;p&gt;I’d like to acknowledge the strong influence of Tom Cacogne’s
&lt;a href=&quot;https://understandingpaxos.wordpress.com/&quot;&gt;“Understanding Paxos”&lt;/a&gt; on
this post, in particular his early sections providing a high-level
description of Paxos.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Generalized distributed consensus in PlusCal: Introduction</title>
   <link href="/2019/05/29/distributed-consensus-intro/"/>
   <updated>2019-05-29T00:00:00-07:00</updated>
   <id>/2019/05/29/distributed-consensus-intro</id>
   <content type="html">&lt;p&gt;&lt;em&gt;First in a series describing Howard &amp;amp; Mortier’s generalization of
distributed consensus, expressed in PlusCal. The next post describes
&lt;a href=&quot;/2019/06/12/why-consensus-is-hard/&quot;&gt;why consensus is hard&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This post begins a new series, which I expect to interleave with the
&lt;a href=&quot;/2018/10/31/exploring-distributed-algorithm-failures-using-tla-toolbox/&quot;&gt;series on failure tolerance&lt;/a&gt;.
This series is inspired by the recent paper by Heidi Howard and
Richard Mortier,
&lt;a href=&quot;https://arxiv.org/abs/1902.06776&quot;&gt;“A Generalized Solution to Distributed Consensus”&lt;/a&gt;,
which extends results from
&lt;a href=&quot;https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-935.pdf&quot;&gt;Howard’s dissertation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Distributed consensus is a core problem in distributed systems,
applied to use cases ranging from
storing configuration metadata for a replicated, high-availability
service to ensuring consistency in distributed storage systems.
Approaches to distributed consensus include the
&lt;a href=&quot;http://paxos.systems/&quot;&gt;Paxos algorithm&lt;/a&gt;, the
&lt;a href=&quot;https://distributedalgorithm.wordpress.com/2015/06/20/architecture-of-zab-zookeeper-atomic-broadcast-protocol/&quot;&gt;ZAB protocol&lt;/a&gt;,
and the &lt;a href=&quot;https://raft.github.io/&quot;&gt;Raft algorithm&lt;/a&gt;. Although these have
typically been presented as distinct (indeed, Raft was proposed as a
more understandable alternative to Paxos), Howard treats them
all as variants of Paxos.&lt;/p&gt;

&lt;p&gt;There is an enormous literature on Paxos. Three
particularly good starting points are, in order of reading:&lt;/p&gt;

&lt;dl&gt;
  &lt;dt&gt;&lt;a href=&quot;https://understandingpaxos.wordpress.com/&quot;&gt;Tom Cocagne’s “Understanding Paxos”&lt;/a&gt;&lt;/dt&gt;
  &lt;dd&gt;The best starting point for those with a focus on the algorithm’s
application. A gradual introduction to the algorithm, followed by
discussion of the variants most commonly used in production. Cocagne
also has a corresponding Python implementations of
&lt;a href=&quot;https://github.com/cocagne/python-composable-paxos&quot;&gt;the basic algorithm&lt;/a&gt;
and the more complex but higher-performance
&lt;a href=&quot;https://github.com/cocagne/multi-paxos-example&quot;&gt;Multi-Paxos variant&lt;/a&gt;. This
latter code could, with further engineering, serve as a basis for
production use.

    &lt;p&gt;Cocagne’s description and implementations have one important
restriction however: They require a fixed configuration of
replicas. Although his Multi-Paxos code provides for a crashed
replica to restart and catch up, the only way to bring a &lt;em&gt;new&lt;/em&gt;
replica into the configuration is to shut them all down and bring up
a new set including the new replica.  The next paper presents a
version that accommodates this process.&lt;/p&gt;
  &lt;/dd&gt;
  &lt;dt&gt;&lt;a href=&quot;http://paxos.systems/&quot;&gt;Altınbüken and van Renesse’s “Paxos Made Moderately Complex”&lt;/a&gt;&lt;/dt&gt;
  &lt;dd&gt;An excellent second source, this is an interactive version of the
authors’
&lt;a href=&quot;https://dl.acm.org/citation.cfm?id=2673577&quot;&gt;2015 Computing Surveys paper&lt;/a&gt;,
providing a readable presentation of the most commonly-used
production variant, Multi-Paxos with reconfiguration. They include a
Python implementation, although their version is oriented to
demonstration and classroom use.  In particular, the replicas all
run in a single process, communicating via a simulated
network. Unlike Cacogne’s version, this one supports
&lt;em&gt;reconfiguration&lt;/em&gt;, the capacity to replace failing replicas while
the algorithm runs.&lt;/dd&gt;
  &lt;dt&gt;&lt;a href=&quot;https://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-935.pdf&quot;&gt;Howard’s dissertation, “Distributed Consensus Revised”&lt;/a&gt;&lt;/dt&gt;
  &lt;dd&gt;This is a complete, very readable, and systematic introduction to
Paxos and its variants. The first two chapters present the basic
algorithm, while the later ones explore variants and
extensions. Howard’s work extends Paxos, so this paper includes
variations not described in the first two. The paper also provides
proofs of all its results, making it the most formal of the
three. An excellent followup to the the first two, providing a
rigorous background to the consensus problem. No code is
provided—all algorithms are presented in pseudocode.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;All of these include links to other important papers on the topic,
providing a view of the major work in the topic.&lt;/p&gt;

&lt;h2 id=&quot;the-goals-of-this-series&quot;&gt;The goals of this series&lt;/h2&gt;

&lt;p&gt;Given the plethora of existing descriptions, why add another? I do not
aim to present another tutorial—the above three are
sufficient. My focus instead is supplementing them,
particularly in light of the new Howard
and Mortier paper. I want to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Bring the introductions up to date:&lt;/strong&gt; Howard’s doctoral research significantly extended the range of
possible algorithms. Her paper with Mortier further extends this work.
The first two introductions above do not include any of this
work and even the dissertation is slightly out of date.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Present the algorithms precisely, in machine-evaluable form:&lt;/strong&gt; The dissertation and paper present some algorithms in pseudocode
and others solely via informal description. In contrast, a PlusCal representation
is precise and evaluable by a model checker.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Integrate the invariants and algorithms in a common notation:&lt;/strong&gt;
A key contribution of Howard’s work is the isolation of more basic
correctness invariants than those
used in earlier papers. These new
invariants and their use in proofs are
presented separately from the algorithms.  Using
PlusCal, the invariants can instead be
incorporated directly into the algorithms and model checked.&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Provide examples of model checking the algorithms:&lt;/strong&gt; Testing
continuously-running services such as consensus is particularly
difficult. A good test suite should exercise many different
state sequences of the algorithm. For consensus, those alternate
sequences arise due to timing differences.&lt;/p&gt;

    &lt;p&gt;Although generating
alternate timings is hard for an executable program, this is
easy to for a PlusCal algorithm, using the TLC model checker.  For
small model configurations, TLC can test every state exhaustively,
proving correctness of the algorithm for a model of that size. For larger
configurations, TLC can test randomly-selected state
sequences. This latter result is less conclusive than an
exhaustive search but provides more confidence in the algorithm
than testing an executable version.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;some-limitations-of-using-pluscal&quot;&gt;Some limitations of using PlusCal&lt;/h2&gt;

&lt;p&gt;In addition to the advantages described above, representing the
algorithms in PlusCal has disadvantages relative to the pseudocode
used in Howard and Mortier’s paper and Howard’s dissertation:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The PlusCal representation requires a greater level of detail. This
includes both representing system features such as the network, as
well as the exact contents of messages.&lt;/li&gt;
  &lt;li&gt;Given the goal of model-checking the algorithms, the
PlusCal representation will be influenced by choices that make the
checking tractable on small hardware. For example, the detailed network
model that I will present in the initial posts dramatically
increases checking time, while a simplistic network model, which can be
checked more quickly, imposes a restatement of the actual
algorithm. This balance is inherent any time an algorithm is to be
model checked; I introduce it here because it influences choices
throughout the series.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;With that introduction, my next post will describe &lt;a href=&quot;/2019/06/12/why-consensus-is-hard/&quot;&gt;why distributed
consensus can be so challenging&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Simulation checks of the PlusCal version of Lamport's algorithm</title>
   <link href="/2019/05/07/simulation-checks-of-pluscal-lamport/"/>
   <updated>2019-05-07T00:00:00-07:00</updated>
   <id>/2019/05/07/simulation-checks-of-pluscal-lamport</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Fifth in a series on using the TLA Toolbox to explore the failure
 tolerance of distributed algorithms. The previous post was a
 &lt;a href=&quot;/2019/04/15/lamport-algorithm/&quot;&gt;description of Lamport’s 1978 mutual exclusion algorithm&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;My first step when checking a new algorithm is to run a simulation. In
this mode, TLC does not exhaustively search the tree but follows a
single trace up to a maximum depth. The search continues until the
operator cancels it. The assurances provided by such runs are both
broader and more provisional than exhaustive searching: Broader
because I can set simulation traces to proceed much further than those
in an exhaustive search, but more provisional because there is no
assurance that the odd, error-prone corner cases will be checked.&lt;/p&gt;

&lt;p&gt;Simulation runs are useful for their capacity to identify simple
errors due to typos and logical oversights. Exhaustive checks require
some work to set up; there is no point to spending that effort until
after I have some assurance that no easily-found mistakes remain.&lt;/p&gt;

&lt;h2 id=&quot;checking-the-pluscal-version-of-lamports-algorithm&quot;&gt;Checking the PlusCal version of Lamport’s algorithm&lt;/h2&gt;

&lt;p&gt;The specification of a model checking run comprises several parts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The invariants to be checked. These are usually defined in the TLA
code trailing the TLA translation of the PlusCal.&lt;/li&gt;
  &lt;li&gt;An optional view, also defined in the trailing TLA code.&lt;/li&gt;
  &lt;li&gt;The options for the TLC model checker. In the Toolbox, these are
defined in a series of dialogue box panels. In this series, I
represent the options in YAML instead.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;invariants-and-views&quot;&gt;Invariants and views&lt;/h3&gt;

&lt;p&gt;The model checker requires that invariants be defined for
checking.&lt;/p&gt;

&lt;p&gt;For the algorithm to be considered correct, it must maintain two
invariants. The first ensures the correct types of non-temporary
variables, the second ensures that at most one process is ever in the
critical section:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;\* Type invariant
TypeOK ==
  \* Globals
  /\ channel \in [Pid -&amp;gt; [Pid -&amp;gt; Seq(Message)]]
  /\ crit \in SUBSET Pid
  \* Locals
  /\ clock \in [Pid -&amp;gt; ClockVal]
  /\ requests \in [Pid -&amp;gt; [Pid -&amp;gt; ClockVal]]

\* At most one process owning the resource
MutualExclusion == Cardinality(crit) &amp;lt; 2
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Checking can be accelerated by defining a view that excludes temporary
variables from the check.  This reduces the state space explored by
the model checker while ensuring the resulting space covers the
essential states:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;\* Essential variables to be monitored by TLC
View == &amp;lt;&amp;lt;channel, crit, clock, acks, requests, pc&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;parameters-to-the-model-checker&quot;&gt;Parameters to the model checker&lt;/h3&gt;

&lt;p&gt;The TLC parameters defining the actual run are spread across multiple
dialogue box panels (in the Toolbox) or multiple files (when running
TLC from the command line). This makes it hard to keep track of them
all. It also makes it hard to record the parameters for
reproducing the results.&lt;/p&gt;

&lt;p&gt;I instead define the parameters in a YAML file. Ultimately, I intend
to write a Python driver that reads such a file, creates the necessary
configuration files for running the command-line version of TLC, and
runs the check.  For now, I record the parameters here and enter them
into the IDE by hand.&lt;/p&gt;

&lt;p&gt;Notes on two YAML syntax features that may be unfamiliar:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;&amp;gt;&lt;/code&gt; symbol introduces a running text block. Line boundaries are
ignored.&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;|&lt;/code&gt; symbol introduces a preformatted text block. Line boundaries
are preserved, as they are by the HTML &lt;code class=&quot;highlighter-rouge&quot;&gt;PRE&lt;/code&gt; tag.&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;Description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;no&quot;&gt;Simulation run of PlusCal representation of Lamport 1978.&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;Specification&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Behavior&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;Temporal-formula&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Spec&lt;/span&gt;

  &lt;span class=&quot;s&quot;&gt;Definition-overrides&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;ClockVal &amp;lt;- Nat&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Declared-constants&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;N &amp;lt;- 2&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;MaxClock &amp;lt;- 8&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;defaultInitValue &amp;lt;- [model value]&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;Checks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Deadlock&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;false&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Invariants&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;TypeOK&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;MutualExclusion&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;Run-type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Simulation&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;Max-trace-length&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;120&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;Seed&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;3154741148735185214&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;Run-parameters&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Workers&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;2&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3 id=&quot;results-of-the-simulation&quot;&gt;Results of the simulation&lt;/h3&gt;

&lt;p&gt;I ran the simulation for two minutes.  In that time, 19 million states
were explored (some of which might be duplicates):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Time (min)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;States explored&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;9,100,140&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;19,242,611&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The invariants
were preserved in all cases. This does not guarantee correctness
because we cannot estimate how many states remained unexplored.  It
does provide confidence that the code has no “obvious” defects.&lt;/p&gt;

&lt;h2 id=&quot;checking-merzs-tla-representation-of-lamports-algorithm&quot;&gt;Checking Merz’s TLA representation of Lamport’s algorithm&lt;/h2&gt;

&lt;p&gt;For comparison, I ran a comparable simulation on &lt;a href=&quot;https://github.com/tlaplus/Examples/tree/master/specifications/lamport_mutex&quot;&gt;Merz’s original TLA
version&lt;/a&gt; of the algorithm.&lt;/p&gt;

&lt;p&gt;Merz’s safety invariant is slightly different in form but tests the
same property as mine above:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Mutex == \A p,q \in crit : p = q
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I used specifications comparable to the ones above for my PlusCal
version. I inadvertently left the deadlock check on but that had no
effect on the outcome:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;s&quot;&gt;Model-description&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;no&quot;&gt;Simulation run of Merz's TLA representation of Lamport 1978.&lt;/span&gt;
  &lt;span class=&quot;no&quot;&gt;See https://github.com/tlaplus/Examples/tree/master/specifications/lamport_mutex&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;Specification&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Behavior&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;Temporal-formula&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Spec&lt;/span&gt;

  &lt;span class=&quot;s&quot;&gt;Definition-overrides&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;pi&quot;&gt;|&lt;/span&gt;
    &lt;span class=&quot;no&quot;&gt;Clock &amp;lt;- 1 .. 130&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;Model&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Declared-constants:|&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;N &amp;lt;- 2&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;maxClock &amp;lt;- 8&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;Checks&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Deadlock&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;true&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Invariants&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;TypeOK&lt;/span&gt;
    &lt;span class=&quot;pi&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;Mutex&lt;/span&gt;

&lt;span class=&quot;s&quot;&gt;Run-type&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;Simulation&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;Max-trace-length&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;120&lt;/span&gt;
    &lt;span class=&quot;s&quot;&gt;Seed&lt;/span&gt;&lt;span class=&quot;pi&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;692067743782335802&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Merz’s simpler TLA representation allowed TLC to check 37% more states
than for my PlusCal representation, though again a given state may
well have been counted multiple times:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: left&quot;&gt;Time (min)&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;States explored&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;1:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;12,898,239&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: left&quot;&gt;2:00&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;26,229,053&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;These simulation runs demonstrated that this PlusCal
representation of Lamport’s algorith had no basic errors. To increase
our confidence, we need to run exhaustive checks.  Even those will not
prove the algorithm’s correctness in a mathematical sense but full
checks will guarantee that we have checked every state within the
parameters of the run. With that result, we can begin to address
the real topic of this series: exploring how the algorithm fails
when its assumptions are violated.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Lamport's 1978 mutual exclusion algorithm in PlusCal</title>
   <link href="/2019/04/15/lamport-algorithm/"/>
   <updated>2019-04-15T00:00:00-07:00</updated>
   <id>/2019/04/15/lamport-algorithm</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Fourth in a series on using the TLA Toolbox to explore the failure
 tolerance of distributed algorithms. The previous post was a
 &lt;a href=&quot;/2019/01/18/fairness-semantics-of-pluscal/&quot;&gt;specialized discussion of the fairness semantics of PlusCal&lt;/a&gt;. The
 post preceding that was a
 &lt;a href=&quot;/2019/01/03/distributed-algorithms-in-pluscal/&quot;&gt;general discussion of writing distributed algorithms in PlusCal&lt;/a&gt;.
 The next post presents &lt;a href=&quot;/2019/05/07/simulation-checks-of-pluscal-lamport/&quot;&gt;the results of simulation runs&lt;/a&gt; on the algorithm.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The series will be organized around Lamport’s mutual exclusion
algorithm,
&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/time-clocks-ordering-events-distributed-system/&quot;&gt;described in his 1978 paper&lt;/a&gt;.
This algorithm is not so much a primary contribution of that paper as
it is a demonstration of the use of the paper’s main contribution,
logical clocks.  The algorithm is not suited to production use, due to
its assumption of perfect instances communicating over a perfect
network.  Yet these assumptions make it ideal for the purposes of this
series, as we can use TLC to demonstrate how the algorithm fails when
they are violated.&lt;/p&gt;

&lt;p&gt;Stephen Merz contributed a
&lt;a href=&quot;https://github.com/tlaplus/Examples/tree/master/specifications/lamport_mutex&quot;&gt;TLA+ version of the algorithm&lt;/a&gt;
to the
&lt;a href=&quot;https://github.com/tlaplus/Examples/&quot;&gt;TLA example library&lt;/a&gt;. The
version here is derived from his, rewritten in PlusCal and
slightly modified.&lt;/p&gt;

&lt;p&gt;The algorithm, with the bodies of the &lt;code class=&quot;highlighter-rouge&quot;&gt;define&lt;/code&gt;s and macros elided
(they are provided in the Appendix), follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;--------------------- MODULE LogicalClocks ------------------------

(*
  Lamport's mutual exclusion algorithm from &quot;Time, Clocks, and the
  Ordering of Events in a Distributed System&quot;.
  
  The algorithm assumes perfect, in-order message transmission and
  reliable (i.e., non-Byzantine, non-crashing) processes.

  See also the formalization of the same algorithm by Stephan Merz:
  github.com/tlaplus/Examples/tree/master/specifications/lamport_mutex
*)

EXTENDS Naturals, Sequences, FiniteSets, TLC

CONSTANTS N,          \* Number of processes
          MaxClock    \* Maximum clock value

\* -------------------------- Types -------------------------------
\* Process identifier
Pid == 1 .. N
(*
  Range of acceptable clock values
  One more than MaxClock because receiving a message with timestamp
  MaxClock can push a process's clock to MaxClock+1.
*)
ClockVal == 0 .. MaxClock+1
\* A message (with three subtypes)
Message == [time: ClockVal, type: {&quot;Request&quot;, &quot;Release&quot;, &quot;AckReq&quot;}]
\* The 1-1 communication channels between every process
Channel == [src \in Pid |-&amp;gt; [dst \in Pid |-&amp;gt; Seq(Message)]]

(******************************************************************
--algorithm LogicalClocks
variables
  (*--------------------------- Network model----------------------
    Messages in transit between processes.  Messages are guaranteed
    to be delivered in the order in which they were sent.
  *)
  channel = [source \in Pid |-&amp;gt; [destination \in Pid |-&amp;gt; &amp;lt;&amp;lt;&amp;gt;&amp;gt;]],

  (*--------------------------System Model-------------------------
    All processes currently in the critical section
  *)
  crit = {}

\*-----------------------------Operators---------------------------

define
  \* Total order of clocks using Pid to break ties
  LogClockLt(reqs, p, q) == \* ...
  \* All processes whose head msg to dst is of this type
  ChanHead(dst, type) == \* ...
  \* Max of two times
  Max(a, b) == \* ...
end define

\*-----------------------------Network operations------------------

\* Wait for a `type` message and return its contents
macro Receive(type, clock, src, time) begin
\* ...
end macro

\* Broadcast a message
macro Broadcast(clock, msg) begin
\* ...
end macro

\* Send a message to a specific process
macro SendTo(clock, dst, msg) begin
\* ...
end macro

\*-----------------------------System model operations------------

macro EnterCritSec() begin
  crit := crit \union {self}
end macro

macro ExitCritSec() begin
  crit := crit \ {self}
end macro

\*-------------------------------Algorithm------------------------

process Proc \in Pid
variables
  \* --- Algorithm state ---
  \* Logical clock
  clock = 1,
  (*
    The processes that have acknowledged this process's request,
    if it has one
  *)
  acks = {},
  \* Request times this process has received (including its own)
  requests = [pid \in Pid |-&amp;gt; 0],
  \* --- Instrumentation ---
  \* Number of times this process has entered critical section
  ownerships = 0,
  \*--- Temporary variables---untyped, uninitialized
  time,
  src

begin \* process
  loop: while TRUE do
     either
     \* --- Manage this process's entry to crit sect ---
        \* Request ownership
        when requests[self] = 0;
          Broadcast(clock, [time |-&amp;gt; clock, type |-&amp;gt; &quot;Request&quot;]);
          requests := [requests EXCEPT ![self] = clock];
          acks := {self}
     or \* Receive acknowledgement of this process's request
        Receive(&quot;AckReq&quot;, clock, src, time);
          clock := Max(clock, time);
          acks := acks \union {src}          
     or \* If at head of request queue, take ownership
        when /\ self \notin crit
             /\ acks = Pid
             /\ \A p \in Pid: p # self =&amp;gt;
                                  LogClockLt(requests, self, p);
          EnterCritSec();
          ownerships := ownerships + 1
     or \* Release ownership
        when self \in crit;
          requests := [requests EXCEPT ![self] = 0];
          ExitCritSec();
          acks := {};
          Broadcast(clock, [time |-&amp;gt; clock, type |-&amp;gt; &quot;Release&quot;])

     \* --- Record other process' requests to enter crit sect ---
     or \* Receive a request and acknowledge receipt
        Receive(&quot;Request&quot;, clock, src, time);
          requests := [requests EXCEPT ![src] = time];
          clock := Max(clock, time);
          (*
            increment clock in msg to reflect addition that will
            occur at loop's end
          *)
      L2: SendTo(clock, src, [time |-&amp;gt; clock+1, type |-&amp;gt; &quot;AckReq&quot;])
     or \* Receive a release
        Receive(&quot;Release&quot;, clock, src, time);
          clock := Max(clock, time);
          requests := [requests EXCEPT ![src] = 0];
     end either;
     tic: clock := clock + 1
   end while;
end process

end algorithm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The algorithm is written based on conventions for PlusCal I have
developed:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Global variables are never accessed directly but only through
macros&lt;/li&gt;
  &lt;li&gt;Complex, regularly-occurring TLA expressions are given
named &lt;code class=&quot;highlighter-rouge&quot;&gt;define&lt;/code&gt;s&lt;/li&gt;
  &lt;li&gt;Conventional layout for every alternative&lt;/li&gt;
  &lt;li&gt;Categorization of variables by function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first two were detailed in an &lt;a href=&quot;/2019/01/03/distributed-algorithms-in-pluscal/&quot;&gt;earlier post&lt;/a&gt;.
I will describe the last two in more detail next.&lt;/p&gt;

&lt;h2 id=&quot;conventional-layout-for-every-alternative&quot;&gt;Conventional layout for every alternative&lt;/h2&gt;

&lt;p&gt;Lamport’s algorithm follows a
&lt;a href=&quot;/2019/01/03/distributed-algorithms-in-pluscal/&quot;&gt;common structure for distributed algorithms&lt;/a&gt;:
An infinite loop whose body is a list of alternatives, with each
alternative comprising a guard followed by updates to process
variables and messages. To highlight the dependency of the updates on
the guards, I indent the updates a further two spaces from the
guards.&lt;/p&gt;

&lt;p&gt;The guards built from &lt;code class=&quot;highlighter-rouge&quot;&gt;when&lt;/code&gt; statements are pure expressions that do
not modify any state. On the other hand, guards using the network
&lt;code class=&quot;highlighter-rouge&quot;&gt;Receive&lt;/code&gt; macro both wait on a condition and change the global network
state when that condition is satisfied, removing the frontmost message
to the process and returning the id of its sender and its sending time
in the local logical clock as process local variables &lt;code class=&quot;highlighter-rouge&quot;&gt;src&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;time&lt;/code&gt;,
respectively.&lt;/p&gt;

&lt;h2 id=&quot;categorization-of-variables-according-to-function&quot;&gt;Categorization of variables according to function&lt;/h2&gt;

&lt;p&gt;My last PlusCal convention is to categorize the global and local
variables according to distinct functions. I find this makes the
program more readable and I use the language more effectively.&lt;/p&gt;

&lt;p&gt;For global variables:&lt;/p&gt;

&lt;dl class=&quot;dl-indented&quot;&gt;
  &lt;dt&gt;Network model&lt;/dt&gt;
  &lt;dd&gt;Global variables representing the state of the network.&lt;/dd&gt;
  &lt;dt&gt;System model&lt;/dt&gt;
  &lt;dd&gt;Variables that model the state of the system as a whole, apart from
the network. These variables are often used to represent parts of
system state that are implied elsewhere but not directly
represented. Representing these elements of the state as system
model variables allows the analyst to write invariants and
behaviours that check them.

    &lt;p&gt;For example, the global &lt;code class=&quot;highlighter-rouge&quot;&gt;crit&lt;/code&gt; is added to the Lamport algorithm to
indicate the set of all processes in their critical section. In the
formal algorithm, this variable is not used but is only
implied. Making this implied state an explicit global variable
allows the analyst to represent the important safety property that
at most one process is ever in the critical section by the simple
invariant &lt;code class=&quot;highlighter-rouge&quot;&gt;Cardinality(crit) &amp;lt; 2&lt;/code&gt;.&lt;/p&gt;
  &lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;For local variables:&lt;/p&gt;

&lt;dl class=&quot;dl-indented&quot;&gt;
  &lt;dt&gt;Algorithm state&lt;/dt&gt;
  &lt;dd&gt;The state of a distributed algorithm is represented in local
variables (by definition, a distributed algorithm cannot rely on
global state).&lt;/dd&gt;
  &lt;dt&gt;Instrumentation&lt;/dt&gt;
  &lt;dd&gt;Variables used to analyze and debug the algorithm. In this
algorithm, &lt;code class=&quot;highlighter-rouge&quot;&gt;ownerships&lt;/code&gt; counts the number of times a given process
has entered the critical section.&lt;/dd&gt;
  &lt;dt&gt;Temporary variables&lt;/dt&gt;
  &lt;dd&gt;Variables local to individual actions, recording temporary state
rather than the state of the algorithm.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;A PlusCal program also has &lt;em&gt;runtime variables&lt;/em&gt;, implied in the source
code and made explicit by the PlusCal translator in the resulting TLA
code:&lt;/p&gt;

&lt;dl class=&quot;dl-indented&quot;&gt;
  &lt;dt&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt;&lt;/dt&gt;
  &lt;dd&gt;The program counter, indicating the currently-enabled state.  This
is present in the translation of any PlusCal program.&lt;/dd&gt;
  &lt;dt&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;stack&lt;/code&gt;&lt;/dt&gt;
  &lt;dd&gt;The stack of return states and local variable values. This is only
present in translations of PlusCal programs that include one or more &lt;code class=&quot;highlighter-rouge&quot;&gt;procedure&lt;/code&gt;s.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;You can use the distinction between algorithm variables versus
instrumentation and temporary variables to accelerate TLC model
checking using a view. You only need the variables
essential to the system and algorithm’s state, together with any
runtime variables inserted by the PlusCal translator; by not including
the instrumentation or temporaries in the view, you reduce the size of
the state space the checker must explore. For this algorithm, the view
definition includes the network model &lt;code class=&quot;highlighter-rouge&quot;&gt;channel&lt;/code&gt;; the system model
&lt;code class=&quot;highlighter-rouge&quot;&gt;crit&lt;/code&gt;; the algorithm state &lt;code class=&quot;highlighter-rouge&quot;&gt;clock&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;acks&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;requests&lt;/code&gt;; and
the runtime variable &lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;\* Essential variables to be monitored by TLC
View == &amp;lt;&amp;lt;channel, crit, clock, acks, requests, pc&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2 id=&quot;the-algorithm&quot;&gt;The algorithm&lt;/h2&gt;

&lt;p&gt;The basics of the algorithm are described in Lamport’s paper, so I
will not repeat them here. The basic structure is an infinite loop
with an &lt;code class=&quot;highlighter-rouge&quot;&gt;either&lt;/code&gt; selecting between six alternatives. I have structured
this version so that the first four alternatives deal with the
successive stages of a process using the critical section (request
ownership, receive an acknowledgement that another process has
received that request, take ownership when it’s this process’s turn,
release ownership), followed by the two alternatives for processing
requests from other processes (acknowledge receipt of a request,
record an ownership release).&lt;/p&gt;

&lt;p&gt;All of the alternatives but one are a single, atomic action.  The
lone exception is the action to record a request from another
process. Because that action requires both receipt of the request
message and sending of an acknowledgement message, the &lt;code class=&quot;highlighter-rouge&quot;&gt;channel&lt;/code&gt; variable in the
network model is updated twice. Consecutive assignments to the same
variable have to occur in different steps, so the statement sending
the reply must be prefixed by a label, &lt;code class=&quot;highlighter-rouge&quot;&gt;L2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The extra label is an artifact of my use of macros. If the step were
written instead using basic PlusCal, the two updates to &lt;code class=&quot;highlighter-rouge&quot;&gt;channel&lt;/code&gt;
could be merged and the step would become atomic. I think the macros
substantially improve readability of the code, readability that is not
worth giving up for modest gains in speed of model checking from
removing the extra state.  Furthermore, as the series proceeds I will
take advantage of the macros to insert failure testing without
modifying the text of the algorithm.&lt;/p&gt;

&lt;h3 id=&quot;instrumentation&quot;&gt;Instrumentation&lt;/h3&gt;

&lt;p&gt;In addition to the variables essential for the process, 
this version has some modest instrumentation.  The &lt;code class=&quot;highlighter-rouge&quot;&gt;Print&lt;/code&gt; macro
displays the current process’s state on the TLC console. The
&lt;code class=&quot;highlighter-rouge&quot;&gt;PrintDebug&lt;/code&gt; TLA operator specified in the &lt;code class=&quot;highlighter-rouge&quot;&gt;define&lt;/code&gt; statement controls
whether the macro actually prints. The default is not to print but it
can be overridden in the TLC console for specific runs.&lt;/p&gt;

&lt;p&gt;The process also includes a variable &lt;code class=&quot;highlighter-rouge&quot;&gt;ownerships&lt;/code&gt; that records the number
of times this process has entered the critical section. This can be
output via the &lt;code class=&quot;highlighter-rouge&quot;&gt;Print&lt;/code&gt; macro, although none of the current macro calls
include the variable.&lt;/p&gt;

&lt;h3 id=&quot;assumptions&quot;&gt;Assumptions&lt;/h3&gt;

&lt;p&gt;The algorithm assumes an idealized system, in which processes never
fail and all messages are delivered in order. Although these
assumptions are fine for its intended use in the original paper, where
it served as an example of the style of reasohing about distributed
clocks that Lamport presented, these assumptions make it of only the
most limited practical use. I cannot imagine many actual
message-passing environments 
where no process will ever fail and message delivery is
perfect. Perhaps some of the MPI-based systems used in the High
Performance Computing community are that reliable but in the community
building high-throughput distributed systems for modern datacentres,
designers are taught to expect
&lt;a href=&quot;https://www.oreilly.com/webops-perf/free/chaos-engineering.csp&quot;&gt;processes to fail&lt;/a&gt;
and
&lt;a href=&quot;http://dl.acm.org/citation.cfm?id=2663191.2643130&quot;&gt;networks to be unreliable&lt;/a&gt;.
I do not see how any new layer, whether below or above the Lamport
algorithm, could allow the algorithm to maintain safety in the
presence of these errors.&lt;/p&gt;

&lt;h2 id=&quot;testing-the-algorithms-behaviour&quot;&gt;Testing the algorithm’s behaviour&lt;/h2&gt;

&lt;p&gt;The next step is to run the algorithm in the TLC model checker.  With
that baseline established, I will begin running the
algorithm in environments where the assumptions of perfect processes
and networks are relaxed.  The ways that the algorithm breaks will
give insights on how the algorithm works.&lt;/p&gt;

&lt;h2 id=&quot;appendix-defines-and-macros&quot;&gt;Appendix: Defines and macros&lt;/h2&gt;

&lt;p&gt;Bodies of the &lt;code class=&quot;highlighter-rouge&quot;&gt;define&lt;/code&gt;s and macros:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;define
  \* Total order of clocks using Pid to break ties
  LogClockLt(reqs, p, q) ==
    \/ reqs[q] = 0
    \/ reqs[p] &amp;lt; reqs[q]
    \/ reqs[p] = reqs[q] /\ p &amp;lt; q
  \* All processes whose head msg to dst is of this type
  ChanHead(dst, type) ==
    {src \in Pid: /\ Len(channel[src][dst]) &amp;gt; 0
                  /\ Head(channel[src][dst]).type = type
    }

  \* Max of two times   
  Max(a, b) == IF a &amp;lt;= b THEN b ELSE a

  \* Instrumentation control
  PrintDebug == FALSE
end define

\*---------------------------Instrumentation Macros------------------
\* Print if debugging turned on
macro Print(clock, vars) begin
  if PrintDebug then
    print &amp;lt;&amp;lt;self, clock, vars&amp;gt;&amp;gt;
  end if
end macro

\*-----------------------------Network operations--------------------

\* Wait for a `type` message and return its contents
macro Receive(type, clock, src, time) begin
  with s \in ChanHead(self, type) do
    src := s;
    time := Head(channel[src][self]).time;
    Print(clock, &amp;lt;&amp;lt; &amp;lt;&amp;lt;&quot;Receiving&quot;, type&amp;gt;&amp;gt;, src, time&amp;gt;&amp;gt;);
    channel :=
	  [channel EXCEPT ![src][self] = Tail(channel[src][self])]
  end with
end macro

\* Broadcast a message
macro Broadcast(clock, msg) begin
  Print(clock, &amp;lt;&amp;lt;&quot;Broadcasting&quot;, msg.type&amp;gt;&amp;gt;);
  channel :=
    [channel EXCEPT ![self] =
      [dst \in Pid |-&amp;gt;
        IF dst = self THEN channel[self][self]
                      ELSE Append(channel[self][dst], msg)]]
end macro

\* Send a message to a specific process
macro SendTo(clock, dst, msg) begin
  Print(clock, &amp;lt;&amp;lt;&quot;Sending&quot;, dst, msg.type&amp;gt;&amp;gt;);
  channel :=
    [channel EXCEPT ![self][dst] = Append(channel[self][dst], msg)]
end macro

&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Fairness semantics of PlusCal</title>
   <link href="/2019/01/18/fairness-semantics-of-pluscal/"/>
   <updated>2019-01-18T00:00:00-08:00</updated>
   <id>/2019/01/18/fairness-semantics-of-pluscal</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Third in a series on using the TLA Toolbox to explore the failure
 tolerance of distributed algorithms. The second post
 &lt;a href=&quot;/2019/01/03/distributed-algorithms-in-pluscal/&quot;&gt;presented some PlusCal conventions for writing distributed algorithms&lt;/a&gt;. The
 next post presents &lt;a href=&quot;/2019/04/15/lamport-algorithm/&quot;&gt;Lamport’s (1978) mutual exclusion algorithm in PlusCal&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Note:  This post covers an esoteric aspect of PlusCal semantics. I
 include it here because I need to understand this topic myself before
 writing the rest of the series. It is not necessary to know this
 topic before reading the rest of the series, however. On first reading, I suggest
 moving directly to the next post, returning to this post only when you
 need these details.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;the-tla-translation-of-pluscal&quot;&gt;The TLA translation of PlusCal&lt;/h2&gt;

&lt;p&gt;PlusCal isn’t the native language of the TLA Toolbox. As the name
implies, TLA is the common notation used by the editor, the TLC model
checker, and the TLAPS proof checker. In particular, an algorithm in
PlusCal must be translated to TLA before it can be checked by TLC.
When checking an algorithm, all of TLC’s reports, including errors,
traces, and coverage, are presented in terms of the underlying TLA.&lt;/p&gt;

&lt;p&gt;Consequently, you can only use TLC effectively if you understand how a
PlusCal algorithm is represented in TLA. The full explanation is
beyond the scope of this series. In short, you need to learn both
PlusCal and TLA, then read the TLA produced by the translation of your
PlusCal algorithms. The details take some time to learn but the
translation is straightforward and can be mastered with modest
practice.&lt;/p&gt;

&lt;p&gt;However, there is one subtle point of PlusCal semantics that is not
straightforward: Its representation of fairness. For many PlusCal use
cases, you do not need to understand this. If you want to check
termination or a liveness property in TLC, simply prefix each process
with the &lt;code class=&quot;highlighter-rouge&quot;&gt;fair&lt;/code&gt; keyword and every transition is asserted to be weakly
fair.  For typical uses of model checking, this is sufficient.&lt;/p&gt;

&lt;p&gt;However, in this series, I will be exploring the consequences of
algorithms for which only some transitions are fair. This models such
behaviours as instances that crash while in a critical section.  For
these use cases, it helps to understand how the TLA produced by the
translation of an algorithm represented in PlusCal differs from how
that same algorithm might be represented in “classic” TLA.&lt;/p&gt;

&lt;h2 id=&quot;a-pluscal-algorithm-and-its-tla-equivalent&quot;&gt;A PlusCal algorithm and its TLA equivalent&lt;/h2&gt;

&lt;p&gt;As an example of the difference between the two notations, consider
the following PlusCal algorithm. It doesn’t do anything particularly
interesting, consisting of a loop with two alternatives.  The loop
increments &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; from 1 to 3 to 4, then terminates:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;--algorithm PlusCalFairnessSemantics
variable
  a = 1;

fair process Proc = 1
begin
P1: while a &amp;lt;= 3 do
    either
      await a = 1;
        a := a + 2
    or
      await a = 3;
        a := a + 1
    end either
  end while
end process
end algorithm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The equivalent version of this algorithm in “classic” TLA would name
each alternative and provide an explicit termination transition:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;VARIABLES a

vars == &amp;lt;&amp;lt; a &amp;gt;&amp;gt;

Init == a = 1

A1 == /\ a = 1
      /\ a' = a + 2

A3 == /\ a = 3
      /\ a' = a + 1

Tm == /\ a &amp;gt; 3
      /\ UNCHANGED vars
      
Next == A1 \/ A3 \/ Tm

Spec == Init /\ [][Next]_vars /\ WF_vars(Next)

Termination == &amp;lt;&amp;gt;([](a &amp;gt; 3))
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In the TLA version, each state of &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; is represented by a separate
named formula, &lt;code class=&quot;highlighter-rouge&quot;&gt;Init&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;A1&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;A3&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;Tm&lt;/code&gt;, comprising a guard that
enables the action for a specific value of &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; and an equality
specifying the new value replacing it.  In this version, &lt;em&gt;the
algorithm is sequenced by the successive values of &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Now consider the TLA equations produced by the translation of the
PlusCal algorithm:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;VARIABLES a, pc

vars == &amp;lt;&amp;lt; a, pc &amp;gt;&amp;gt;

ProcSet == {1}

Init == (* Global variables *)
        /\ a = 1
        /\ pc = [self \in ProcSet |-&amp;gt; &quot;P1&quot;]

P1 == /\ pc[1] = &quot;P1&quot;
      /\ IF a &amp;lt;= 3
            THEN /\ \/ /\ a = 1
                       /\ a' = a + 2
                    \/ /\ a = 3
                       /\ a' = a + 1
                 /\ pc' = [pc EXCEPT ![1] = &quot;P1&quot;]
            ELSE /\ pc' = [pc EXCEPT ![1] = &quot;Done&quot;]
                 /\ a' = a

Proc == P1

Next ==
  \/ Proc
  (* Disjunct to prevent deadlock *)
  \/ /\ (\A self \in ProcSet: pc[self] = &quot;Done&quot;)
     /\ UNCHANGED vars

Spec == /\ Init
        /\ [][Next]_vars
        /\ WF_vars(Proc)

Termination ==
    &amp;lt;&amp;gt;(\A self \in ProcSet: pc[self] = &quot;Done&quot;)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This representation only has two named definitions, &lt;code class=&quot;highlighter-rouge&quot;&gt;Init&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;P1&lt;/code&gt;
and introduces a variable not present in the PlusCal code, &lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt;.
Unlike the “classic” TLA version, in the PlusCal translation, &lt;em&gt;the
algorithm is sequenced by a variable, &lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt;, whose only purpose is
sequencing.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;There is a second difference between the two TLA versions.  In the
PlusCal translation, the definition of &lt;code class=&quot;highlighter-rouge&quot;&gt;P1&lt;/code&gt; combines the formulas &lt;code class=&quot;highlighter-rouge&quot;&gt;A1&lt;/code&gt;,
&lt;code class=&quot;highlighter-rouge&quot;&gt;A3&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;Tm&lt;/code&gt; from the “classic” TLA version. Though their structure
appears different, they are equivalent. After stripping the references to
&lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt;, the definition of &lt;code class=&quot;highlighter-rouge&quot;&gt;P1&lt;/code&gt; becomes&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;IF a &amp;lt;= 3
THEN \/ /\ a = 1
        /\ a' = a + 2
     \/ /\ a = 3
        /\ a' = a + 1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;which, after removing the redundant test, is just&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;\/ /\ a = 1
   /\ a' = a + 2
\/ /\ a = 3
   /\ a' = a + 1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;which in turn is simply &lt;code class=&quot;highlighter-rouge&quot;&gt;A1 \/ A3&lt;/code&gt; from the “classic” version.&lt;/p&gt;

&lt;p&gt;So in this case, the PlusCal version is simply the “classic” version,
annotated with sequencing by the &lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt; variable.&lt;/p&gt;

&lt;h2 id=&quot;unfair-transitions-when-pluscal-differs-from-classic&quot;&gt;Unfair transitions: When PlusCal differs from “classic”&lt;/h2&gt;

&lt;p&gt;Although in the above case “classic” TLA design and PlusCal produce
equivalent TLA code that differs only in whether sequencing is done
implicitly (in the “classic” version) or explicitly (in PlusCal), they
are not equivalent in other cases. When we specify that some transitions are
unfair, the forms become subtly different.&lt;/p&gt;

&lt;p&gt;Suppose we want to indicate that the &lt;code class=&quot;highlighter-rouge&quot;&gt;A3&lt;/code&gt; transition is unfair.  In the
“classic” version, we do not change the transitions at all but simply
change the specification so that only &lt;code class=&quot;highlighter-rouge&quot;&gt;A1&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;Tm&lt;/code&gt; are marked as fair:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Spec == /\ Init /\ [][Next]_vars
        /\ WF_vars(A1 \/ Tm)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The change to the PlusCal code is even smaller: Simply prefix the
guard with a label suffixed by &lt;code class=&quot;highlighter-rouge&quot;&gt;-&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;L1:- await a = 3;
  a := a + 1
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This small change to PlusCal however induces a substantive change in
its TLA translation:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;P1 == /\ pc[1] = &quot;P1&quot;
      /\ IF a &amp;lt;= 3
         THEN /\ \/ /\ a = 1
                    /\ a' = a + 2
                    /\ pc' = [pc EXCEPT ![1] = &quot;P1&quot;]
                 \/ /\ pc' = [pc EXCEPT ![1] = &quot;L1&quot;]
                    /\ a' = a
         ELSE /\ pc' = [pc EXCEPT ![1] = &quot;Done&quot;]
              /\ a' = a

L1 == /\ pc[1] = &quot;L1&quot;
      /\ a = 3
      /\ a' = a + 1
      /\ pc' = [pc EXCEPT ![1] = &quot;P1&quot;]

Proc == P1 \/ L1

Next ==
  \/ Proc
  (* Disjunct to prevent deadlock *)
  \/ /\ (\A self \in ProcSet: pc[self] = &quot;Done&quot;)
     /\ UNCHANGED vars

Spec == /\ Init /\ [][Next]_vars
        /\ WF_vars((pc[1] # &quot;L1&quot;) /\ Proc)
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The code has changed in three ways:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A new state has been introduced, denoted by &lt;code class=&quot;highlighter-rouge&quot;&gt;pc = &quot;L1&quot;&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;A new labelled formula has been created, &lt;code class=&quot;highlighter-rouge&quot;&gt;L1&lt;/code&gt;, which is enabled by
the new value of &lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;The fairness condition now &lt;em&gt;excludes&lt;/em&gt; the new state. Consequently,
when transition &lt;code class=&quot;highlighter-rouge&quot;&gt;L1&lt;/code&gt; is enabled, it is not guaranteed to ever be
executed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Logically, this is equivalent to the “classic” TLA version. In both
versions, the transition when &lt;code class=&quot;highlighter-rouge&quot;&gt;a = 3&lt;/code&gt; is not guaranteed to be taken
even if it is enabled infinitely many times. However, they differ in
their number of states: The PlusCal version introduces an extra state
to mark the unfair transition, whereas the unfair TLA version has only
as many states as its fair counterpart.&lt;/p&gt;

&lt;p&gt;The size of the state space representing potential executions of the
algorithm has a direct effect on the time required to model check it.
This effect is amplified when checking liveness properties, which
require extra passes over the state space after it has been completely
generated.  Although in this example, the space has only increased by
a single state, if the label is placed within a frequently-executed
loop, the increase could be substantial.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The TLA translation of a PlusCal algorithm differs from how one would
represent the same algorithm in “classic” TLA. All fair transitions have
their common conditions merged to create a single labelled transition,
while any unfair transitions have a new state defined for &lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt; and the
transition defined as a separately-labelled transition.&lt;/p&gt;

&lt;p&gt;Although this representation appears quite different from the
distinct, focused definitions used in “classic” TLA, their logic is
equivalent. They do perform differently in model checking, however.
The new values of &lt;code class=&quot;highlighter-rouge&quot;&gt;pc&lt;/code&gt; introduced for unfair transitions by the
PlusCal translation increase the time required by TLC to check the
model. Given that this choice is built in to the PlusCal translator,
we cannot remove this problem but it is useful to be aware of its
impact.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Distributed algorithms in PlusCal</title>
   <link href="/2019/01/03/distributed-algorithms-in-pluscal/"/>
   <updated>2019-01-03T00:00:00-08:00</updated>
   <id>/2019/01/03/distributed-algorithms-in-pluscal</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Second in a series on using the TLA Toolbox to explore the failure
 tolerance of distributed algorithms. The first post
 &lt;a href=&quot;/2018/10/31/exploring-distributed-algorithm-failures-using-tla-toolbox/&quot;&gt;presented the context and why the topic is important&lt;/a&gt;. The
 next post describes the &lt;a href=&quot;/2019/01/18/fairness-semantics-of-pluscal/&quot;&gt;semantics of fairness in PlusCal&lt;/a&gt;&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Before describing how to analyze failures in distributed algorithms in
the TLA Toolbox, I want to provide some backround in the conventions I
use to represent the algorithms. Although Lamport has provided a
&lt;a href=&quot;http://lamport.azurewebsites.net/tla/pluscal.html&quot;&gt;good reference for the features of the PlusCal language&lt;/a&gt;,
there is a lack of material on how to structure the larger scale
of algorithms. As my purpose in this series is to provide an
intermediate level tutorial, in this post I want to describe the
conventions I use to make writing distributed algorithms in PlusCal
more readable and reliable, while the next post will clarify some
potentially obscure aspects of PlusCal semantics.  With that
background out of the way, I can turn to the main topic.&lt;/p&gt;

&lt;h2 id=&quot;the-dialect&quot;&gt;The dialect&lt;/h2&gt;

&lt;p&gt;PlusCal has two dialects, PlusCal-c, which uses syntax similar to C
(but different enough in the details to be confusing),
and PlusCal-p, which uses syntax similar to Pascal. I prefer the
PlusCal-p syntax, as it emphasizes that I am presenting an algorithm
rather than a bowdlerized C program.&lt;/p&gt;

&lt;h2 id=&quot;the-common-structure-of-many-distributed-algorithms&quot;&gt;The common structure of many distributed algorithms&lt;/h2&gt;

&lt;p&gt;Effective PlusCal is a matter of matching the features of the language
to the structure of the algorithms that we want to represent.  Many
distributed algorithms have a common structure, an infinite loop whose
body is a collection of alternatives, each guarded by a condition:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;while TRUE do
  either
    guard1
      alternative1
  or
    guard2
      alternative2
  or
    ...
  end either
end while
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Each guard specifies the enabling condition for its associated
alternative.  In each loop iteration, one of the enabled alternatives
is chosen to be executed. So long as at least one guard is true,
enabling its alternative, the loop continues to execute.  The loop may
also terminate if it executes an alternative that ends with a &lt;code class=&quot;highlighter-rouge&quot;&gt;goto&lt;/code&gt;
out of the loop.&lt;/p&gt;

&lt;p&gt;If there is an iteration in which every alternative is disabled, the
algorithm has deadlocked. When checking the algorithm with TLC, you
can set an option for TLC to check for deadlocks.&lt;/p&gt;

&lt;p&gt;What is the best way to represent this structure in PlusCal?&lt;/p&gt;

&lt;h2 id=&quot;alternatives-actions-and-atomicity&quot;&gt;Alternatives, actions, and atomicity&lt;/h2&gt;

&lt;p&gt;In the above structure, an “alternative” may comprise one or more
actions. In TLA, &lt;em&gt;action&lt;/em&gt; denotes a single transition in the
underlying state machine.  In PlusCal code, this would be all the
statements lying between a guard and the first label following it.  So
long as the alternative enabled by a guard has no labels, it comprises
a single TLA action. If the alternative includes labels, then it
comprises one more TLA action than the number of labels it contains.&lt;/p&gt;

&lt;p&gt;The granularity of an alternative determines its atomicity. If it is
only a single TLA action, it is &lt;em&gt;atomic&lt;/em&gt;: It executes instantaneously,
while all other processes are paused. An alternative that includes one
or more labels, on the other hand, will have its execution
interspersed with actions by other processes. I will return to this
point in a moment; for now, I’ll simply state that for distributed
algorithms, which only communicate through messages, atomicity of
alternatives in an &lt;code class=&quot;highlighter-rouge&quot;&gt;either&lt;/code&gt; statement is less important than for
algorithms that communicate through shared memory.&lt;/p&gt;

&lt;h2 id=&quot;guards-in-pluscal&quot;&gt;Guards in PlusCal&lt;/h2&gt;

&lt;p&gt;PlusCal guards can have rich structure. They are constructed from
three language keywords that define an enabling condition: &lt;code class=&quot;highlighter-rouge&quot;&gt;await&lt;/code&gt;,
&lt;code class=&quot;highlighter-rouge&quot;&gt;when&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;with&lt;/code&gt;. The &lt;code class=&quot;highlighter-rouge&quot;&gt;await&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;when&lt;/code&gt; keywords are
interchangeable. In the Lamport algorithm, I chose &lt;code class=&quot;highlighter-rouge&quot;&gt;when&lt;/code&gt; because it
gave the algorithm a straightforward reading but for other algorithms
&lt;code class=&quot;highlighter-rouge&quot;&gt;await&lt;/code&gt; might read better.&lt;/p&gt;

&lt;p&gt;Whereas &lt;code class=&quot;highlighter-rouge&quot;&gt;await&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;when&lt;/code&gt; simply establish an enabling condition, the
&lt;code class=&quot;highlighter-rouge&quot;&gt;with&lt;/code&gt; keyword combines an enabling condition with the operation of
choosing a value from a set. An expression such as&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;with a \in { ... some set ...}
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;is enabled when the set is nonempty. Furthermore, when the set is
nonempty, a value is nondeterministically chosen and assigned to &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;A guard composed of just one of these keywords is simple enough to
interpret. For example, in the following snippet,&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;when /\ 1 &amp;lt; b
     /\ b &amp;lt; 10;
  \* guarded alternative ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;the alternative is enabled when &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; is strictly between 1 and 10.&lt;/p&gt;

&lt;p&gt;However, PlusCal allows combining enabling statements and even
interspersing assignments with guards. Guards can be placed at any
point in an action, even as the last statement. The evaluation rule
for actions is:&lt;/p&gt;

&lt;p class=&quot;pull&quot;&gt;An action is enabled if and only if every one of its &lt;code class=&quot;highlighter-rouge&quot;&gt;await&lt;/code&gt;,
&lt;code class=&quot;highlighter-rouge&quot;&gt;when&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;with&lt;/code&gt; statements is enabled. If even one guard is
disabled, no statement in the action is executed.&lt;/p&gt;

&lt;p&gt;This rule implies that the evaluation may backtrack when a guard
depends upon the result of an assignment. Consider this snippet:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;a := b + 1;
await a &amp;gt; 2;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;If &lt;code class=&quot;highlighter-rouge&quot;&gt;b &amp;lt;= 1&lt;/code&gt;, the action will not be enabled and so &lt;code class=&quot;highlighter-rouge&quot;&gt;a&lt;/code&gt; will not in fact
be assigned in the preceding statement.  The action comprising these
two statements is only executed if the assignment &lt;em&gt;were to have
resulted&lt;/em&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;a &amp;gt; 2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Another way of viewing this is that the mathematical equalities
in the TLA underlying PlusCal allow us to rewrite the above
statements as the equivalent&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;await b &amp;gt; 1;
a := b + 1;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;moving the guard before the assignment.&lt;/p&gt;

&lt;h2 id=&quot;atomic-actions-and-data-races-in-distributed-algorithms&quot;&gt;Atomic actions and data races in distributed algorithms&lt;/h2&gt;

&lt;p&gt;The second requirement for effective use of PlusCal is knowing when
and how to ensure atomic actions.  This is directly related to the
distinction between local and global variables.&lt;/p&gt;

&lt;p&gt;In a completely distributed algorithm, processes only communicate via
messages. Writing such an algorithm in PlusCal, the system state is
split, such that&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the state of the &lt;em&gt;algorithm&lt;/em&gt; is contained in the local variables of its
processes, and&lt;/li&gt;
  &lt;li&gt;the state of the &lt;em&gt;network&lt;/em&gt;, the messages in transit, is contained in
the global variables.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Because process variables are local, you can freely mix references and
assignments to them, without concern for intervening actions by other
processes, whereas for global variables, mixing references and
assignments may introduce race conditions.  The syntactic distinction
between local and global variables highlights the ones for which
atomic access is important:&lt;/p&gt;

&lt;p class=&quot;pull&quot;&gt;When writing a message-passing algorithm in PlusCal, the only
variables for which atomic access matters are the global variables
representing the network.&lt;/p&gt;

&lt;h3 id=&quot;example-contrasting-local-and-global-variables&quot;&gt;Example contrasting local and global variables&lt;/h3&gt;

&lt;p&gt;For example, consider the following algorithm, which includes one
global variable and two local variables:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;--algorithm RaceAlgo
variables
  \* Global variable
  glob

process Proc \in 1 .. 2
variables
  \* Variables local to process
  loc1 \in 1 .. 2,
  loc2

begin
(* Unaffected by other processes because loc1, loc2 are local ... *)
L1:
  loc2 := loc1 + 1;
L2:
  loc2 := loc2 + 1;

(* ... but following has race condition because glob is global *)
L3:
  glob := loc1 + 1;
L4:
  glob := glob + 1;

  print &amp;lt;&amp;lt;self, loc1, loc2, glob&amp;gt;&amp;gt;

end process
end algorithm
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Running this on TLC, it finds 54 distinct end states. The algorithm is
symmetric, so there are 6 distinct outcomes, repeated for each
process:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loc1&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;loc2&lt;/code&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;glob&lt;/code&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;1&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;3&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;1&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;2&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;strong&gt;4&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;2&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;4&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;5&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;In every case, &lt;code class=&quot;highlighter-rouge&quot;&gt;loc2&lt;/code&gt; equals &lt;code class=&quot;highlighter-rouge&quot;&gt;loc1 + 2&lt;/code&gt;, but not necessarily for
&lt;code class=&quot;highlighter-rouge&quot;&gt;glob&lt;/code&gt;, which can have three different outcomes for each value
of&lt;code class=&quot;highlighter-rouge&quot;&gt;loc1&lt;/code&gt;. We get &lt;code class=&quot;highlighter-rouge&quot;&gt;glob&lt;/code&gt; equal to &lt;code class=&quot;highlighter-rouge&quot;&gt;loc1 + 2&lt;/code&gt; if the two processes are
executed sequentially, producing the two highlighted rows: 1, 3, 3 and
2, 4, 4.  But those aren’t the only outcomes. In addition to them,
there are four other outcomes for &lt;code class=&quot;highlighter-rouge&quot;&gt;glob&lt;/code&gt;, from executions that
intermingled execution of the statements at &lt;code class=&quot;highlighter-rouge&quot;&gt;L3&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;L4&lt;/code&gt; by
Processes 1 and 2.&lt;/p&gt;

&lt;p&gt;As the example demonstrates, we can assign to local variables without
concern for the presence of labels but when assigning to global
variables we must be alert to the placement of labels, as those mark
points where a different process could intervene and update the globals.&lt;/p&gt;

&lt;h2 id=&quot;packaging-network-operations-as-macros&quot;&gt;Packaging network operations as macros&lt;/h2&gt;

&lt;p&gt;Given that global variables represent the network state and are also
the variables for which we need to ensure atomic access, it would be
useful to have a way to ensure our network operations are atomic.
PlusCal macros fulfill this need because they are always atomic, not
allowed to include a label. Macros also package the slightly unfamiliar
representation of networks as sets and functions into familiar
operation names.&lt;/p&gt;

&lt;p&gt;For example, in the Lamport algorithm, the network is represented as a
function of type &lt;code class=&quot;highlighter-rouge&quot;&gt;Channel&lt;/code&gt;, a mapping from source and
destination process ids to a &lt;code class=&quot;highlighter-rouge&quot;&gt;Sequence&lt;/code&gt; of &lt;code class=&quot;highlighter-rouge&quot;&gt;Messages&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Channel == [src \in Pid |-&amp;gt; [dst \in Pid |-&amp;gt; Seq(Message)]]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The network itself is a variable &lt;code class=&quot;highlighter-rouge&quot;&gt;channel&lt;/code&gt; of that type, and a
network broadcast is represented by&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;channel := [channel EXCEPT ![self] =
             [dst \in Pid |-&amp;gt;
               IF dst = self THEN channel[self][self]
                             ELSE Append(channel[self][dst], msg)]]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This is more readably written as the macro call&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Broadcast(msg);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;For a more complex example, consider receiving a message. The
receiving process must perform three steps in sequence:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Wait for a message of a specified &lt;code class=&quot;highlighter-rouge&quot;&gt;type&lt;/code&gt; to be
available at the head of the sequence sent from at least one source,&lt;/li&gt;
  &lt;li&gt;pick the process id of one source when the wait is satisfied, and&lt;/li&gt;
  &lt;li&gt;remove that message from the sequence, passing the message contents
&lt;code class=&quot;highlighter-rouge&quot;&gt;src&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;time&lt;/code&gt; to the destination.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The resulting code is subtle:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;with s \in {src \in Pid: /\ Len(channel[src][dst]) &amp;gt; 0
                         /\ Head(channel[src][dst]).type = type
           } do
  src := s;
  time := Head(channel[src][self]).time;
  channel := [channel EXCEPT ![src][self] = Tail(channel[src][self])]
end with
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;It’s far more readable when packaged into a macro call:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Receive(&quot;AckReq&quot;, src, time);
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;Receive&lt;/code&gt; macro functions as both a guard and, when the guard is
enabled and allows the assignments to be executed, updates the global
state. A message is removed from the network (represented by
&lt;code class=&quot;highlighter-rouge&quot;&gt;channel&lt;/code&gt;) and its contents, a sender id and logical clock value, are
assigned to local variables. In the actual algorithm, its call looks like&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;either
 ...
or
  Receive(&quot;AckReq&quot;, src, time); \* Guard; updates src and time
    clock := Max(clock, time);  \* Update local clock
    acks := acks \union {src}   \* Record receipt of acknowledgement
or
 ...
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;I indent the statements following the guard to indicate that their
execution is controlled by the guard.&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Effective use of PlusCal for distributed algorithms requires matching
the language features to the structure of the algorithm. Typically,
the only actions that have to be atomic are those that reference or
update global variables. Package global accesses as macros, ensuring
atomic access. Given that these actions are nearly always network
operations, the macros also make the operations clearer than the
underlying TLA expressions.&lt;/p&gt;

&lt;p&gt;Pay attention to the guards enabling the alternative choices in an
algorithm.  Often these guards will be macros representing network
operations that wait on a message of a specific type and retrieve the
message contents when one is received.&lt;/p&gt;

&lt;p&gt;I have found that adopting these conventions makes my algorithms
clearer and more reliable.  In the next post, I’ll go beneath this
syntax and explore a subtle point of the semantics of PlusCal.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Exploring distributed algorithm failures using TLA Toolbox</title>
   <link href="/2018/10/31/exploring-distributed-algorithm-failures-using-tla-toolbox/"/>
   <updated>2018-10-31T00:00:00-07:00</updated>
   <id>/2018/10/31/exploring-distributed-algorithm-failures-using-tla-toolbox</id>
   <content type="html">&lt;p&gt;&lt;em&gt;First in a series on using the TLA Toolbox to explore the failure
 tolerance of distributed algorithms. The next post has not been written.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I have wanted to write a series about Leslie Lamport’s
&lt;a href=&quot;https://lamport.azurewebsites.net/tla/toolbox.html&quot;&gt;TLA Toolbox&lt;/a&gt; for
some time. For years, I’ve been following the growing use of formal
and semi-formal methods in software development, including such tools
as &lt;a href=&quot;https://lamport.azurewebsites.net/tla/toolbox.html&quot;&gt;Alloy&lt;/a&gt;,
&lt;a href=&quot;https://coq.inria.fr/&quot;&gt;Coq&lt;/a&gt;,
&lt;a href=&quot;http://spinroot.com/spin/whatispin.html&quot;&gt;Spin&lt;/a&gt;, and
&lt;a href=&quot;https://isabelle.in.tum.de/&quot;&gt;Isabelle&lt;/a&gt;. And that’s just a taste of
what’s on offer—consider the tools Byron Cook lists at the end of
his talk on
&lt;a href=&quot;http://www0.cs.ucl.ac.uk/staff/b.cook/CAV18_invited.pdf&quot;&gt;formal verification of security at Amazon Web Services&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Of the tools I have explored, the TLA language and the TLC model
checker represent a fascinating design point:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;simple enough to pick up
quickly,&lt;/li&gt;
  &lt;li&gt;focused enough that they do their job well without diluting
that focus by attempting too much, and&lt;/li&gt;
  &lt;li&gt;powerful enough to apply to
questions of interest in a production environment.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lamport has
&lt;a href=&quot;https://amturing.acm.org/award_winners/lamport_1205376.cfm&quot;&gt;devoted his career&lt;/a&gt;
to developing provably correct distributed algorithms and the Toolbox
distills this experience into executable form. The rest of us, those
who haven’t won a Turing award, can use the wisdom embedded in these
tools to approach that level of performance.&lt;/p&gt;

&lt;h2 id=&quot;focusing-on-failure-tolerance-of-distribute-algorithms&quot;&gt;Focusing on failure tolerance of distribute algorithms&lt;/h2&gt;

&lt;p&gt;Despite my interest in the Toolbox, I have held off writing anything
about it because so much has already been written.  In fact, the
newcomer is held back by the sheer number of tutorials and references
available at the Toolbox site alone, let alone the others around the
Web.  There seemed no point in duplicating what was already so
well-described elsewhere.&lt;/p&gt;

&lt;p&gt;In recent months however, I have found a novel angle for approaching
the Toolbox, using it to study the failure tolerance of distributed
algorithms. This is a slippery topic, yet of growing
importance. Modern service-oriented designs,
&lt;a href=&quot;/2018/10/13/data-engineering-design-space/&quot;&gt;running on cloud data centres&lt;/a&gt;,
are expected to be
&lt;a href=&quot;https://www.oreilly.com/ideas/chaos-engineering&quot;&gt;resilient in the face of failure&lt;/a&gt;. The
most basic form of this resilience is that the service must run on
multiple instances and continue when a subset of those instances
fails. A necessary condition of a resilient service is that its
algorithm is designed to be replicated and resilient in the event of
failure of one or more instances.&lt;/p&gt;

&lt;p&gt;Notably, Lamport has contributed one of the oldest and most famous
resilient algorithms, Paxos. Opinions vary on how easy Paxos is
to understand: Lamport
&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/paxos-made-simple/&quot;&gt;considers it simple&lt;/a&gt;,
others see it as at least &lt;a href=&quot;http://paxos.systems/&quot;&gt;moderately complex&lt;/a&gt;,
while still others emphasize the substantial extra work required to
&lt;a href=&quot;http://www.scs.stanford.edu/~dm/home/papers/paxos.pdf&quot;&gt;make it practical&lt;/a&gt;
and
&lt;a href=&quot;https://ai.google/research/pubs/pub33002&quot;&gt;make it production-ready&lt;/a&gt;. And
all these articles focus on understanding the cases where at least a
majority of the instances run without failure.  What of the cases where
one instance crashes (which the algorithm should handle) or where so many
instances crash that it cannot proceed?&lt;/p&gt;

&lt;h2 id=&quot;the-benefits-of-model-checking&quot;&gt;The benefits of model checking&lt;/h2&gt;

&lt;p&gt;Model checking can help tackle the challenge of understanding whether
a distributed algorithm proceeds or fails in the presence of failed
instances. A model checker lets you explore the behaviours of an
algorithm. You can, for example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ensure that all behaviours up to a certain length conform to a
requirement or trace out a counterexample behaviour that violates
the requirement;&lt;/li&gt;
  &lt;li&gt;Remove a necessary subtlety of the algorithm and demonstrate that
the simplified algorithm no longer meets a requirement; or&lt;/li&gt;
  &lt;li&gt;Demonstrate that an algorithm fails a requirement
outside its original intent (for example, that an algorithm designed
under an assumption of a perfect network fails when the network
drops messages).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A model checker run is a superpowered version of a regular test run.
Where a test run simply demonstrates a single behaviour, a model
checker run tests all behaviours up to some maximum length. Although
such runs are less complete than proofs (a proof is valid for all
behaviours, regardless of length), runs of a model checker are far
more complete than a single run of the program. With a model checker,
the designer can see the implications of a change on a wide range
of behaviours in a short time. The method does not provide 100% confidence in
your conclusions but it provides far more confidence than mere runs of the
program could ever provide.&lt;/p&gt;

&lt;h2 id=&quot;and-the-horror-the-horror&quot;&gt;… and the horror, the horror!&lt;/h2&gt;

&lt;p&gt;However useful a model checker can be, I worry that I violate the
express wishes of the TLA team when I apply their Toolbox to
investigate failure tolerance, which typically requires
writing liveness properties in moderately complex formulas of temporal logic. In
&lt;a href=&quot;https://lamport.azurewebsites.net/tla/book.html&quot;&gt;&lt;em&gt;The TLA Book&lt;/em&gt;&lt;/a&gt;,
Lamport advocates focusing instead on &lt;em&gt;safety&lt;/em&gt; properties, which can typically
be written in propositional logic, avoiding liveness properties and the more
complicated temporal logic they require:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Experience shows that most of the benefit from writing and using a
specification comes from the safety part … [W]hen looking for
errors, most of your effort should be devoted to examining the
safety part … The unbridled use of temporal logic produces
formulas that are hard to understand. (p. 116)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I am unsure whether Lamport would consider my use of temporal logic in
the following posts “well-bridled” but I do believe that such formulas
are more important now that liveness properties have become more
prominent. It is not enough that a system in production ensure that at
most one process is in a critical section at a given time (a safety
property).  The system must also ensure that processes attempting to
enter that critical section are admitted without undue delay (a
liveness property). As
&lt;a href=&quot;https://ai.google/research/pubs/pub40801&quot;&gt;Dean and Barroso&lt;/a&gt; argue,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Just as fault-tolerant computing aims to create a reliable whole out
of less reliable parts, we suggest that large online services need
to create a predictably responsive whole out of less predictable
parts. [Abstract]&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;These guarantees are ultimately probabilistic and as such, they cannot
be tested by model checking, which is fundamentally logical.  Yet
model checking can test the logical properties standing as
&lt;em&gt;prerequisites&lt;/em&gt; to acceptable latency distributions.  An algorithm that
halts when an instance crashes or becomes partitioned can never
provide acceptable latencies in the long tail.  The tests described in
this series are insufficient to guarantee success but their &lt;em&gt;failure&lt;/em&gt;
guarantees the design will be inadequate in the face of some types of
failure.&lt;/p&gt;

&lt;h2 id=&quot;what-we-stand-to-learn-and-not-learn&quot;&gt;What we stand to learn and not learn&lt;/h2&gt;

&lt;p&gt;Taking all this together, using TLA to explore a distributed algorithm’s
responses to failure offers several lessons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A tool for understanding a slippery property of increasing
importance in actual systems&lt;/li&gt;
  &lt;li&gt;Practice at intermediate-level use of the Toolbox, beyond the simple
cases used in most tutorials&lt;/li&gt;
  &lt;li&gt;A deeper understanding of model checking more generally.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It is also important to bear in mind what the method will not do:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It will not consider more complex failure scenarios, such as
“Byzantine” cases, where a buggy or compromised instance actively
subverts the system.&lt;/li&gt;
  &lt;li&gt;It will not consider the distribution of response latencies.&lt;/li&gt;
  &lt;li&gt;It will not consider probabilistic failures such as a fractional
loss rate of messages on the network.&lt;/li&gt;
  &lt;li&gt;The size of the spaces searchable using practical resources
will be smaller for the more complex temporal formulas required for
liveness than for the simpler predicate logic formulas commonly used
for checking safety.&lt;/li&gt;
  &lt;li&gt;For the sorts of long-running algorithms we will consider, model
checking can not provide the complete guarantees of a mathematical
proof.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Despite these limitations, the approach remains useful and fun. I’ll
start by considering a simpler algorithm than Paxos,
&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/time-clocks-ordering-events-distributed-system/&quot;&gt;Lamport’s 1978 distributed mutual exclusion algorithm&lt;/a&gt;. This
algorithm was designed under an assumption of perfect instances
running on a perfect network, so it’s a good case for analyzing its
response to instance failure.  Even this simple algorithm will provide
fodder for a whole series of posts.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Assignments with coding only teach coding</title>
   <link href="/2018/10/26/assignments-with-coding-only-teach-coding/"/>
   <updated>2018-10-26T00:00:00-07:00</updated>
   <id>/2018/10/26/assignments-with-coding-only-teach-coding</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Fourth in a series on designing a course on data engineering.  The
 previous post listed the
 &lt;a href=&quot;/2018/10/23/data-engineering-prerequisites/&quot;&gt;minimal operating system and networking knowlege&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;When designing an upper-division or graduate-level class, we often set
our learning outcomes to include higher-level concepts characterizing
systems architecture.  For example, I am designing a course in data
engineering for a professional master’s program.  This course features
such concepts as&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Consistency of data in durable storage with multiple instances&lt;/li&gt;
  &lt;li&gt;Effects of high-percentile (“long tail”) latencies on overall system
performance&lt;/li&gt;
  &lt;li&gt;Resiliency testing via injection of anomolous messages&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I begin from
&lt;a href=&quot;http://www.johnbiggs.com.au/academic/constructive-alignment/&quot;&gt;Biggs’s rule&lt;/a&gt;:
Learning results from &lt;em&gt;what the learner does&lt;/em&gt;. The activities I ask
learners to perform should align with the way I expect them to use the
relevant knowledge after the class; my assessment of learners against
those outcomes should align with the expected use as well.&lt;/p&gt;

&lt;p&gt;Set aside the issue of assessment for a moment.  The immediate
question is how shall I design the exercises to best align with the
desired outcomes?&lt;/p&gt;

&lt;h2 id=&quot;defining-the-outcomes-in-detail&quot;&gt;Defining the outcomes in detail&lt;/h2&gt;

&lt;p&gt;Abstract concepts in a graduate course ought to be expressed via one
of the higher-level categories of the
&lt;a href=&quot;http://www.celt.iastate.edu/teaching/effective-teaching-practices/revised-blooms-taxonomy&quot;&gt;cognitive process dimension of the revised Bloom Taxonomy&lt;/a&gt;,
using verbs such as “analyze”, “evaluate”, or “create”.  As is typical
with applications of this taxonomy, the level at which to categorize a
given outcome is sensitive to how we frame it. For example, consider
the learning outcome of “student will be able to profile the
distribution of latencies for a microservice”. At first, this might
seem like “analyze”, with its implication of attribution. But if the
students are asked to contrast this profile with a specified Service
Level Objective (SLO), the process is arguably “evaluate”. On further
consideration, latency profiling requires designing a test plan,
specifying input distributions, adding metrics, and creating a final
report—processes more directly fitting “create”.&lt;/p&gt;

&lt;p&gt;The learning outcome could be set as any of the three verbs,
“Analyze”, “Evaluate”, or “Create”, depending upon the emphasis of the
instructor.&lt;/p&gt;

&lt;h2 id=&quot;from-learning-what-they-do-&quot;&gt;From learning what they do …&lt;/h2&gt;

&lt;p&gt;Having specified the detailed outcome, we can now create an activity
whose performance leads the student to that outcome.&lt;/p&gt;

&lt;p&gt;A typical activity will ask the students to build
something and as part of that assignment, analyze the performance of
what they build.&lt;/p&gt;

&lt;p&gt;But consider this from the Biggs perspective, that what the student &lt;em&gt;does&lt;/em&gt;
is what the student &lt;em&gt;learns&lt;/em&gt;.  What are students spending most of
their time doing?  Programming, of course.  Designing (well, not
really, but in a perfect course, they would design), coding, testing,
debugging, coding some more, integrating, and arguing about what to do
next and which team member needs to contribute more.&lt;/p&gt;

&lt;p&gt;How much time have they spent profiling the latency? Well, they could
only do that after the system is built and almost reliable—a tiny
window at the end of a multi-week programming frenzy.  Human
memory records most clearly the activities upon which the learner spent the
most time and attention. Given how much more time they spent building
the system than instrumenting and tuning it, their strongest
memory will be programming.&lt;/p&gt;

&lt;p&gt;This is reflected in how the students respond to job interviews.  When
asked to summarize what they did in class (itself a misdirecting
question, focusing the students on their activities and not on the
principles nominally guiding those activities), they will reply, “We
built a distributed system in [language X]” rather than “We measured
latency and tuned the architecture to achieve our Service
Objectives”.&lt;/p&gt;

&lt;h2 id=&quot;to-doing-what-we-want-them-to-learn&quot;&gt;… to doing what we want them to learn&lt;/h2&gt;

&lt;p&gt;To increase the mindshare occupied by the intended learning outcome,
we have to reduce the time spent on less relevant activities and
increase the time spent on activities directly relevant to the
outcome. In our example case, we want to reduce the time spent
programming and increase the time spent reasoning about the
performance implications of a program’s design. In fact, the key
metric is not really total time but &lt;em&gt;proportion&lt;/em&gt; of time. In an ideal
exercise, students would not work particularly long but &lt;em&gt;all&lt;/em&gt; their
time would be on activities directly achieving the learning outcome.&lt;/p&gt;

&lt;p&gt;Brevity is a desirable property for an exercise.  Long activities,
especially those the length of a major assignment, engender
substantial fatigue and stress, which reduce the amount and quality of
learning. Pushing the real outcome to the end of such an assignment,
as occurs with an instruction such as, “Measure your system’s
performance under a sample load and write up your analysis”, means
that students engage with the most important learning outcomes
precisely when their fatigue, stress, and deadlines most work against
effective learning.&lt;/p&gt;

&lt;h2 id=&quot;creating-environments-for-learning-skills-of-analysis&quot;&gt;Creating environments for learning skills of analysis&lt;/h2&gt;

&lt;p&gt;If “program an X and then analyze it” is ineffective for learning the
analysis skills (and probably isn’t particularly effective at teaching
them programming skills, either), what sorts of activity are
effective? Here’s some that I’ve come up with:&lt;/p&gt;

&lt;dl class=&quot;dl-indent&quot;&gt;
  &lt;dt&gt;Analyze a paper model&lt;/dt&gt;
  &lt;dd&gt;Provide a paper design, some sample output metrics, and ask them to
evaluate the system.  This sort of exercise focuses them directly on
the theory, considering how the pieces fit together, applying
formulas, and so forth. It might be a good prologue to working with an
actual system. It has the merit that with some computational support,
the instructor can give the class several distinct cases, reducing the
risk of cheating. It is of course the only sort of question you can
pose on an exam.&lt;/dd&gt;
  &lt;dt&gt;Analyze an interactive model&lt;/dt&gt;
  &lt;dd&gt;The instructor can build an interactive model, which the students
can analyze.  An interactive model can have hidden complexities that
the student has to tease out, an impossible challenge to create in a
paper exercise. Every group can be given different parameters,
reducing the risk of cheating. And the system might even do some
portion of the assessment automatically.  The primary disadvantage is
the effort to create the simulation.&lt;/dd&gt;
  &lt;dt&gt;Analyze a system they have already built&lt;/dt&gt;
  &lt;dd&gt;In this exercise, the students instrument, analyze, and perhaps tune
a system they built in another course or earlier in the same course.
This approach has some inherent interest for students, in that they
are improving a system in which they have some investment. It also
reduces system learning for those team members who developed the
original project. It has the further merit of reducing cheating, as
every group has their own project. The biggest risk is projects that
are too buggy or poorly-designed to instrument and get usable results.&lt;/dd&gt;
  &lt;dt&gt;Analyze a system provided by the instructor&lt;/dt&gt;
  &lt;dd&gt;In contrast to the approach of students instrumenting their own
system, in this style the instructor provides a system for them to
instrument and analyze. This has the advantage that the instructor is
assured that the system is correct and will yield interesting analyses
at a level attainable by this class. It also helps the instructor
grade, as the results will follow one of a few known patterns.  Its
two disadvantages are the risk of cheating when every group has the
same project, as well as the effort to create such a system.&lt;/dd&gt;
  &lt;dt&gt;Analyze a system selected from a public repository&lt;/dt&gt;
  &lt;dd&gt;Students could be asked to analyze a system selected from
repositories such as GitHub or BitBucket. This has mostly the same
advantages and disadvantages of using a system the students had
previously developed (though the students start with no prior
experience with the code).  It has the extra disadvantage of requiring
some gate-keeping by the instructor to ensure the students pick a
system that is likely to yield an interesting analysis.&lt;/dd&gt;
&lt;/dl&gt;

&lt;h2 id=&quot;so-what-will-i-do&quot;&gt;So what will I do?&lt;/h2&gt;

&lt;p&gt;Programming assignments are not particularly effective or efficient
ways for students to achieve non-programming learning outcomes.  But
they are one of the most efficient ways for the &lt;em&gt;instructor to set up
an exercise&lt;/em&gt;. All the alternatives that I’ve listed above, with the
possible exception of paper exercises, require significantly more
pre-class system development by the instructor.  I suspect the
instructor’s ease of developing programming assignments contributes to
their persistent use in many courses.&lt;/p&gt;

&lt;p&gt;I haven’t decided how to structure assignments for my upcoming data
engineering course.  This post has started my thinking about what I
might do. My time is limited before the course begins in
January 2019, so I must pick realistic goals.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Minimal OS and networking knowledge for a data engineering course</title>
   <link href="/2018/10/23/data-engineering-prerequisites/"/>
   <updated>2018-10-23T00:00:00-07:00</updated>
   <id>/2018/10/23/data-engineering-prerequisites</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Third in a series on designing a data engineering course.  The
 previous post presented
 &lt;a href=&quot;/2018/10/18/data-engineering-learning-outcomes/&quot;&gt;draft learning outcomes&lt;/a&gt;. The
 next post considers &lt;a href=&quot;/2018/10/26/assignments-with-coding-only-teach-coding/&quot;&gt;what exercises will best achive the learning outcomes&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Although the students in this course are expected to have a CS degree
or equivalent, most of them will have spent several years in
industry, long enough for the lessons from that degree to have faded.&lt;/p&gt;

&lt;p&gt;Many of the concepts listed in the
&lt;a href=&quot;2018/10/13/data-engineering-design-space/&quot;&gt;design space&lt;/a&gt; presume
familiarity with the topics in undergraduate operating systems and
networking courses.  Some of these topics, such as the basics of TCP,
are likely to have been kept fresh by use at work. Anyone building a
simple Web application has to know the basics of IP address and ports.
Other concepts, especially those concerned with synchronization and
communication between concurrent processes, will have become
unfamiliar from lack of use, to the extent students ever understood
them. Honestly, most students (incuding me!) complete their OS course
with an incomplete and imperfect understanding of that material.&lt;/p&gt;

&lt;p&gt;On the other hand, other students will enter the course with a strong
understanding of these concepts and an eagerness to learn the concepts
more deeply and apply them to data engineering.  These students will
be bored by repeating material they already know and see time spent on
them to be a lost opportunity to learn material new to them.  We don’t
want to bore them, often the most competent and motivated in
the cohort.&lt;/p&gt;

&lt;p&gt;Which raises the questions:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;What is the OS and networking knowledge that I should consider
prerequisite to the course and unnecessary to review?  If students
find this material unfamiliar, I simply point them to outside
resources as remedial learning.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What is the minimal OS and networking knowledge that I should
review in the course and in how much depth depth should I cover
it?&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;What is the best way to review this material, such that students
who have forgotten it can pick it up quickly while students who
already know it will remain interested?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I’ll begin by simply enumerating the required concepts from each domain.&lt;/p&gt;

&lt;h2 id=&quot;os-concepts&quot;&gt;OS concepts&lt;/h2&gt;

&lt;p&gt;Fortunately, only a subset of concepts from classical operating
systems that are essential to data engineering:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Process model
    &lt;ul&gt;
      &lt;li&gt;Process isolation&lt;/li&gt;
      &lt;li&gt;Virtual memory&lt;/li&gt;
      &lt;li&gt;Threads&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Kernel versus applications&lt;/li&gt;
  &lt;li&gt;Concurrency
    &lt;ul&gt;
      &lt;li&gt;Critical section and critical resource&lt;/li&gt;
      &lt;li&gt;Race conditions&lt;/li&gt;
      &lt;li&gt;Semaphore&lt;/li&gt;
      &lt;li&gt;Deadlock&lt;/li&gt;
      &lt;li&gt;Fairness&lt;/li&gt;
      &lt;li&gt;Starvation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Interprocess communication
    &lt;ul&gt;
      &lt;li&gt;Shared memory&lt;/li&gt;
      &lt;li&gt;Message passing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Scheduler&lt;/li&gt;
  &lt;li&gt;Priority&lt;/li&gt;
  &lt;li&gt;Resource allocation&lt;/li&gt;
  &lt;li&gt;Memory management
    &lt;ul&gt;
      &lt;li&gt;Internal versus external fragmentation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Memory hierarchy
    &lt;ul&gt;
      &lt;li&gt;Caching&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Context switching&lt;/li&gt;
  &lt;li&gt;Asynchronous vs. synchronous calls&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Bear in mind that the students will be familiar with using tools such
as file systems and even a distributed file system such as HDFS. I am
listing here OS internals that they need to understand.&lt;/p&gt;

&lt;h3 id=&quot;new-concepts-in-operating-systems&quot;&gt;New concepts in operating systems&lt;/h3&gt;

&lt;p&gt;These concepts may have been touched upon in their undergraduate
course but they will not have been covered in depth (or never
even mentioned):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Virtualization
    &lt;ul&gt;
      &lt;li&gt;Virtual machine&lt;/li&gt;
      &lt;li&gt;Hypervisor&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Container
    &lt;ul&gt;
      &lt;li&gt;Leaks in process isolation&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Orchestration&lt;/li&gt;
  &lt;li&gt;Multi-level scheduler&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;networking-concepts&quot;&gt;Networking concepts&lt;/h2&gt;

&lt;p&gt;The basic concepts from an undergraduate networking course that they
need to know to do data engineering:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IP address
    &lt;ul&gt;
      &lt;li&gt;Port number&lt;/li&gt;
      &lt;li&gt;Well-known ports&lt;/li&gt;
      &lt;li&gt;Loopback address&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;TCP and UDP&lt;/li&gt;
  &lt;li&gt;Delivery guarantees
    &lt;ul&gt;
      &lt;li&gt;None (zero to unlimited copies delivered)&lt;/li&gt;
      &lt;li&gt;At most once&lt;/li&gt;
      &lt;li&gt;At least once&lt;/li&gt;
      &lt;li&gt;Exactly once&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Flow control&lt;/li&gt;
  &lt;li&gt;Remote procedure calls&lt;/li&gt;
  &lt;li&gt;Message buffering&lt;/li&gt;
  &lt;li&gt;Marshalling and serialization&lt;/li&gt;
  &lt;li&gt;Topology&lt;/li&gt;
  &lt;li&gt;Distinction between wide-area and local-area networks&lt;/li&gt;
  &lt;li&gt;Client-server architecture&lt;/li&gt;
  &lt;li&gt;Message signing&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;new-concepts-in-networking&quot;&gt;New concepts in networking&lt;/h3&gt;

&lt;p&gt;These concepts specifically relate to the current cloud architectures
of data centres, availability zones, and regions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Data centre networking
    &lt;ul&gt;
      &lt;li&gt;Bisection bandwidth&lt;/li&gt;
      &lt;li&gt;“Top-of-rack” (usually located in the middle of the rack) switch&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Relative latencies of within-centre, within-region, and
inter-region round trips&lt;/li&gt;
  &lt;li&gt;Shuffling (which exercises both the file system and the network)&lt;/li&gt;
  &lt;li&gt;Idempotent messages&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;topics-intrinsic-to-the-data-engineering-course&quot;&gt;Topics intrinsic to the data engineering course&lt;/h2&gt;

&lt;p&gt;The above lists comprise prerequisite knowledge of other domains.  The
bulk of the data engineering course will consist of topics specific to
this domain, such as those listed in the
&lt;a href=&quot;/2018/10/13/data-engineering-design-space/&quot;&gt;design space post&lt;/a&gt; and
the
&lt;a href=&quot;/2018/10/18/data-engineering-learning-outcomes/&quot;&gt;learning outcomes post&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Draft learning outcomes for data engineering course</title>
   <link href="/2018/10/18/data-engineering-learning-outcomes/"/>
   <updated>2018-10-18T00:00:00-07:00</updated>
   <id>/2018/10/18/data-engineering-learning-outcomes</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Second in a series about designing a professional master’s course on
 data engineering.  The first post laid out the
 &lt;a href=&quot;/2018/10/13/data-engineering-design-space/&quot;&gt;data engineering design space&lt;/a&gt;. The
 next post lists
 &lt;a href=&quot;/2018/10/23/data-engineering-prerequisites/&quot;&gt;prerequisite operating system and networking knowledge&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The draft learning outcomes for the data engineering course.&lt;/p&gt;

&lt;h2 id=&quot;course-summary&quot;&gt;Course summary&lt;/h2&gt;

&lt;p&gt;The one-paragraph course summary, as would be written in the
university calendar:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Data engineering turns a proof-of-concept data model into an
efficient, maintainable service well-matched to running in large-scale
data centres. Such services are resilient against failure of either
their own instances or a service dependency, deployed in a controlled
way, suited for co-tenancy with services with different latency goals,
instrumented to detect performance problems, and compatible with the
data centre scheduler. Data engineering ensures that the services run
all night while the operations staff sleep all night.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;learning-outcomes&quot;&gt;Learning outcomes&lt;/h2&gt;

&lt;p&gt;After completing the course, students will be able to:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Design space analysis:&lt;/strong&gt; Analyze the tradeoffs inherent in a
cloud service design. Situate the design in the overall
space. Suggest likely impacts of changes that move the design in
that space.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Service level metrics, indicators, objectives, and agreements:&lt;/strong&gt;
Describe the difference between each and apply the appropriate
type to a given design.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Resilience and recovery:&lt;/strong&gt; Estimate the resilience of a design to
various failures, test a service for resilience, and harden a
system to make it resilient in the face of failure.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Latency versus consistency:&lt;/strong&gt; Analyze a design’s tradeoffs
between latency when all replicas are connected versus the
consistency guarantees when some replicas are partitioned.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Data centre operating systems:&lt;/strong&gt; Differentiate the approaches to
managing the resources of a data centre (which can be viewed as the
operating system for a “computer” comprising the entire
centre). Configure a service to work with one or more of these
operating systems.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Instrumentation:&lt;/strong&gt; Classify the approaches to instrumenting a
system. Add instrumentation to a system to make visible a hidden
aspect of service performance.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Consensus:&lt;/strong&gt; Summarize the need for consensus, particularly for
service metadata. Differentiate the several algorithms and their
common implementations. Explain the relationship between the
consensus problem and consistency guarantees in the event of
replica failure.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;rationale&quot;&gt;Rationale&lt;/h2&gt;

&lt;p&gt;I consider learning outcomes both essential and unimportant.  On the
one hand, my thinking about a course is helped enormously when I define
5–8 broad outcomes for the course.  I generally follow the
categories of the
&lt;a href=&quot;http://www.celt.iastate.edu/teaching/effective-teaching-practices/revised-blooms-taxonomy&quot;&gt;Revised Bloom taxonomy&lt;/a&gt;
for the language of these outcomes. In particular, the Bloom
categories help me set the difficulty level that I want students
to master.&lt;/p&gt;

&lt;p&gt;On the other hand, I haven’t found the resulting outcomes
useful for actually generating assignments and assessments. In
principle, the assignments and assessments for an outcome should be
determined by where it falls in the taxonomy.  In practice, I’ve never
found the categorization to provide much guidance.  I suspect that
this is typical of the fourth-year and graduate courses that I have
been teaching, where the material emphasizes integration of
previously-learned concepts.  Indeed, at course end, I often have
difficulty relating the &lt;em&gt;actual&lt;/em&gt; content of the course to the outcomes
I specified at the outset.&lt;/p&gt;

&lt;p&gt;I still consider it worthwhile to develop outcomes but I don’t
necessarily observe them closely as the actual course unfolds.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The data engineering design space (2019 Edition)</title>
   <link href="/2018/10/13/data-engineering-design-space/"/>
   <updated>2018-10-13T00:00:00-07:00</updated>
   <id>/2018/10/13/data-engineering-design-space</id>
   <content type="html">&lt;p&gt;&lt;em&gt;First in a series on designing a course on data engineering.  The
 next post specifies the
 &lt;a href=&quot;/2018/10/18/data-engineering-learning-outcomes/&quot;&gt;learning outcomes&lt;/a&gt;.
 There is a version &lt;a href=&quot;/2019/12/31/design-space-2020/&quot;&gt;updated for 2020&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I will teach a course on Data Engineering in
Spring 2019. The course will be the second semester of a
professional graduate program in Big Data.&lt;/p&gt;

&lt;h2 id=&quot;student-background&quot;&gt;Student background&lt;/h2&gt;

&lt;dl&gt;
  &lt;dt&gt;Program entry requirements&lt;/dt&gt;
  &lt;dd&gt;Bachelor’s degree in CS or related field.&lt;/dd&gt;
  &lt;dt&gt;Courses students took in prior semesters&lt;/dt&gt;
  &lt;dd&gt;In their first semester, students will already have taken a course
on machine learning and a lab introducing them to technologies of
large-scale data analysis, including HDFS, Hadoop, Spark, Cassandra,
and HBase. Some may have taken electives in visualization or natural
language processing.&lt;/dd&gt;
  &lt;dt&gt;Courses students take concurrently&lt;/dt&gt;
  &lt;dd&gt;Concurrently with the data engineering course, they will be taking a
second lab, focussed on applied statistical analysis and machine
learning. They will also be taking an algorithms course including
Paxos and the Gilbert/Lynch CAP Theorem.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Many students will be entering the course straight from their first
semester. A few will be taking it in their last semester, after
completing an eight-month paid internship in a big data-related role.
For this last group, this would be an elective in their final
semester.&lt;/p&gt;

&lt;h2 id=&quot;data-engineering-from-data-model-to-cloud-ready-data-service&quot;&gt;Data engineering: From data model to cloud-ready data service&lt;/h2&gt;

&lt;p&gt;Data engineering is the practice of transforming a proof of concept data
science model into a production-quality service. Amongst other things,
this may include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Hardening the system against failure&lt;/li&gt;
  &lt;li&gt;Making the model more efficient&lt;/li&gt;
  &lt;li&gt;Parallelizing a single-process model&lt;/li&gt;
  &lt;li&gt;Reimplementing the model in a language more suited to
production environments&lt;/li&gt;
  &lt;li&gt;Automating the handling of exceptional cases such as data in the
wrong format&lt;/li&gt;
  &lt;li&gt;Adding instrumentation to monitor system performance, input data
drift, gray failures, and other issues&lt;/li&gt;
  &lt;li&gt;Automating deployment of revisions, including backout in the case of failure&lt;/li&gt;
  &lt;li&gt;Adding admission controls and feature switches for restarting after failure&lt;/li&gt;
  &lt;li&gt;Working with the data centre scheduler and orchestration services to
ensure that the service is compatible with any services
co-tenant on its instance and with the data center as a whole&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most of these practices are central to any component of
service-oriented architectures running in a large data
centre. Although these data centres may be hosted in a variety of
ways—by a commercial service, on-premise, or hybrid—I will
group them under the single term, “cloud”.&lt;/p&gt;

&lt;p&gt;The one-sentence summary of all these improvements is &lt;strong&gt;making a data model
cloud-ready&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;approach&quot;&gt;Approach&lt;/h2&gt;

&lt;p&gt;Given the lengthy topic list that follows, the course can only provide
a broad survey, not deep understanding. The importance of these topics
extends beyond data engineering. If the students become comfortable
with these concepts, they will be prepared for a broad range of roles
in cloud computing, well beyond services for data analysis.&lt;/p&gt;

&lt;h2 id=&quot;the-design-space-of-cloud-services&quot;&gt;The design space of cloud services&lt;/h2&gt;

&lt;p&gt;I have taught cloud computing to undergraduates three times.  Every
time I regretted not setting out clear definitions of the foundational
properties characterizing such systems. Beyond giving students a
language to discuss the topics, this establishes the &lt;em&gt;design space&lt;/em&gt;
for course discussions and within which to evaluate designs. These
properties are also the measures of system success.&lt;/p&gt;

&lt;p&gt;These properties can be applied to the system as a whole; many also
characterize system components.&lt;/p&gt;

&lt;h2 id=&quot;metrics---measured-properties-of-the-system&quot;&gt;Metrics—measured properties of the system&lt;/h2&gt;

&lt;p&gt;Metrics are measurable properties of the system. They reflect the
match between system architecture and use.&lt;/p&gt;

&lt;p&gt;In addition to learning the following concepts, students need to become familiar
with representing the distributions of metrics via key percentiles
(50th, 75th, 90th, …). Students also need to understand the impact
of “long tail” high percentiles, such as the 99th, on aggregate system
performance.&lt;/p&gt;

&lt;p&gt;Metrics can be part of &lt;a href=&quot;#objectives&quot;&gt;objectives&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;system-performance-metrics&quot;&gt;System performance metrics&lt;/h3&gt;

&lt;p&gt;These metrics characterize the system itself, running on a
representative workload:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency&lt;/li&gt;
  &lt;li&gt;Throughput&lt;/li&gt;
  &lt;li&gt;Scalability&lt;/li&gt;
  &lt;li&gt;Availability&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-centre-fabric-metrics&quot;&gt;Data centre fabric metrics&lt;/h3&gt;

&lt;p&gt;These metrics characterize the design of the data centre&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Processor performance&lt;/li&gt;
  &lt;li&gt;Clock variability&lt;/li&gt;
  &lt;li&gt;Bisection bandwidth&lt;/li&gt;
  &lt;li&gt;Likelihood of component failures&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inter-data-centre-round-trip-metrics&quot;&gt;Inter-data centre round trip metrics&lt;/h3&gt;

&lt;p&gt;For systems running on multiple data centres, perhaps in different
continents, we need to consider the round trip times:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Between availability zones in one region&lt;/li&gt;
  &lt;li&gt;Between regions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;business-metrics&quot;&gt;Business metrics&lt;/h3&gt;

&lt;p&gt;As described in
&lt;a href=&quot;https://www.oreilly.com/webops-perf/free/chaos-engineering.csp&quot;&gt;Chaos Engineering, pp. 22–23&lt;/a&gt;,
business metrics are specific to your application. They measure how
successfully the application is serving clients and meeting its
purpose. The measurement is often indirect, using some metric as a
proxy for the actually desired indicator, such as “real time customer
satisfaction”.  For example, Netflix measures the number of times the
“start” button is pressed per second.  As their service ultimately is
about streaming video, an unexpected drop in start presses indicates
the service is not meeting its purpose.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Specific to application, measuring “service success” or “client
satisfaction” (often indirectly)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;guarantees-and-invariants-inherent-properties-of-the-systems-design&quot;&gt;Guarantees and invariants: Inherent properties of the system’s design&lt;/h2&gt;

&lt;p&gt;Whereas metrics are measurable attributes of a system that can vary with
such factors as system load, properties are fundamental to the
system’s design. For example, the design either replicates durable
data or it does not.&lt;/p&gt;

&lt;h3 id=&quot;guarantees-for-durable-data&quot;&gt;Guarantees for durable data&lt;/h3&gt;

&lt;p&gt;Durable data is stored by the system on behalf of the users, typically
on disk or solid-state storage. What sort of guarantees does the
system provide on this data?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Replication for durability&lt;/li&gt;
  &lt;li&gt;Replication for availability&lt;/li&gt;
  &lt;li&gt;Synchronous vs. asynchronous writes&lt;/li&gt;
  &lt;li&gt;Consistency guarantees&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In principle, consistency guarantees can be made for ephemeral data that only
ever resides in memory but in most cases only eventual consistency
is provided, minimizing processing cost.&lt;/p&gt;

&lt;h3 id=&quot;instrumentation&quot;&gt;Instrumentation&lt;/h3&gt;

&lt;p&gt;How well does the system support monitoring its current state and
diagnosing problems:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Logs&lt;/li&gt;
  &lt;li&gt;Dashboards&lt;/li&gt;
  &lt;li&gt;Probes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;fault-tolerance&quot;&gt;Fault tolerance&lt;/h3&gt;

&lt;p&gt;How well does the system tolerate failure of its own components and
the services and data centre fabric upon which it depends:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Tolerance of component failures within the system&lt;/li&gt;
  &lt;li&gt;Tolerance of failure of external services upon which this depends&lt;/li&gt;
  &lt;li&gt;Tolerance of larger system failures (availability zone, region,
transoceanic partition, …)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;How well does it support failure, diagnosis, repair, and restart:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Diagnostic logs&lt;/li&gt;
  &lt;li&gt;Canary deployments&lt;/li&gt;
  &lt;li&gt;Admission control&lt;/li&gt;
  &lt;li&gt;Feature switches&lt;/li&gt;
  &lt;li&gt;Approximate results&lt;/li&gt;
  &lt;li&gt;Other engineering techniques&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;business-logic-invariants&quot;&gt;Business logic invariants&lt;/h3&gt;

&lt;p&gt;Business logic invariants are the business property counterparts of
business metrics:  The guarantees the system makes for entities that
the system’s clients care about.  For example, banks maintain the
invariant that if you transfer money between two accounts, the amount
taken from one equals the amount added to the other.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.researchgate.net/publication/220476881_CAP_Twelve_years_later_How_the_Rules_have_Changed&quot;&gt;Eric Brewer notes&lt;/a&gt;
that many business invariants are only implicitly specified for
single-processor systems, which typically guarantee strong
consistency.  When consistency guarantees are loosened (see
“Properties of durable data” above) to migrate the system to a
distributed implementation, the business invariants need to be
specified explicitly.&lt;/p&gt;

&lt;p&gt;Business invariants often must specify a mitigation procedure, to
resolve any violations (see the Brewer article cited above). For
example, what is the process for redressing an error in an account’s
balance, whether due to system defect or human error?&lt;/p&gt;

&lt;h3 id=&quot;automated-deployment&quot;&gt;Automated deployment&lt;/h3&gt;

&lt;p&gt;In addition to readying the initial release for production, the
service will require automated support for deploying updates.&lt;/p&gt;

&lt;h2 id=&quot;objectives&quot;&gt;Indicators and objectives&lt;/h2&gt;

&lt;p&gt;The above metrics, guarantees, and invariants shape the design space of the
architecture for modern cloud systems.  As such, they are
direct concerns of the the development and operations staff. In
addition, they may be exposed to clients as indicators and
even contractual obligations. 
As defined in
&lt;a href=&quot;https://landing.google.com/sre/book/chapters/service-level-objectives.html&quot;&gt;Site Reliability Engineering, Ch. 4&lt;/a&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Service Level Indicators (SLI)&lt;/li&gt;
  &lt;li&gt;Service Level Objectives (SLO)&lt;/li&gt;
  &lt;li&gt;Service Level Agreements (SLA)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;development-process-metrics&quot;&gt;Development process metrics&lt;/h2&gt;

&lt;p&gt;The above metrics and properties characterize the system’s design and
performance. Other metrics characterize the development process:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Velocity of feature development (&lt;a href=&quot;https://www.oreilly.com/webops-perf/free/chaos-engineering.csp&quot;&gt;Chaos Engineering, p. 9&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;inherent-limitations-of-distributed-systems&quot;&gt;Inherent limitations of distributed systems&lt;/h2&gt;

&lt;p&gt;Decades of study and practice in distributed systems have yielded
principles and rules of thumb characterizing all such
systems. As modern cloud systems are a species of
distributed system, their designers must account for how these issues
arise in this context.&lt;/p&gt;

&lt;p&gt;Properties of distributed systems that must be accounted for (from
&lt;a href=&quot;http://www.cs.mcgill.ca/~navindra/kde-devel/kwn-18/smli_tr-94-29.ps.gz&quot;&gt;Waldo et al., 1994&lt;/a&gt;):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency&lt;/li&gt;
  &lt;li&gt;Message-passing architecture (no shared memory)&lt;/li&gt;
  &lt;li&gt;True concurrency&lt;/li&gt;
  &lt;li&gt;Partial failure (process, service, and machine failure)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;No common system clock
(&lt;a href=&quot;https://www.microsoft.com/en-us/research/publication/time-clocks-ordering-events-distributed-system/&quot;&gt;Lamport, 1978&lt;/a&gt;):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Systems must use some variant of &lt;a href=&quot;https://queue.acm.org/detail.cfm?id=2917756&quot;&gt;logical clocks&lt;/a&gt;, vector clocks, or
interval clocks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing&quot;&gt;“The Eight Fallacies of Distributed Computing”&lt;/a&gt;
(rephrased as statements about how distributed systems &lt;strong&gt;actually&lt;/strong&gt;
work):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The network is unreliable (messages can be out of order or lost, or
connectivity may be dropped altogether).&lt;/li&gt;
  &lt;li&gt;Latency is non-zero.&lt;/li&gt;
  &lt;li&gt;Bandwidth is finite.&lt;/li&gt;
  &lt;li&gt;The network is insecure.&lt;/li&gt;
  &lt;li&gt;Topology changes.&lt;/li&gt;
  &lt;li&gt;There are multiple administrators.&lt;/li&gt;
  &lt;li&gt;Transport cost is non-zero.&lt;/li&gt;
  &lt;li&gt;The network is heterogenous.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The design space for production cloud-based data services is huge. The
service architect and implementation team must trade off between many
conflicting goals and build a service that integrates well with the
operations of the organization as a whole. This design process turns a
robust, accurate data model—the kernel of a service but not an
actual service—into a production service.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Myth-spotting</title>
   <link href="/2018/10/03/myth-spotting/"/>
   <updated>2018-10-03T00:00:00-07:00</updated>
   <id>/2018/10/03/myth-spotting</id>
   <content type="html">&lt;p&gt;As part of a larger project, I’m reading many articles from the
management literature. This is a very different kind of writing and
argument than I’m used to in the technical side of computing. The
management literature (including the literature on management of
computing personnel and projects) is also prone to fads, to such a
degree that Harvard Business Review has an article on
&lt;a href=&quot;https://hbr.org/2002/10/spotting-management-fads&quot;&gt;spotting management fads&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In addition to fads, management theory is also prone to myths. Where a
fad is often closely tied to its major proponent, who typically
derives a steady consulting revenue from it, myths are more widely
accepted. Where the instigation of a fad can be precisely traced,
typically to a publication such as
&lt;a href=&quot;https://en.wikipedia.org/wiki/The_One_Minute_Manager&quot;&gt;The One-Minute Manager&lt;/a&gt;,
the source of a myth is impossible to locate. It’s just always seemed
to be there, a piece of received wisdom, and only on close examination
does the viewer start to question it: “Everyone accepts it—but has
any one &lt;em&gt;demonstrated&lt;/em&gt; it?”&lt;/p&gt;

&lt;h2 id=&quot;an-example-myth&quot;&gt;An example myth&lt;/h2&gt;

&lt;p&gt;An example of a widely-accepted myth is the so-called
“&lt;a href=&quot;https://en.wikipedia.org/wiki/Yerkes%E2%80%93Dodson_law&quot;&gt;Yerkes-Dodson Law&lt;/a&gt;”.
I say so-called because neither Yerkes nor Dodson codified it into a
law. As Michael Corbett recounts in his excellent paper,
&lt;a href=&quot;https://www.tandfonline.com/doi/abs/10.1080/14759551.2013.815619&quot;&gt;“Cold Comfort Firm: Lean Organisation and the Empirical Mirage of the Comfort Zone”&lt;/a&gt;
(whose broader argument I will return to in a later post), their
experiments were published in 1908 but it was only in 1957 that
Broadhurst published a paper codifying their results as a broader
“law”. The original data from Yerkes and Dodson in fact
contradicts the typical presentation as a U-shaped graph (contrast the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Yerkes%E2%80%93Dodson_law&quot;&gt;“Original” and “Hebbian” versions&lt;/a&gt;
of the graph on Wikipedia).&lt;/p&gt;

&lt;p&gt;Yet despite this longstanding inaccuracy, management theories, such as
performance management, continue to base their recommendations on
Yerkes and Dodson’s “law” and its supposed support for a
&lt;a href=&quot;https://en.wikipedia.org/wiki/Comfort_zone&quot;&gt;“comfort zone”&lt;/a&gt;. What is
it about such myths that ensures their persistence, even in the face
of well-grounded contradictory evidence, and is there anything about
the structure of such claims that suggests it might be a myth?&lt;/p&gt;

&lt;h2 id=&quot;why-do-we-want-to-believe-myths&quot;&gt;Why do we want to believe myths?&lt;/h2&gt;

&lt;p&gt;Myths persist because they serve a need: They help people navigate
complex questions by providing easy answers that appear on their face
to be valid. When first told the typical (mis)presentation of the
Yerkes-Dodson results, that moderate stress encourages highest
performance, while too little and too much stress reduce performance,
it makes sense. We have typically had experiences where the right
stakes—neither trivial nor life-threatening but the possibility of
meaningful gains—improved our focus. We have also probably had days
where we weren’t motivated to budge from the couch and others where
the prospect of failure shrank our creativity or even froze us
outright.&lt;/p&gt;

&lt;p&gt;The problem with a myth is that it only &lt;em&gt;conforms&lt;/em&gt; to experience but it does
not actually &lt;em&gt;explain&lt;/em&gt; it. The myth lays out a pattern into which we
can place a few experiences selected to match. The cycle is quick and
subtle:  The myth provides a pattern, we locate a few experiences
within that pattern, which we then interpret as validating the pattern
set out by the myth.&lt;/p&gt;

&lt;p&gt;This approach differs from how we interpret actual, well-demonstrated
results in social psychology, such as the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Fundamental_attribution_error&quot;&gt;fundamental attribution error&lt;/a&gt;.
In those cases, the original supporting evidence is a broad series of
experiments, covering a wide range of circumstances. When we then hear
of the principle and organize some of our own experiences according to
the pattern, we are &lt;em&gt;sense-making&lt;/em&gt;, integrating the principle into our
experience, testing it out. Although we may be testing whether it is
appropriate to our life and how it may fit with our established
principles and values, we are not validating it. The validation
preceded our learning about the result, during the period of testing
in the literature.&lt;/p&gt;

&lt;h2 id=&quot;the-marks-of-a-myth&quot;&gt;The marks of a myth&lt;/h2&gt;

&lt;p&gt;Superficially, both well-grounded results and myths will appear to be
supported by the literature. The definitive test is to do a detailed
review of the primary literature but this is impractical: We do not have
time to track down the sources of every claim, however
widely-believed. On the other hand, brute contrarianism, the automatic
gainsaying of all received knowledge, is a dead end as well. Are there
strong surface indicators of a myth that might warn us not to take a
claim as stated?&lt;/p&gt;

&lt;p&gt;I believe such markers exist. This post is a draft of my approaches to
testing a broad, widely-repeated principle to assess the likelihood
that it can guide successful action or is just a well-meaning
platitude.&lt;/p&gt;

&lt;h2 id=&quot;mark-1-broad-vague-terms&quot;&gt;Mark 1: Broad, vague terms&lt;/h2&gt;

&lt;p&gt;Myths traffic in broad, vague terms. In fact, myths probably require
terms that sweep the horizon, encompassing the largest possible range.
This provides an essential advantage: The myth appears to apply to any
situation, all depending upon how the viewer interprets its key terms.&lt;/p&gt;

&lt;p&gt;Consider the Yerkes-Dodson “law”. Although it is frequently described
in the management literature as the effect of changes in “stress” on
“performance”, Yerkes and Dodson’s original work used the more
technical psychological concept of
&lt;a href=&quot;https://en.wikipedia.org/wiki/Arousal&quot;&gt;arousal&lt;/a&gt;, which has
measurable indirect correlates in heart rate and blood pressure, as
well as more direct correlates in activation of the ascending
reticular activating system. In actual fact, Yerkes and Dodson did not
measure any correlates at all, instead choosing to vary the external
stimulus, an electrical shock.&lt;/p&gt;

&lt;p&gt;Varying the external stimulus was an entirely acceptable choice for
Yerkes and Dodson, given their goals and the technology of the time.
The problem enters when this experimental operationalization is
glossed as “stress” by those who want to apply it to management
theory. Although there is face value in associating greater “stress”
with an increase in electrical shock, the actual relationship is
complex. In commmon use, “stress” refers to a complex mix of
physiological and psychological characteristics. The measurements
recorded by Yerkes and Dodson provide no way to assess the level of
“stress” experienced by the mice in their experiments. Perhaps it was
a linear relationship, perhaps logarithmic, perhaps quadratic, perhaps
its form varied piecewise over several distinct ranges. There is no
way to know. This ambiguity works to the advantage of the myth-makers,
as the listener interprets the terms within their existing biases.&lt;/p&gt;

&lt;h2 id=&quot;mark-2-conflating-description-and-judgement&quot;&gt;Mark 2: Conflating description and judgement&lt;/h2&gt;

&lt;p&gt;If the first part of a myth is framing the relationships between
variables denoted by broad terms, the second part exploits the connotations
of those terms.&lt;/p&gt;

&lt;p&gt;Mythmakers not only prefer terms sufficiently vague to be broadly
applied, they also prefer to use those terms in a manner that
conflates description and judgement. Consider the term “stress”. On
the one hand, that term is descriptive, characterizing a form of
experience, one that can even be operationalized as measurable
correlates. But it also, especially in contemporary usage, has an
emotional valence, a connotation of undesirability. Stress is
something to avoid, a situation to minimize or from which to be rescued,
and in sufficient quantity is even a risk to your health.&lt;/p&gt;

&lt;p&gt;To a management myth-maker, this conflation of description and
judgement is not a problem but a &lt;em&gt;resource&lt;/em&gt;. The descriptive element
implies an objective, measurable, “scientific” aspect, while the
unpleasant connotation gets the listener’s attention. “We’re talking
about &lt;em&gt;stress&lt;/em&gt; after all, and who wants too much of that?”. Better
still if it can be exploited for
&lt;a href=&quot;http://www.slate.com/blogs/browbeat/2009/10/22/the_slate_pitch_twitter_meme.html&quot;&gt;contrarian spin&lt;/a&gt;,
such as “Stress can be a good for you—here’s why!”.&lt;/p&gt;

&lt;p&gt;Combining denotation and connotation serves another purpose for the
mythmaker as well: It reduces a complex relationship to a single
dimension.  But this post is already long enough, so I will save that
part for the next post.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The vision: A culture of effective meetings</title>
   <link href="/2018/09/26/the-vision-a-culture-of-effective-meetings/"/>
   <updated>2018-09-26T00:00:00-07:00</updated>
   <id>/2018/09/26/the-vision-a-culture-of-effective-meetings</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Seventh and final post in a series on group decision-making, based on
Ch. 10–11 of
&lt;a href=&quot;https://www.amazon.com/Making-Meetings-Work-Achieving-Decisions/dp/0761927050/&quot;&gt;Making Meetings Work&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The series:&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/08/13/the-best-process-for-group-decisions/&quot;&gt;Introduction. Decision rules.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/08/24/decision-crystallization/&quot;&gt;Overview of decision crystallization.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/08/29/the-decision-mosaic-every-piece-in-place/&quot;&gt;The decision mosaic and the determinative element.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/09/05/discussion-rounds-and-decision-crystallization/&quot;&gt;Crystallizing a decision at the end of a round.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/09/16/learning-decision-crystallization/&quot;&gt;Learning to crystallize decisions.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/09/21/decision-sculpting/&quot;&gt;Reviewing and refining the decision as a whole.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;A culture of effective meetings (this post).&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;what-good-meetings-can-do&quot;&gt;What good meetings can do&lt;/h2&gt;

&lt;p&gt;This series of posts has gone into detail about the core function of
meetings: making effective decisions. Successful meetings have other
facets as well.  An effective meeting is&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;preceded&lt;/em&gt; with appropriate preparation, by both the chair
and the regular members,&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;managed&lt;/em&gt; to ensure full participation and safety of all members, and&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;followed up&lt;/em&gt; with one-on-one or small-group discussions, minutes,
and assigned actions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Tropman’s book provides useful, detailed advice for all these phases.
It’s well worth reading the whole thing and applying his advice.&lt;/p&gt;

&lt;p&gt;Yet the focus of all this, the apogee of the meeting’s arc, is making
decisions.  Consistently get that right, achieve real agreement
from all interested parties, address all concerns, stay within any
strong boundaries drawn by management or expertise, and your
group will be energized by a sense of progress.&lt;/p&gt;

&lt;p&gt;Several years after I began seriously practicing these ideas, I had an
experience at the university that affirmed their value. It was a week
when I chaired two meetings. I was the only common member between the
two groups and in fact their areas of responsibility were distinct:
one was concerned with policies within our department, the other with
universy-wide policy.  At the end of the first day’s meeting, a member
spontaneously said, “That was a great meeting”.  At the end of the
second day’s meeting, a member of that group exclaimed, “That was the
best meeting I’ve ever attended!”. One of the favourite weeks of my
academic career.&lt;/p&gt;

&lt;p&gt;Dare to imagine meetings like that: Ones that the participants
look forward to, which they view with a sense of ownership, where they can
influence the course of their work, and where their voices are heard
and valued. It’s possible, it’s practical, and you can do it. What are
you waiting for?&lt;/p&gt;

&lt;h2 id=&quot;coming-up-&quot;&gt;Coming up …&lt;/h2&gt;

&lt;p&gt;I want to spend a few posts on issues that have accumulated while
writing this series. After that, I expect to consider a higher level
of soft skills, the practice of innovation as described in Denning and
Dunham’s &lt;a href=&quot;http://innovators-way.com/&quot;&gt;The Innovator’s Way&lt;/a&gt;.  Their book
has some strong similarities to Tropman’s but also
some distinct differences. Stay tuned!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Decision sculpting: Stepping back to see the whole mosaic</title>
   <link href="/2018/09/21/decision-sculpting/"/>
   <updated>2018-09-21T00:00:00-07:00</updated>
   <id>/2018/09/21/decision-sculpting</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Sixth in a series on group decision-making, based on Ch. 10–11
of
&lt;a href=&quot;https://www.amazon.com/Making-Meetings-Work-Achieving-Decisions/dp/0761927050/&quot;&gt;Making Meetings Work&lt;/a&gt;.
The previous post suggested
&lt;a href=&quot;/2018/09/16/learning-decision-crystallization&quot;&gt;ways to learn the skill of decision crystallization&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;zooming-from-the-mosaic-to-a-few-tiles-&quot;&gt;Zooming from the mosaic to a few tiles …&lt;/h2&gt;

&lt;p&gt;The last four posts in this series have focused on Chapter 11 of
Tropman’s book, describing how to guide a group to an effective
decision.  I began by defining the
&lt;a href=&quot;/2018/08/29/the-decision-mosaic-every-piece-in-place/&quot;&gt;decision mosaic&lt;/a&gt;,
the many small consitutents comprising a typical decision, called the
&lt;em&gt;decision elements&lt;/em&gt;.  Of these elements, a few—often just one—set
the context for most others. This element is called the &lt;em&gt;determinative
element&lt;/em&gt;. If there are several candidates for determinative element,
simply pick one.&lt;/p&gt;

&lt;p&gt;Focus the group on the determinative element until a &lt;em&gt;discussion
round&lt;/em&gt; has completed. Note the points made and how members support and
critique the points.&lt;/p&gt;

&lt;p&gt;At the end of the round,
&lt;a href=&quot;/2018/09/05/discussion-rounds-and-decision-crystallization/&quot;&gt;crystallize the decision&lt;/a&gt;. If
the group agrees on the proposed choice, refocus the group on a new
determinative element.  If the group does not accept it, start a new
discussion round focused on alternatives to previously-discussed choices.&lt;/p&gt;

&lt;h2 id=&quot;and-back-out-to-the-mosaic-as-a-whole&quot;&gt;… and back out to the mosaic as a whole&lt;/h2&gt;

&lt;p&gt;At some point, perhaps in this meeting or, in the case of a
particularly complex decision, after several meetings, all decision
elements will be decided.  Now is the time to consider the decision as
a whole.  Tropman calls this final step of the decision process,
&lt;em&gt;decision sculpting&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Until now, the group has proceeded one element at a time, making a
series of small choices.  The sequence of these, working on
the most consequential remaining choice as the determinative element,
has helped ensure that the choices were mutually compatible.  Yet this
only ensures a rough compatibility.&lt;/p&gt;

&lt;p&gt;Recall Tropman’s metaphor of a decision
mosaic:  an arrangement of small tiles that create a coherent image
when seen as a whole. The group has spent its time ensuring that each
piece is well-seated next to its immediate neighbours but they
have not reviewed the resulting image. Now that all decision elements have been
resolved, it is time to review the whole decision.&lt;/p&gt;

&lt;p&gt;Ask the group to consider all their choices as a package. Seen
together, are there small improvements or adjustments that would make
them more harmonious? Are there any missing pieces? Depending upon the
group and the decision, you may wish to let the proposal sit for a day
or a week before reviewing it. Take the time to
make the final package not just acceptable but brilliant.&lt;/p&gt;

&lt;p&gt;You may be concerned that revisiting the decision will simply reignite
old controversies. Although this can happen with decisions made using
typical ad hoc, chaotic processes, decisions crafted using this
process will be remarkably stable. Every choice was supported by
several
&lt;a href=&quot;/2018/08/13/the-best-process-for-group-decisions/&quot;&gt;decision rules&lt;/a&gt;,
each highlighting the needs of a different constituency.  Even groups
who did not get their preferred outcome will be comfortable with the
final decision because their concerns were heard and validated during
the discussion.&lt;/p&gt;

&lt;h2 id=&quot;wrapping-up-and-moving-on&quot;&gt;Wrapping up and moving on&lt;/h2&gt;

&lt;p&gt;Once sculpting is complete, you have a decision. Congratulations!
There will often be a genuine positivity in the group, an energy going
forward to its implementation, even an excitement. It’s a great
feeling—and once a group has experienced it a few times, they will
be eager to adopt processes that make it the likely outcome rather
than the exception.&lt;/p&gt;

&lt;p&gt;In my final post in this series, I will consider how consistent use of
this process can transform an organization.  I will also tease my next
series on the topic of soft skills.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Three evidence-based books for better teaching</title>
   <link href="/2018/09/19/three-evidence-based-books-for-better-teaching/"/>
   <updated>2018-09-19T00:00:00-07:00</updated>
   <id>/2018/09/19/three-evidence-based-books-for-better-teaching</id>
   <content type="html">&lt;p&gt;I’ve read many books on effective university education, covering a
range of topics and perspectives.  An annotated bibliography of them
all would be a &lt;em&gt;long&lt;/em&gt; post.&lt;/p&gt;

&lt;p&gt;At any given time, however, there’s a small subset of those books that
directly drive my decisions.  Here are three books that I refer to
routinely in my current course designs.&lt;/p&gt;

&lt;p&gt;All three take an evidence-based approach, grounding their claims of
effectiveness in reliably-determined research results.  From this
broad starting point, they travel to distinct destinations, at very
different levels: the big issues of teaching (practice, motivation,
assessment, …), specific activities you can ask your students to
perform, and myths that have entered into received wisdom.&lt;/p&gt;

&lt;p&gt;I am intimidated by the effort it must have required to prepare each
of these books.  The authors had to read and synthesize the results
from hundreds of papers, discarding those with questionable research
designs or low experimental power.  Then they had to derive their
synthesis at a more abstract level, isolating broader principles that
might be applied in a range of teaching contexts.  This is a
tremendous service, as few instructors will have the time to read even
a fraction of the requisite articles.&lt;/p&gt;

&lt;p&gt;These very different books complement each other well. Read them,
apply their ideas, and your own teaching will surely improve.  They
demonstrate the value of an evidence-based approach to the teaching
literature.  Let’s have more like these.&lt;/p&gt;

&lt;p&gt;The first two recommendations are courtesy of
&lt;a href=&quot;http://third-bit.com/&quot;&gt;Greg Wilson&lt;/a&gt;, whose writings and conversations
have had a tremendous impact on my teaching.&lt;/p&gt;

&lt;h2 id=&quot;informed-principles-your-overall-course-design&quot;&gt;Informed Principles: Your Overall Course Design&lt;/h2&gt;

&lt;p&gt;This first book is the single best starting starting point for
course and curriculum design.
&lt;a href=&quot;https://www.wiley.com/en-us/How+Learning+Works%3A+Seven+Research+Based+Principles+for+Smart+Teaching-p-9780470484104&quot;&gt;How Learning Works: Seven Research-Based Principles for Smart Teaching&lt;/a&gt;
is organized around seven “research-based principles”:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Students’ prior knowledge can help or hinder their learning.&lt;/li&gt;
  &lt;li&gt;The way students organize knowledge influences how they learn and
apply what they know.&lt;/li&gt;
  &lt;li&gt;Students’ motivation generates, directs, and sustains what they do
to learn.&lt;/li&gt;
  &lt;li&gt;To develop mastery, students must acquire component skils, practice
integrating them, and know when to apply what they have learned.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Goal-directed&lt;/em&gt; practice coupled with &lt;em&gt;targeted&lt;/em&gt; feedback are
critical to learning.&lt;/li&gt;
  &lt;li&gt;Students’ current level of development interacts with the social,
emotional, and intellectucal climate of the course to impact learning.&lt;/li&gt;
  &lt;li&gt;To become self-directed learners, students must learn to assess the
demands of the task, evaluate their own knowledge and skills, plan
their approach, monitor their progress, and adjust their strategies
as needed.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;As ever, the details are what really matters and the authors deliver
those in abundance, identifying the elements instructors have to
have in place to successfully support these principles and create the
most effective learning environment for their students. All claims are
supported by references to reliably-supported research results.&lt;/p&gt;

&lt;p&gt;With its focus on broad principles arching over all of education,
regardless of level and domain, this book provides a modern,
evidence-grounded framework for thinking about any course.&lt;/p&gt;

&lt;p&gt;This is the sort of book that one has to read multiple times, with
intervening gaps of practice, to derive most benefit. Writing this
summary has reminded me it’s time for a reread.&lt;/p&gt;

&lt;h2 id=&quot;informed-activities-things-your-learners-can-do&quot;&gt;Informed Activities: Things Your Learners Can Do&lt;/h2&gt;

&lt;p&gt;Where “How Learning Works” explored the big picture of course design,
&lt;a href=&quot;https://www.routledge.com/Teaching-for-Learning-101-Intentionally-Designed-Educational-Activities/Howell-Major-Harris-Zakrajsek/p/book/9780415699365&quot;&gt;Teaching for Learning: 101 Intentionally Designed Educational Activities to Put Students on the Path to Success&lt;/a&gt;
takes a bottom-up approach, introducing 101 activities whose
effectiveness is supported by empirical results. The book organizes
these activities into eight chapters, with titles such as “Discussion”
or “Writing to Learn”.&lt;/p&gt;

&lt;p&gt;Each chapter begins with an overview of the activity type, 
distinguishing this type of activity
from others with similar names but distinct structures. The authors
summarize the broad empirical results regarding this type.
They next categorize the several forms this type of activity might take, such
as whole-class discussion versus dividing the class into discussion
dyads.
They conclude the overview with evidence-based recommendations for how
to organize these activities for most effective learning outcomes.&lt;/p&gt;

&lt;p&gt;Following the overview, the authors provide detailed descriptions of
all the activities of this type.  They call these activities IDEAs, an
acronym for	Intentionally Designed Educational Activities.  For each
IDEA, they describe its structure, its likely learning benefits, and
the research supporting its use.&lt;/p&gt;

&lt;p&gt;This isn’t the sort of book I’d read cover to cover.  The long lists
of IDEAs can be numbing.  However, the chapter introductions are a
tremendous resource in their own right. The introductions provide a
fantastic overview of the essential types of class activity,
highlighting the strengths and weaknesses of each. I find the
recommendations on effective implementation of each activity
particularly useful.  Taken together, the introductions orient each
activity in light of all the others.  I finished the book with a sense of how
these disparate pieces fit.&lt;/p&gt;

&lt;p&gt;I also gained from some of the authors’ careful distinctions between
similar-sounding activities that in fact have quite different
outcomes. For example, the authors categorize “Socratic dialogue”
under “Lecturing” rather than
“Discussion groups” because classic Socratic technique has a specific,
planned sequence of points, as opposed to the freer topic choices
characterizing discussion.  Whether or not you agree with such
characterizations, simply considering them will clarify your own practice.&lt;/p&gt;

&lt;h2 id=&quot;informed-skepticism-contesting-unsupported-myths&quot;&gt;Informed Skepticism: Contesting Unsupported Myths&lt;/h2&gt;

&lt;p&gt;Where the first two books describe approaches to teaching and learning
that are well-supported by evidence,
&lt;a href=&quot;https://www.elsevier.com/books/urban-myths-about-learning-and-education/de-bruyckere/978-0-12-801537-7&quot;&gt;Urban Myths About Learning and Education&lt;/a&gt;
focuses instead on those widely-assumed assumptions that have
in fact been contradicted or unsupported by evidence.  Where the first
two books make you a more successful teacher, this short book makes you a
more successful skeptic, fending off the mountebanks and sellers of
educational snake oil.&lt;/p&gt;

&lt;p&gt;Their introductory chapter sets the agenda:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;We have become saddled with a multiplicity of methods, approaches,
theories and pseudotheories, many of which have been shown by
science to be wrong or, at best, only partially effective. The
purpose of this book is to initiate a big clear-out of myths about
learning and education, for everyone involved in the educational
process: teachers, schools, parents, boards of education,
educational policy-makers and politicians. (Ch. 1)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Given the book’s broad sweep, not every section will be useful to an
educator, though they may prove useful in arguments with the people
controlling educational funding.&lt;/p&gt;

&lt;p&gt;As an appetizer, the authors begin with a critique of
&lt;a href=&quot;https://www.simplypsychology.org/maslow.html&quot;&gt;“Maslow’s Pyramid”&lt;/a&gt;
[link to an example of the myth, not the book’s critique]. I write the
name in quotes because this book’s authors point out that:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Maslow never represented his hierarchy as a pyramid,&lt;/li&gt;
  &lt;li&gt;at the end of his career, he added two new layers that are typically
not included in the five-layer diagrams of “his” pyramid, and&lt;/li&gt;
  &lt;li&gt;extensive research since his death in 1970 has demonstrated that his
hierarchy does not in fact describe the structure of human needs and desires.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With this as preface, successive chapters tackle myths from several
big topics in education:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Myths about learning&lt;/li&gt;
  &lt;li&gt;Neuromyths, regarding supposed “innate” features of the human mind&lt;/li&gt;
  &lt;li&gt;Myths about technology in education&lt;/li&gt;
  &lt;li&gt;Myths about educational policy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;followed by a concluding chapter about the persistence of myths and
how the reader can avoid falling prey to myths.&lt;/p&gt;

&lt;p&gt;The opening paragraph
of the final chapter is an apt summary of all three books I’ve
discussed in this post:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In order to implement valuable ideas from educational research into
practice, the educational sciences must be driven by theories, not
by simple observations. These theories must be based on strong
empirical data gained from methodologically valid experiments,
rather than legends, hypes and unsound research, and tested in
real-life settings before proceeding with large-scale
implementation. (Ch. 6)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Taken together, they give you useful, reliable ways to think about
your class as a whole, to design individual activities in that class, and
to avoid the traps of myths presented as received wisdom.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Learning decision crystallization</title>
   <link href="/2018/09/16/learning-decision-crystallization/"/>
   <updated>2018-09-16T00:00:00-07:00</updated>
   <id>/2018/09/16/learning-decision-crystallization</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Fifth in a series on group decision-making, based on Ch. 10–11 of &lt;a href=&quot;https://www.amazon.com/Making-Meetings-Work-Achieving-Decisions/dp/0761927050/&quot;&gt;Making Meetings Work&lt;/a&gt;. The previous post
showed &lt;a href=&quot;/2018/09/05/discussion-rounds-and-decision-crystallization/&quot;&gt;how to crystallize a decision out of a round of discussion&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The last two posts, on
&lt;a href=&quot;/2018/08/29/the-decision-mosaic-every-piece-in-place/&quot;&gt;focusing the group&lt;/a&gt;
towards the most important next decision element and on
&lt;a href=&quot;/2018/09/05/discussion-rounds-and-decision-crystallization/&quot;&gt;how to crystallize a decision&lt;/a&gt;
out of the ensuing discussion, highlight how subtle the process of
group decision-making is. And it all has to be done in real time,
potentially while the group is making decisions with real impact on
your work and life. It’s not an obvious process, not something that
you just fall into. How do you learn this skill?&lt;/p&gt;

&lt;p&gt;You can find opportunities to practice decision crystallization in
both actual meetings, convened to commit to actual decisions, and in
mock meetings, convened solely to practice the skill of crystallization.&lt;/p&gt;

&lt;h2 id=&quot;practicing-in-actual-meetings&quot;&gt;Practicing in actual meetings&lt;/h2&gt;

&lt;p&gt;Actual meetings, with real decisions on the line, are the most
effective places to learn the process of decision
crystallization. Participants will be engaged because the outcomes of
these meetings will have real impact in their lives.&lt;/p&gt;

&lt;h3 id=&quot;observing&quot;&gt;Observing&lt;/h3&gt;

&lt;p&gt;For the same reasons, however, you want increase your own engagement
in such meetings gradually. It might help to begin by simply observing
meetings in which you have no responsibility. As an auditor, you can
observe the dynamics of group decision-making with the dispassionate
eye of someone unaffected by the choices made. If you do this, bear in
mind that you are there only to listen, not to contribute. You’ll have
opportunity to practice vocalizing the crystallization step later,
after these listening sessions.&lt;/p&gt;

&lt;p&gt;When observing, watch for discussion rounds, noting their shape and
how pauses indicate the round’s end. Is there a clear decision element
under discussion and does it seem an appropriate choice at this point?
Note what happens at round’s end: Does someone suggest a choice, does
someone simply express frustration with the apparent lack of progress,
does someone start a new round, or something else? If a member makes a
proposal, do they support it with one or more decision rule?  How does
the group respond?&lt;/p&gt;

&lt;h3 id=&quot;crystallizing&quot;&gt;Crystallizing&lt;/h3&gt;

&lt;p&gt;Once your ear is attuned to the shape of discussion rounds, you can
practice as an actual participant.  Note that any participant can
initiate crystallization—the role is not restricted to the
chair. When you hear the end of a round, propose a choice using the
crystallization sequence: neutral summary, action hypothesis, and
legitimization. The response of the group, whether “go” or “no go”,
will typically be clear to everyone.&lt;/p&gt;

&lt;h3 id=&quot;gradually-increasing-your-responsibility&quot;&gt;Gradually increasing your responsibility&lt;/h3&gt;

&lt;p&gt;Although any member, not just the chair, can initiate crystallization,
groups are also sensitive to someone dominating. They will accept the
chair guiding every round—setting the determinative element,
crystallizing the choice, and refocusing—but will not accept the
same from a member not assigned that role, especially if the member is
considered junior in the organization. Furthermore, although
this method works well and seems “natural” when done well, it also
takes some time for groups to become comfortable with the process.
For all these reasons, when beginning to practice this skill, if you
are not the designated chair, only try to crystallize the discussion
once or twice in any one meeting.  With practice, and greater
familiarity in the group, you can guide discussion more often. You may
well see other members picking up on the basic idea and trying it
themselves, once they’ve seen it in action.&lt;/p&gt;

&lt;h2 id=&quot;practicing-in-mock-meetings&quot;&gt;Practicing in mock meetings&lt;/h2&gt;

&lt;p&gt;It can take quite a while to learn this skill if you only exercise it
once or twice a meeting. You can accelerate the process by
role-playing or practicing with some like-minded coworkers or friends
and family. There’s many ways of doing this, including:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;When a group is making a simple, daily decision through informal
means, such as where to go for lunch, try instead doing it using a
decision array, with you selecting the determinative element,
observing the rounds, and crystallizing at the end of the round.&lt;/p&gt;

    &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Only do this with a group who have all previously
expressed interest in improving their own meeting skills. Otherwise,
asking hungry, busy coworkers to delay lunch while you indulge in
your hobby is a good way to isolate your self at work.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Have a friend list a lot of pros and cons for a decision, whether
real or fabricated.  Try suggesting a choice using the four
parts of decision crystallization and then have your friend respond to
your proposal.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Role-play a meeting from a fictional world you all know, such as the
King’s Council from Game of Thrones or the bridge of the Starship
Enterprise. How should Cersei respond to the High Sparrow or Picard
to the Borg? Take turns focusing the discussion on the next element
and crystallizing the choices.  Can your team come to a better
decision than your fictional counterparts?&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;returning-to-the-whole-decision&quot;&gt;Returning to the whole decision&lt;/h2&gt;

&lt;p&gt;Eventually, all elements in the array will have been decided. The
group will have an enthusiastic energy from this positive progress.
The decision process is almost complete. The next post will describe
the final step,
&lt;a href=&quot;/2018/09/21/decision-sculpting/&quot;&gt;arranging these elements into the final mosaic&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Discussion rounds and decision crystallization</title>
   <link href="/2018/09/05/discussion-rounds-and-decision-crystallization/"/>
   <updated>2018-09-05T00:00:00-07:00</updated>
   <id>/2018/09/05/discussion-rounds-and-decision-crystallization</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Fourth in a series on group decision-making, based on Ch. 10–11 of &lt;a href=&quot;https://www.amazon.com/Making-Meetings-Work-Achieving-Decisions/dp/0761927050/&quot;&gt;Making Meetings Work&lt;/a&gt;. The previous post
showed &lt;a href=&quot;/2018/08/29/the-decision-mosaic-every-piece-in-place/&quot;&gt;how to pick the next decision element to discuss&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Guiding the group to consider the determinative element, the element upon which most other choices depend, is only the first step. You must then guide them to a decision through the process of &lt;em&gt;decision crystallization&lt;/em&gt;.  This doesn’t mean “guiding them to a predetermined outcome you have decided is best” nor “guiding them to the outcome benefitting you the most”.  Leading a discussion is ultimately an act of humility: You set aside your personal goals for the broader outcome of the greatest benefit to the group overall. So long as the group perceives your interventions as honest efforts to facilitate discussion, rather than a ploy to herd everyone into agreeing with you, they will appreciate your efforts.&lt;/p&gt;

&lt;h2 id=&quot;what-to-listen-for&quot;&gt;What to listen for&lt;/h2&gt;

&lt;p&gt;You will spend a lot of time listening, with an intensity of focus that may be unfamiliar. You’re no longer listening for just for content, you’re listening for &lt;em&gt;consensus&lt;/em&gt;. Is the discussion converging and what is the direction of that convergence?  Listen for these indicators:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Degree of agreement on the options under consideration (extensive decision rule)&lt;/li&gt;
  &lt;li&gt;Intensity of feeling for each option (intensive decision rule)&lt;/li&gt;
  &lt;li&gt;Contraindications of options by experts or management (expertise and power decision rules)&lt;/li&gt;
  &lt;li&gt;Repetition (indicating the discussion is playing out)&lt;/li&gt;
  &lt;li&gt;Focus (gently returning discussion to the element under consideration if discussion drifts)&lt;/li&gt;
  &lt;li&gt;Revealed dependencies (Has the discussion uncovered incompatibilities with decisions on prior elements? Should you redirect discussion to re-open a previously-decided element?)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The required focus is another reason why you will say less and listen more.&lt;/p&gt;

&lt;p&gt;Absent a specific kind of prompt, these discussions can run without ever concluding. You will have to instigate the process by which they crystallize into a decision.&lt;/p&gt;

&lt;h2 id=&quot;rounds-of-discussion&quot;&gt;Rounds of discussion&lt;/h2&gt;

&lt;p&gt;Discussion typically proceeds in &lt;em&gt;rounds&lt;/em&gt;, a sequence of comments by everyone who wishes to contribute. In some contexts, this may be a formal protocol where every member is allotted a chance to speak, while in other cases members may speak and respond in a free flow. Either way, the discussion leader should take care that everyone has had a real opportunity to contribute, no one has dominated, and no one has been shut out.&lt;/p&gt;

&lt;p&gt;At some point, there will be a pause.  The group tacitly agrees that there is nothing more to say about this element. Someone may even ask, “Does anyone have anything more to say?” This is the moment when a decision is imminent, but only if a crystallizing prompt is provided. These moments are not arbitrary. The group is waiting for something to happen. If a decision is not explicitly initiated, someone will simply restart discussion. This new discussion is unlikely to reveal anything new, so the group will simply rehash what has already been said.&lt;/p&gt;

&lt;h3 id=&quot;crystallization&quot;&gt;Crystallization&lt;/h3&gt;

&lt;p&gt;Tropman provides a template for a crystallizing prompt, which proceeds in four steps:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;em&gt;Summative reflection&lt;/em&gt;: A neutral summary of the discussion so far.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Action hypothesis&lt;/em&gt;: Propose a choice for this decision.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Action legitimization&lt;/em&gt;: Support the choice by appeal to the decision rules.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Discussion refocus&lt;/em&gt;: If the group commits to the proposed choice, suggest the next determinative element in the sequence.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once again, the technical language is simply for your use, helping you formulate what to say. The statement that actually initiates the crystallization is much less formal, more fluid.  For example, suppose the decision at hand is setting the latency Service Level Objectives (SLOs) for a service. Seen as a mosaic, the elements of this decision may include setting the 50th percentile, setting the 95th percentile, setting the 99th percentile, and  choosing between alternative services to call in turn, each with its own published SLOs.&lt;/p&gt;

&lt;p&gt;Let’s assume the initial determinitive element is the 50th percentile, as this characterizes the “typical” performance of this service and only once this level has been specified can the group move on to bound the upper limits via higher percentiles.  At the end of the discussion round, you could say something like,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;em&gt;Neutral summary:&lt;/em&gt; The group is evenly split between proposals for 10 ms and 20 ms as median latency.
&lt;em&gt;Action hypothesis:&lt;/em&gt; On balance, it sounds like 
10 ms has the most support.
&lt;em&gt;Legitimize the suggestion using the decision rules:&lt;/em&gt; The teams who will call this service are strongly in favour
of the lower median latency, as it gives
them more room to do some complex computations &lt;em&gt;(intensity rule)&lt;/em&gt;. The implementation team are are confident they can meet the 10 ms
value &lt;em&gt;(involvement rule)&lt;/em&gt;. The capacity planners say that we have sufficient capacity to sustain this rate, while
the instrumentation team says that even at this rate they can provide accurate real-time estimates for our dashboard &lt;em&gt;(expertise rule)&lt;/em&gt;.
Management has encouraged us to make it as fast as possible because they are emphasizing low latency as a
differentiating factor for our product &lt;em&gt;(power rule)&lt;/em&gt;.  There are no strong arguments against it &lt;em&gt;(extensive rule)&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At this point, the group must decide whether or not to commit to the proposed choice. They &lt;em&gt;will&lt;/em&gt; decide, because they have a clear question with a clear answer, justified using points they made in the discussion. The sample proposal above, supported by all the decision rules, is very likely to be accepted. In other cases, the decision rules will contradict each other.  Tropman suggests that a proposal supported by three or more rules has a high likelihood of acceptance, while one supported by less than three rules is unlikely to be accepted.&lt;/p&gt;

&lt;h3 id=&quot;proposing-the-choice-and-reading-the-groups-response&quot;&gt;Proposing the choice and reading the group’s response&lt;/h3&gt;

&lt;p&gt;Some details about crystallization:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Proposing the choice:&lt;/em&gt; It helps to suggest the proposed action tentatively, emphasizing its basis
in the group’s discussion:&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;“We might want to … “&lt;/li&gt;
      &lt;li&gt;“It seems … “&lt;/li&gt;
      &lt;li&gt;“Based on this discussion, it looks like … “&lt;/li&gt;
      &lt;li&gt;“How about …”&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;By contrast, stating the proposal formally or definitively, such as “I propose that we vote on … “,
risks engaging factional responses ungrounded in the proposal’s suitability.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Reading the group’s response:&lt;/em&gt; How do you actually make the decision? Long habit suggests taking a vote.
In many formal contexts, a vote is required. But note that apart from meetings bound by formal legal requirements
such as parliamentary debates or board meetings, voting is only required for the the overall decision.
For component elements of that decision, less formal options are available and often preferred.&lt;/p&gt;

    &lt;p&gt;If the group is small, the decision is typically apparent from their immediate responses.
A proposal will be accepted via
nods or brief assents, rejected via grimaces, interjections (“Hold on!”, “Ewww!”), or strongly-voiced complaints. So
long as everyone can clearly agree on the tone of the room, you can consider the decision made.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;if-the-group-does-not-accept-the-proposal&quot;&gt;If the group does not accept the proposal&lt;/h3&gt;

&lt;p&gt;What should you do if the group rejects the proposal? Although it can feel personally invalidating for the group to decline the proposal, understand that their refusal is not personal and it represents real progress.  First, you may have voiced the proposal but it was on behalf of the group, setting out a clear idea for everyone to consider. They have rejected &lt;em&gt;their&lt;/em&gt; idea, not yours.  Second, the group has made progress: They have found a crucial lack, something that they will not compromise away. They may not know just what that lack is but it was there and formed the basis of their refusal.&lt;/p&gt;

&lt;p&gt;The group should now be led through another discussion round, with the goal of uncovering new possibilities rather than rearguing previous points. Suggest as a guideline that no one should repropose options that received strong consideration in the last round. Depending on circumstances, the group might work to articulate what was lacking in the declined proposal and identify fixes. Or the group could simply free-associate new possibilities. Either way, the focus of the new round ought to be suggesting options that have not yet been considered.&lt;/p&gt;

&lt;p&gt;The round continues until it too ends, when you can start a new crystallization step.  The round should have identified some new options from which you can select and make another proposal.&lt;/p&gt;

&lt;h3 id=&quot;if-the-group-accepts-the-proposal&quot;&gt;If the group accepts the proposal&lt;/h3&gt;

&lt;p&gt;If the group accepts the proposal, the current element has found its place in the decision mosaic and you can refocus the group.
This simply requires selecting the next determinative element and setting it before the group, perhaps with a brief justication for
why this ought to be the next item:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Now let’s consider the 95th percentile. This will help us bound the higher ranges of performance.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;learning-and-applying-this-process&quot;&gt;Learning and applying this process&lt;/h2&gt;

&lt;p&gt;This post has presented a lot of detail, yet there is more to say about decision crystallization. The practice of effective group decision-making is subtle and not obvious, as evidenced by the preponderance of ineffective meetings yielding bad decisions. In the next post, I will suggest ways to &lt;a href=&quot;/2018/09/16/learning-decision-crystallization&quot;&gt;learn this process&lt;/a&gt;, while in the post after that I’ll describe the final step of &lt;a href=&quot;/2018/09/21/decision-sculpting/&quot;&gt;crafting the individual elements of the decision into a complete, coherent mosaic&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;ps-for-what-its-worth-&quot;&gt;PS: For what it’s worth …&lt;/h2&gt;

&lt;p&gt;While writing this post, a meme crossed my feeds, suggesting that you pick up the nearest book to your computer, and select a random sentence from p. 45. This will supposedly summarize your love life. As I am busy with these posts, the book nearest to hand was Tropman. Here is the result:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;In the executive summary technique, the full report is not sent out, except by request.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Make of this what you will.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Disqus comments enabled</title>
   <link href="/2018/09/04/disqus-enabled/"/>
   <updated>2018-09-04T00:00:00-07:00</updated>
   <id>/2018/09/04/disqus-enabled</id>
   <content type="html">&lt;p&gt;I have set up Disqus comments on each post. Google Analytics shows that recent posts are generating some views, so it seemed time to finally turn comments on.&lt;/p&gt;

&lt;p&gt;I hope I’ve set everything up correctly but, as with any technical
update, there may be lingering issues.  If you encounter problems, let
me know at &lt;code class=&quot;highlighter-rouge&quot;&gt;ted@kirkpatricktech.com&lt;/code&gt; or in the comments.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The decision mosaic: Every piece in place</title>
   <link href="/2018/08/29/the-decision-mosaic-every-piece-in-place/"/>
   <updated>2018-08-29T00:00:00-07:00</updated>
   <id>/2018/08/29/the-decision-mosaic-every-piece-in-place</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Third in a series on group decision-making, based on Ch. 10–11
of
&lt;a href=&quot;https://www.amazon.com/Making-Meetings-Work-Achieving-Decisions/dp/0761927050/&quot;&gt;Making Meetings Work&lt;/a&gt;. The
previous post
&lt;a href=&quot;/2018/08/24/decision-crystallization/&quot;&gt;introduced decision crystallization&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As
described in the previous post, a substantive decision is not
monolithic but a collection of smaller decisions. Tropman (&lt;a href=&quot;https://www.amazon.com/Making-Meetings-Work-Achieving-Decisions/dp/0761927050/&quot;&gt;Ch. 11&lt;/a&gt;) calls these
the &lt;em&gt;decision elements&lt;/em&gt; and taken together they form the &lt;em&gt;decision mosaic&lt;/em&gt;.
When meeting to make the decision, its elements are best considered in a
certain sequence, one that minimizes back-tracking and organizes the
elements into an elegant pattern.  Where do you start?&lt;/p&gt;

&lt;h2 id=&quot;how-do-decision-elements-depend-on-each-other&quot;&gt;How do decision elements depend on each other?&lt;/h2&gt;

&lt;p&gt;Out of all the elements in the decision mosaic, at any point in the
discussion, one will likely be the &lt;em&gt;determinative element&lt;/em&gt;, the one
upon which the rest depend.  This element fixes the context in which
the others will be decided, much as a striking piece in a mosaic draws
the eye and the viewer sees all its neighbours in relation to that piece.&lt;/p&gt;

&lt;p&gt;In the last post, I cited Tropman’s example of a meal’s main course as
the determinative element in planning a meal, setting a dominant
flavour against which the side dishes provide contrast. Although
software teams rarely do meal planning, we’re familiar with dependency
analysis, from the practice of identifying and managing dependencies
between system components.  What sorts of dependencies might we have
to untangle in the mosaic of a typical technical decision?&lt;/p&gt;

&lt;h3 id=&quot;software-development-as-unfolding-decisions&quot;&gt;Software development as unfolding decisions&lt;/h3&gt;

&lt;p&gt;In software development, a decision is rarely “green field”, unconnected
to other choices. Rather, a project unfolds via a series of
decisions, decided by meetings of representatives of the relevant
groups.&lt;/p&gt;

&lt;p&gt;When exploring a decision at project start, the determinative
element is often the terms of reference: The boundaries that are already
set by external authorities or circumstances. You will want
to ensure at the outset that everyone understands the bounds
circumscribing the group’s choices.&lt;/p&gt;

&lt;h3 id=&quot;example-setting-a-latency-objective&quot;&gt;Example: Setting a latency objective&lt;/h3&gt;

&lt;p&gt;As the project continues, the constitutive elements of the decisions
and their interdependencies will change. For example, when designing a
microservice, one of the first decisions will be setting its
&lt;a href=&quot;https://en.wikipedia.org/wiki/Service_level_objective&quot;&gt;service level objectives&lt;/a&gt;
(SLOs). These are the determinative element for many other decisions,
such as designing for tight latencies or selecting a failure recovery
mechanism.  A team will typically have to know such
objectives—including those service indicators for which there are no
objectives—before making many other choices.&lt;/p&gt;

&lt;p&gt;The decision for the SLOs will itself be a mosaic of smaller
elements, such as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Objectives for competing services&lt;/li&gt;
  &lt;li&gt;Levels feasible with the implementation stack&lt;/li&gt;
  &lt;li&gt;Expected load (likely specified for several percentiles)&lt;/li&gt;
  &lt;li&gt;Expected variation of load, such as diurnal or seasonal spikes&lt;/li&gt;
  &lt;li&gt;Consequences of failing to meet the objectives&lt;/li&gt;
  &lt;li&gt;Pressure on services called&lt;/li&gt;
  &lt;li&gt;Available capacity&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These in turn would constitute their own mosaics. Some might even
spawn a separate project, such as estimating seasonal demand variation
or surveying availability statistics for competing services. In that
case, the team would either have to postpone defining the SLOs or else
set provisional levels, subject to revision upon conclusion from the
subproject.  While this process can be frustrating, recognizing that the
determinative element cannot be decided without further information
also contributes to efficient decision-making, as it prevents the
group from committing to decisions on other elements that might be
overturned when the determinative one is decided later, once full information
is available.&lt;/p&gt;

&lt;h3 id=&quot;decision-rules-aid-setting-a-determinative-element&quot;&gt;Decision rules aid setting a determinative element&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&quot;2018/08/13/the-best-process-for-group-decisions/&quot;&gt;decision rules&lt;/a&gt;
may be used to select the determinative element. If you know that one
element of the decision mosaic elicits particularly strong responses,
you may choose to make it the determinative element and consider it
first or, equally valid, defer it for later.  If you start the
discussion with this element, you gain insight into which choice the
intensive rule will utlimately recommend. If you instead begin by
deciding a few simpler, less-contentious elements, the group’s sense
of accomplishment and progress can develop a useful energy for
tackling a difficult item.  There is no single right agenda, so long
as whichever you pick is informed by the emotional dynamics of the
group.  That will make it far more likely to lead to a cohesive,
well-accepted final decision.&lt;/p&gt;

&lt;h3 id=&quot;proposing-a-determinative-element-to-the-group&quot;&gt;Proposing a determinative element to the group&lt;/h3&gt;

&lt;p&gt;How does this work in actual meetings? Locating the determinative
element, the constituent of the overall decision mosaic to tackle
first, is an approximate process. You have to do it in real time,
accounting for new points and emotional shifts in the group, all the
while scanning the group for levels of participation, occasionally
tempering members who tend to overcontribute and soliciting opinions
from the more timid members.&lt;/p&gt;

&lt;p&gt;When the group is addressing a complex decision, once you have
identified a determinative element, you need to propose that the group
focus on it.
If this seems daunting, bear in mind that groups are often desperate
for exactly this sort of leadership.  There’s an odd but persistent
aspect of group psychology, that a group will tend to talk around a
choice but will never be able to decide on it until it is expressly
stated. If you propose to focus on a specific element of the decision,
group members will typically be grateful and more importantly, take
your suggestion and apply themselves to that focus.&lt;/p&gt;

&lt;h3 id=&quot;the-decision-rules-can-aid-setting-a-determinative-element&quot;&gt;The decision rules can aid setting a determinative element&lt;/h3&gt;

&lt;p&gt;You can introduce the focus informally, with something like, “Our
capacity planning and choice of technology stack all seem affected by
the service’s latency objectives, so how about we focus on setting those
percentiles first?”  There is no need to use the nomenclature described here. The
notions of “determinative element” within a “decision mosaic” are
useful for identifying the items you, as decision leader, need to identify
whereas simple descriptive language is enough to set a direction for
the group.&lt;/p&gt;

&lt;h2 id=&quot;from-determinative-element-to-decision&quot;&gt;From determinative element to decision&lt;/h2&gt;

&lt;p&gt;Choosing a determinative element and setting it as the group’s focus
is only the first step. You also need to know how to lead the group to
converge on a decision for that element and move on to the next
determinative element.  That will be the subject of the &lt;a href=&quot;/2018/09/05/discussion-rounds-and-decision-crystallization/&quot;&gt;next post&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;appropriate-preparation-improves-the-process&quot;&gt;Appropriate preparation improves the process&lt;/h2&gt;

&lt;p&gt;In this post, I have focused on identifying the decision elements in
real time, amidst the helter-skelter of a meeting. This is only part
of the process.  In fact, while the final parts of this process must
be done in the meeting, you will be most successful if you spend time
preparing beforehand.&lt;/p&gt;

&lt;p&gt;In these posts, I am focussing on Tropman’s Chapters 10 and 11.  His
first nine chapters recommend best practices for meeting
preparation. I don’t mean to discount the importance of those
activities with this series. I focus on the decision-making process in
meetings because that is the outcome that matters, the one that grabs
readers’ attention. Working backwards from this beneficial outcome,
the value of preparing for a meeting becomes apparent.&lt;/p&gt;

&lt;p&gt;As a rule of thumb, when I am scheduled to chair a meeting, I like to
spend as much time preparing for it as is scheduled for the meeting
itself.  In fact, should I find myself only spending a few minutes
setting the agenda for a one-hour meeting, I reflect on my choices to
see if there’s something else I need to do. Sometimes meetings only
require minor preparation but I am surprised at how often apparently
simple agendas have hidden complexities, like reefs just underneath
smooth water, threatening to rip the keel from your boat.&lt;/p&gt;

&lt;p&gt;Informal conversations with meeting members can give you the outlines
of issues before entering the meeting, averting unpleasant
surprises in the meeting itself. Listen for such issues as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Strong feelings that members have about a specific topic (intensity
decision rule)&lt;/li&gt;
  &lt;li&gt;What elements will be part of the overall decision mosaic&lt;/li&gt;
  &lt;li&gt;Warnings from experts on dependencies that are not apparent to you
(expert decision rule)&lt;/li&gt;
  &lt;li&gt;The prior inclinations or outright decisions of management (power decision rule)&lt;/li&gt;
  &lt;li&gt;The general tone of group members on this topic (extensive decision rule)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These discussions will not reveal every issue that might arise in the
meeting but what they do reveal will allow you to organize your
thoughts in advance.  Forewarned is forearmed.&lt;/p&gt;

&lt;h2 id=&quot;practicing&quot;&gt;Practicing&lt;/h2&gt;

&lt;p&gt;This concepts are difficult enough and their interplay in actual
meetings is fast enough that before actually trying to intervene in a
meeting, simply practice identifying them.  At your next meeting to
make a substantive decision, note down all the different elements. How
do they interdepend?  After the meeting, reflect a few minutes on how
the choices unfolded.  Did the group select one element after another,
with minimal backtracking, or did were they trapped in cycles of
re-decision? With benefit of hindsight, can you identify a more
efficient, effective sequence of elements that the group could have
followed?&lt;/p&gt;

&lt;p&gt;As you become more comfortable identifying decision elements,
organizing them into the larger mosaic, and choosing the one that
influences most of the others, you will be able to identify them in
the maelstrom of an actual meeting.  In the next post, I will describe
how to
lead the group to &lt;a href=&quot;/2018/09/05/discussion-rounds-and-decision-crystallization/&quot;&gt;selecting and deciding the elements in efficient
sequence&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Decision crystallization: Form emerging from solution</title>
   <link href="/2018/08/24/decision-crystallization/"/>
   <updated>2018-08-24T00:00:00-07:00</updated>
   <id>/2018/08/24/decision-crystallization</id>
   <content type="html">&lt;p&gt;&lt;em&gt;Second in a series on group decision-making, based on Ch. 10–11
of
&lt;a href=&quot;https://www.amazon.com/Making-Meetings-Work-Achieving-Decisions/dp/0761927050/&quot;&gt;Making Meetings Work&lt;/a&gt;.
The first post described
&lt;a href=&quot;/2018/08/13/the-best-process-for-group-decisions/&quot;&gt;the rules group use to justify decisions&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Understanding &lt;a href=&quot;/2018/08/13/the-best-process-for-group-decisions/&quot;&gt;decision rules&lt;/a&gt;, the criteria groups use to justify decisions, is the first step to becoming an effective decision leader. The next step is applying this understanding in actual meetings.  This skill is more complex, because it requires attending to many different things in real time, and harder to practice, because you can only perform it in an actual group as it makes a decision.  However, given the low level of effectiveness of typical group decisions, even moderate skill in this process can make a substantial improvement. Your colleagues will notice your contribution.&lt;/p&gt;

&lt;p&gt;Tropman coined the phrase &lt;em&gt;decision crystallization&lt;/em&gt; to describe the
skill of leading a group to a great outcome that seems to emerge
naturally from the discussion.  But if the outcome is so natural, why
is it so rare? Why do so very many meetings circle round indecisively,
producing mediocre results?&lt;/p&gt;

&lt;h2 id=&quot;decisions-are-collections-of-interconnected-choices&quot;&gt;Decisions are collections of interconnected choices&lt;/h2&gt;

&lt;p&gt;The problem arises from the unacknowledged complexity of decisions. Decisions of any import are not single choices but a collection of interconnected choices. To use one of Tropman’s examples, the decision “What shall we serve for dinner at the party?” is in fact a collection of decisions, including aperitif, main course, side dishes, beverage, and dessert.  These choices in turn might be constrained by allergies or dietary restrictions of some guests, when the hosts can begin preparing the food, seasonal availability of ingredients, and other restrictions. Deciding “What to serve for dinner” is in fact a process of making many smaller decisions, which may be mutually constraining. The choice of main dish will restrict appropriate beverages and side dishes. Furthermore, some restrictions will only become apparent during the discussion, as when the hosts realize that a given dish would require them to start cooking earlier than their schedule permits.&lt;/p&gt;

&lt;p&gt;During the meeting, all these distinct choices float about as though in solution.  The group attends to one, then another, in no particular order, identifying barriers and conflicts to some choices, favouring other choices, highlighting their interconnectedness, never settling on any one point, never &lt;em&gt;deciding&lt;/em&gt; anything. The formless discussion frustrates progress.&lt;/p&gt;

&lt;h2 id=&quot;crystallizing-a-decision-from-the-chaos&quot;&gt;Crystallizing a decision from the chaos&lt;/h2&gt;

&lt;p&gt;Tropman’s term &lt;em&gt;crystallization&lt;/em&gt; perfectly captures how a good decision can appear to a group once it’s been articulated. From a blur of conflicting, unprioritized notions appears a proposal, seemingly fully-formed, one that addresses the concerns of the group, is supported by a majority or even all of the decision rules, and resolves conflicts by making balanced compromises.  Once the group hears such a proposal, they will usually endorse it and enthusiastically implement it.&lt;/p&gt;

&lt;p&gt;The word “hears” is key. Individual points may have been made during the discussion but they would have been lost as the topic shimmied from issue to issue.  The decision has to be spoken aloud, articulated as a package, in the right way, at the right time.  The process is subtle enough that I’ll spread the discussion over the next several posts:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The &lt;em&gt;decision mosaic&lt;/em&gt;—organizing the collection of sub-decisions that comprise the overarching decision at issue.&lt;/li&gt;
  &lt;li&gt;The &lt;em&gt;determinative element&lt;/em&gt;—selecting the best sub-decision to discuss next.&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;Decision rounds&lt;/em&gt;—when to propose a choice to address the current decision.&lt;/li&gt;
  &lt;li&gt;The crystallization process—how to propose a choice that addresses the goals and concerns expressed by the group.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;My next post will describe &lt;a href=&quot;/2018/08/29/the-decision-mosaic-every-piece-in-place/&quot;&gt;the decision mosaic and selecting the determinative element&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Attributing causality has important practical consequences</title>
   <link href="/2018/08/22/attributing-causality-has-important-consequences/"/>
   <updated>2018-08-22T00:00:00-07:00</updated>
   <id>/2018/08/22/attributing-causality-has-important-consequences</id>
   <content type="html">&lt;p&gt;Yesterday Matthew Zeitlin tweeted:&lt;/p&gt;

&lt;blockquote class=&quot;twitter-tweet&quot; data-lang=&quot;en&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;If you uncover an interesting correlation, hoards of wonks and twitter pedants will bray that all you have is a correlation, but if you do the work to &amp;quot;show&amp;quot; causation, those same people will bury you in little detailed complaints about how you did it&lt;/p&gt;&amp;mdash; Matthew Zeitlin (@MattZeitlin) &lt;a href=&quot;https://twitter.com/MattZeitlin/status/1032064399203287040?ref_src=twsrc%5Etfw&quot;&gt;August 22, 2018&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async=&quot;&quot; src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;

&lt;p&gt;Later in that thread, Zeitlin adds,&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;people always say judea pearl has figured this stuff out but i don’t think i’m smart enough for him.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I agree that Pearl’s &lt;a href=&quot;http://bayes.cs.ucla.edu/BOOK-2K/&quot;&gt;Causality&lt;/a&gt; is a dense read, filled with such concepts as &lt;a href=&quot;http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html&quot;&gt;d-separation&lt;/a&gt;. However, as important as the book’s technical contributions are, equally important is Pearl’s discussion of &lt;em&gt;why causality matters&lt;/em&gt;.  This explanation is simple, understandable without the underlying mathematics of Bayesian networks, and eminently practical.&lt;/p&gt;

&lt;p&gt;Pearl points out that by establishing causality, we &lt;strong&gt;increase our control over the world&lt;/strong&gt;. From his perspective, the distinction between a correlative and a causal result is that the causal result claims that by changing input &lt;em&gt;X&lt;/em&gt;, we modify the expected outcome &lt;em&gt;Y&lt;/em&gt;.  For example, &lt;a href=&quot;https://www.cdc.gov/tobacco/campaign/tips/diseases/heart-disease-stroke.html&quot;&gt;both strokes and smoking may be correlated with heart disease&lt;/a&gt; but we can only reduce risk of heart disease by reducing smoking, because smoking’s relationship with heart disease is causal whereas strokes are only correlated with it. (Reducing smoking also reduces risk of stroke, as smoking is a common cause of both outcomes.)&lt;/p&gt;

&lt;p&gt;There’s some important qualifications.  Causal relationship are often determined statistically, so they do not guarantee that the desired outcome will be achieved.  There are frequently multiple causes for an outcome, some of which may be currently unknown, potentially interacting in nonlinear ways. A causality argument only states that on average, we expect to have a better outcome by modifying the cause.  If we can improve our expected outcome enough via a sufficiently cheap change in the cause, it’s worth a try.&lt;/p&gt;

&lt;p&gt;Some writers argue that the distinction between correlation and causation is irrelevant.  I am insufficiently familiar with the philosophy of causation to join that debate but I think Pearl has emphasized the key practical reason for distinguishing them and for putting in the extra effort to demonstrate causality.  We study the world not just for the fascination we gain from determining correlations, but also to locate causes and their effects, to improve our lives and those of others.&lt;/p&gt;

&lt;p&gt;Returning to Zeitlin’s main point, demonstrations of causality are multifaceted, with data analysis forming only one part. They represent some of the most useful knowledge that we can have. Attacking such arguments through a focus on small details is both missing the point and, if pursued consistently, arguing in bad faith.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Don't let your babies grow up to be microbenchmarkers!</title>
   <link href="/2018/08/20/dont-let-your-babies-grow-up-to-be-microbenchmarkers/"/>
   <updated>2018-08-20T00:00:00-07:00</updated>
   <id>/2018/08/20/dont-let-your-babies-grow-up-to-be-microbenchmarkers</id>
   <content type="html">&lt;p&gt;I never wanted to be a microbenchmarker. I was OK with a modest but
respectable career choice, such as programming in &lt;a href=&quot;https://en.wikipedia.org/wiki/IBM_RPG_II&quot;&gt;RPG II&lt;/a&gt;
or &lt;a href=&quot;http://www.computerhistory.org/collections/catalog/102635171&quot;&gt;IBM 1604 assembler&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;But then I went and wrote several posts on the machine language efficiency of
the code compiled from several
&lt;a href=&quot;http://kirkpatricktech.org/2017/05/03/analysis-of-code-generated-from-the-transform-idiom/&quot;&gt;STL-based idioms&lt;/a&gt;.
Which pretty much demanded a follow up actually comparing the performance of the various
algorithms in practice. Which in turn meant microbenchmarks. And here
we are.&lt;/p&gt;

&lt;h2 id=&quot;microbenchmarks-are-influenced-by-many-sources-of-variability&quot;&gt;Microbenchmarks are influenced by many sources of variability&lt;/h2&gt;

&lt;p&gt;The pitfalls of microbenchmarks are legion.  Oh, it’s easy enough to run a few
timing tests and compute some comparative measure but how broadly can you generalize
from those numbers?  There’s plenty of sources of variability underlying a
microbenchmark:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://shape-of-code.coding-guidelines.com/2015/02/24/hardware-variability-may-be-greater-than-algorithmic-improvement/&quot;&gt;Variance between instances of the same chip design&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Variance between microarchitectures in the same family&lt;/li&gt;
  &lt;li&gt;Variance between vendor implementations of a common instruction set&lt;/li&gt;
  &lt;li&gt;Variance between architectures (x86 vs. ARM)&lt;/li&gt;
  &lt;li&gt;Variance due to chip temperature changes, including those caused by a benchmark run&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://blog.acolyer.org/2017/11/07/virtual-machine-warmup-blows-hot-and-cold/&quot;&gt;Variance across virtual machine startups&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Compiled code variance with compiler, version, and optimization level&lt;/li&gt;
  &lt;li&gt;Variance due to test data sets&lt;/li&gt;
  &lt;li&gt;Interference from co-resident processes and active kernel threads on the same machine&lt;/li&gt;
  &lt;li&gt;Heap layout&lt;/li&gt;
  &lt;li&gt;Timing of garbage collection&lt;/li&gt;
  &lt;li&gt;Other factors …&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;an-example&quot;&gt;An example&lt;/h2&gt;

&lt;p&gt;Recently, I microbenchmarked two C++ implementations of a simple text
manipulation problem (the one given to Albino Tonnina for his
&lt;a href=&quot;https://hackernoon.com/how-to-lose-an-it-job-in-10-minutes-3d63213c8370&quot;&gt;job interview&lt;/a&gt;).
One was an &lt;em&gt;O(n&lt;sup&gt;2&lt;/sup&gt;)&lt;/em&gt; iterative algorithm featuring a pair of nested loops, the other an &lt;em&gt;O(n)&lt;/em&gt;
algorithm using a hash table. For my initial benchmarks, I used a
test dataset with &lt;em&gt;n&lt;/em&gt;=740 and ran benchmarks using
&lt;a href=&quot;https://nonius.io/&quot;&gt;nonius&lt;/a&gt;, which computes
confidence intervals for the mean and standard deviation using
the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Methods_for_bootstrap_confidence_intervals&quot;&gt;accelerated bias-corrected bootstrap&lt;/a&gt;,
a nonparametric estimator.&lt;/p&gt;

&lt;p&gt;The initial implementations performed broadly as their respective
asymptotic behaviour suggested: On this dataset, the hash table implementation was
typically about 100 times as fast as the nested-loop implementation.&lt;/p&gt;

&lt;p&gt;But I wanted more than simple confirmation of their expected
asymptotic performance. As each implementation was a first draft,
I wanted to remove inefficiencies in their code and see how their
respective performance improved.  The 
&lt;a href=&quot;https://github.com/namhyung/uftrace&quot;&gt;uftrace&lt;/a&gt;
user-space tracer revealed a number of extraneous
string constructor calls in the nested-loop algorithm, as well as some
superfluous calls to other expensive routines.&lt;/p&gt;

&lt;p&gt;The first few performance fixes for the nested-loop implementation yielded
sufficiently large improvements that it became only
2–3 times as slow as the hash table implementation. At this
point I hit a wall, as I could no longer get repeatable benchmark
results.
Consecutive runs of
the benchmark would yield means that were never within the computed
confidence intervals of each other.&lt;/p&gt;

&lt;p&gt;Some runs using nonius’s default of 100 runs (times in microseconds):&lt;/p&gt;

&lt;table class=&quot;table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Mean&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Lower bound 95% CI&lt;/th&gt;
      &lt;th style=&quot;text-align: right&quot;&gt;Upper bound 95% CI&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;662.5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;660.6&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;666.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;675.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;671.9&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;680.3&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;678.5&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;669.3&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;698.9&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;742.7&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;738.0&lt;/td&gt;
      &lt;td style=&quot;text-align: right&quot;&gt;749.3&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Of the six combinations, only two of the estimated means (678.5 lies
in 675.0’s interval, 675.0 lies in 678.5’s interval) lie within
the CI estimated for another mean.&lt;/p&gt;

&lt;h2 id=&quot;how-do-i-interpret-this-variation&quot;&gt;How do I interpret this variation?&lt;/h2&gt;

&lt;p&gt;The bootstrap method is powerful but requires care. It can be
sensitive to sample size (the nonius default of 100 runs may well be
too small). Running the benchmark with 1000 runs yields estimates
within the range of those above but no greater consistency of means to
confidence intervals, though the confidence intervals tend to be
tighter.&lt;/p&gt;

&lt;p&gt;I am unsure how to interpret these numbers. The confidence intervals are
computed from the sample of runs and so each is subject to the particularities
of its underlying sample. If a sample run sequence includes
values from the extreme low or
high tail (and for timing data, the
probability of extremely high values is much higher than
for low values), these values will skew the computed interval. The
intervals will not necessarily overlap. Some distance between them is expected. But
how far apart is too far? How tight must the means be for us
to consider them “consistent”?&lt;/p&gt;

&lt;h2 id=&quot;what-are-microbenchmarks-good-for&quot;&gt;What are microbenchmarks good for?&lt;/h2&gt;

&lt;p&gt;Ultimately, the microbenchmarks are consistent enough to indicate that the nested-loop
implementation is substantially slower than the hash table
implementation for this dataset.  But they do not provide sufficiently
consistent results to say &lt;em&gt;how much&lt;/em&gt; faster the hash table
implementation is. When I get such variance between benchmark runs,
which means do I present as the “results”?&lt;/p&gt;

&lt;p&gt;I’ve wrestled with this topic for months, revising this post.  I don’t
have a firm conclusion.  Microbenchmarks are variable, difficult to
interpret, even unreliable, but what else do we have?  My goal was to
gain a sense of the relative performance of several C++ features, as
implemented by a specific compiler and standard library, and I
achieved that.  The microbenchmarks could distinguish substantial
performance improvements from trivial ones, a useful result.  But in
the end they were incapable of making a definitive estimate of the
sizes of those improvements.  Perhaps I should just set my
expectations to a more realistic level.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The best process for effective group decisions</title>
   <link href="/2018/08/13/the-best-process-for-group-decisions/"/>
   <updated>2018-08-13T00:00:00-07:00</updated>
   <id>/2018/08/13/the-best-process-for-group-decisions</id>
   <content type="html">&lt;p&gt;&lt;em&gt;First post in a series on group decision-making.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;The series:&lt;/em&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Introduction. Decision rules (this post).&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/08/24/decision-crystallization/&quot;&gt;Overview of decision crystallization.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/08/29/the-decision-mosaic-every-piece-in-place/&quot;&gt;The decision mosaic and the determinative element.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/09/05/discussion-rounds-and-decision-crystallization/&quot;&gt;Crystallizing a decision at the end of a round.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/09/16/learning-decision-crystallization/&quot;&gt;Learning to crystallize decisions.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/09/21/decision-sculpting/&quot;&gt;Reviewing and refining the decision as a whole.&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;/2018/09/26/the-vision-a-culture-of-effective-meetings/&quot;&gt;A culture of effective meetings.&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;making-effective-group-decisions&quot;&gt;Making effective group decisions&lt;/h2&gt;

&lt;p&gt;John E. Tropman’s &lt;a href=&quot;https://www.amazon.com/Making-Meetings-Work-Achieving-Decisions/dp/0761927050/&quot;&gt;Making Meetings Work: Achieving High Quality Group Decisions&lt;/a&gt; is the single most important book I’ve read for developing the skills of effective organizational work. (His more recent book, &lt;a href=&quot;https://www.amazon.com/Effective-Meetings-Improving-Decision-Services-ebook/dp/aB00JFC3XXU/&quot;&gt;Effective Meetings: Improving Group Decision Making&lt;/a&gt;, which I haven’t read, appears to cover much the same territory.)&lt;/p&gt;

&lt;p&gt;To benefit from &lt;em&gt;Making Meetings Work&lt;/em&gt;, you have to apply sustained effort. Although simply reading through it once and then shelving it might nudge you towards slightly more effective meeting habits, the big gains accrue from practice.&lt;/p&gt;

&lt;p&gt;Much of the book is concerned with practical details of setting agendas (don’t allow last-minute additions, include time for discussing long-term issues, …), keeping to agendas (do what you planned, no more and no less), recording minutes (record points made but not the person who made them), and similar skills. Become proficient in these skills and people will want to attend your meetings because the meetings will be reliably efficient and productive.&lt;/p&gt;

&lt;p&gt;But for me the genius of Tropman’s ideas, and the heart of the book, is Chapters 10 and 11 on how to lead a group to make effective decisions.  Chapters 1–9 describe how to prepare the group for a decision; the meeting is the mechanism for actually making the decision. Chapters 10 and 11 lay out the process for that decision to be &lt;em&gt;effective&lt;/em&gt;: supported by all parties necessary for its success, responsive to outside constraints, matched to the culture of the organization, and situated within the history of previous agreements. If one or more groups had to postpone or sacrifice a goal important to them, they are confident that their concerns are valued and will be addressed in future.&lt;/p&gt;

&lt;h2 id=&quot;decision-rules-evaluating-your-options&quot;&gt;Decision rules: Evaluating your options&lt;/h2&gt;

&lt;p&gt;Chapter 10 describes the criteria participant use to assess support for a decision. Tropman calls such criteria &lt;em&gt;decision rules&lt;/em&gt; and describes five in wide use:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Extensive: Choose the option with the most votes, with every vote weighted equally.&lt;/li&gt;
  &lt;li&gt;Intensive: Weight votes by intensity of feeling, for or against.&lt;/li&gt;
  &lt;li&gt;Expertise: Rule options in or out based upon expert advice, as might be provided by legal, technical, or accounting professionals&lt;/li&gt;
  &lt;li&gt;Involvement: Choose the option preferred by those responsible for implementing the decision.&lt;/li&gt;
  &lt;li&gt;Power: Select the choice favoured by the management, funders, the government, competition judges, or other arbiters.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This classification is not absolute. Some groups may use variations or even favour rules distinct from these.  For example, an organization might have a “cultural fit” rule that favours options conforming to “our way of doing things”, such as favouring decentralized decisions. Overall however, Tropman’s five rules are used by groups from a very wide range of contexts.&lt;/p&gt;

&lt;p&gt;The rules may provide conflicting guidance, recommending different choices due to the different factors they emphasize. An effective decision balances these emphases, addressing the concerns of every group and setting the foundation for successful collaboration.&lt;/p&gt;

&lt;h2 id=&quot;making-decision-rules-explicit-improves-decisions&quot;&gt;Making decision rules explicit improves decisions&lt;/h2&gt;

&lt;p&gt;The decision rules underly all decisions but are often only tacit. Group members are aware of the differing intensities of feeling amongst their members, differing degrees of involvement, and the like. However, if the rules are not explicitly articulated, such issues will be folded into proposals, shaping what is on offer. A group with unaddressed concerns will only be tepidly enthusiastic for or even undercut implementation of the final decision. We want active collaboration, not mere acquiescence, and that only results when people believe their concerns have been heard and accounted for.&lt;/p&gt;

&lt;p&gt;In North America, the extensive decision rule—majority vote, all participants equal—has acquired such cultural prominence that at first it may be hard to imagine alternatives.  But forcing all decisions according to this rule, to say nothing of the far more restrictive rule of “unanimous consent”, distorts the process. Explicitly articulating the choices and tradeoffs in terms of distinct rules, highlighting their potential conflicts, allows the group to balance the conflicting goals in a decision that addresses everyone’s concerns.&lt;/p&gt;

&lt;h2 id=&quot;implement-decision-rules-within-a-larger-context&quot;&gt;Implement decision rules within a larger context&lt;/h2&gt;

&lt;p&gt;Decision rules are actually implemented as part of a larger process. Tropman describes this process in his Chapter 11, where he recommends a process for leading a group to a high-quality decision. This process is subtle and requires practice. I will summarize that process in the next post.&lt;/p&gt;

&lt;p&gt;As a prerequisite, you need experience recognizing the rules in action. The next several meetings that you attend, observe the basis of the decisions made.  Can you locate claims and concerns as expressions of the underlying rules?  Are the meeting participants aware that there are potentially conflicting criteria or do they force-fit everything into a majority-vote, extensive rule?&lt;/p&gt;

&lt;p&gt;While doing this exercise, be alert to distinguishing decision rules from a more basic level of response, &lt;em&gt;values&lt;/em&gt;.  Whereas decision rules are tied to specific actions, values are deep commitments underlying such choices and assigning them an ethical or moral dimension. Values include such principles as, “Treat people fairly” or “the client comes first”. Tropman discusses values in a separate chapter. Values are important and must be considered when leading a group to a decision but they represent a distinct level from the more applied one of decision rules.&lt;/p&gt;

&lt;p&gt;In the next post, I will introduce the process by which &lt;a href=&quot;/2018/08/24/decision-crystallization/&quot;&gt;you can lead a group to consensus around a good choice&lt;/a&gt;.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The many and varied audiences for Big Data training</title>
   <link href="/2017/08/13/the-many-and-varied-audiences-for-big-data-training/"/>
   <updated>2017-08-13T00:00:00-07:00</updated>
   <id>/2017/08/13/the-many-and-varied-audiences-for-big-data-training</id>
   <content type="html">&lt;p&gt;There’s a wide range of Big Data training on offer, from full in-person university degree programs (in the North American context, typically Master’s degrees), to certificates from online universities (such as Coursera or EdX), to short professional development courses from for-profit trainers.  A common element of the sales pitches is the presumed universality of the need.  Every discipline and nearly every profession, it is claimed, will benefit from the technologies of Big Data.  Some pitches make an even stronger claim, that incorporating data analysis is now &lt;em&gt;essential&lt;/em&gt; for success.&lt;/p&gt;

&lt;p&gt;These pitches tacitly presume another form of universality: That a small suite of courses will be sufficient to cover all potential audiences. For example, the on-line courses in data analysis from Coursera fall into several distinct categories:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Courses with a full-on technology focus, such as Hadoop and Spark or analogous technologies.  These presume the students have good prerequisite knowledge of programming.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Courses with a mostly-technology focus, covering R or Python and the essentials of data analysis.  These address a similar audience to above but the focus includes smaller data sets and the level of prior technical knowledge isn’t as high.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Courses with an emphasis on an application domain, with a secondary focus on spreadsheets (typically Microsoft Excel). Specific domains include brand development, market segmentation, and related fields.  The courses presume a higher level of skill in the source domain and a lower level of technical skill. Their audience is analysts who use spreadsheets but do little to no programming.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Overviews for experts in non-analytic domains.  These presume no technical knowledge but aim to give experts in other domains sufficient background to collaborate with more technical specialists who will do the actual analysis.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first three, featuring more technical content, are by far the most common type of courses on offer. I think a big factor in this consensus is that the technologies used, whether Big Data, statistical suites, or spreadsheets, are coherent and readily identified. There are substantial populations using each of these tool chains and analysts tend to consistently use a given chain.  The programmer who builds the Spark pipeline and configures a cluster for Web site click analysis is unlikely to move on next to an Excel market segmentation. Such analyses require different skill set that are rarely posessed by any single analyst.&lt;/p&gt;

&lt;p&gt;Yet this stable clustering of tool chains belies a potentially vast range of analysis domains. I think it is indicative that the spreadsheet-based courses, which incorporate more domain knowledge, are more segmented and diverse than courses focused on tool chains. Although technologies for data analysis may fall into distinct clusters, their use cases vary widely.&lt;/p&gt;

&lt;p&gt;What happens if we design Big Data training from the other direction, starting with the needs of the ultimate consumer of its results? First, we have to identify that consumer. &lt;a href=&quot;https://www.linkedin.com/learning/instructors/doug-rose&quot;&gt;Doug Rose&lt;/a&gt; makes the case in &lt;a href=&quot;https://www.lynda.com/Business-Skills-tutorials/Understanding-Data-Science/477452-2.html&quot;&gt;Learning Data Science: Understanding the Basics&lt;/a&gt; that Data Science (which includes Big Data as a subfield) is inherently exploratory: It uncovers opportunities.
If Big Data (and Data Science more generally) is exploratory, then it takes three steps to have real effects in the world:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The analyst uncovers an opportunity: An unmet need, an unacknowledged problem, an unaddressed risk.&lt;/li&gt;
  &lt;li&gt;One or more proposals are developed to address the opportunity.  A company might propose products or services, a not-for-profit might propose campaigns or programs, while a government agency might propose policies.&lt;/li&gt;
  &lt;li&gt;A proposal is chosen and implemented. This will often proceed in phases, including focus groups, test markets, or progressive rollouts.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Each step addresses a different audience and makes different arguments:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The analyst must demonstrate that the opportunity presents a substantial benefit or cost to outcomes of interest to the organization.  The case is successful when funders allocate resources to proposal development.&lt;/li&gt;
  &lt;li&gt;For proposal development, the analyst typically takes a support role, with domain specialists developing the proposal.  The case is successful when the funders select a proposal for implementation.&lt;/li&gt;
  &lt;li&gt;For implementation the analyst is further in the background. They may provide data for assessing the first stages of rollout or develop production pipelines necessary to support full implementation of the proposal.  The effort is successful if the product,  program, or policy succeeds.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Each stage addresses a different audience, using a different style of argument. Although the technical details of data analysis may be consistent, the work products will be very different. A market analysis would estimate the monetary value of an unmet need, while a business plan for a product addressing that need would describe price points and value propositions and the test marketing of the actual product would assess customer perception of value.&lt;/p&gt;

&lt;p&gt;Different domains have different styles of argument and different presentations of evidence, differences arising from both distinct needs and distinct histories. The various forms of presentation in turn drive differences in the original data analysis.&lt;/p&gt;

&lt;p&gt;I’ll present detailed examples of this argument in future posts.  For now, I only want to emphasize this point:&lt;/p&gt;

&lt;p class=&quot;pull&quot;&gt;If we design Big Data training from the perspective of which tool chain is
used, we create a small number of curricula focused on stable, coherent
tools.  But if we design Big Data training from the perspective of which
arguments are going to be made to which audience, we may have to instead
create a much larger number of domain-specific courses.&lt;/p&gt;

&lt;p&gt;Successful arguments address concerns of interest to &lt;em&gt;the people with authority to effect the necessary change&lt;/em&gt;. For Big Data training to succeed, it must emphasize how much the analysis, from its earliest stages, has that focus.  That will probably require a much greater diversity of training than we currently see.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Random access to long string bodies incurs cache misses</title>
   <link href="/2017/06/29/rand-access-long-cache-misses/"/>
   <updated>2017-06-29T00:00:00-07:00</updated>
   <id>/2017/06/29/rand-access-long-cache-misses</id>
   <content type="html">&lt;p&gt;As I &lt;a href=&quot;/2017/06/23/for-long-strings-access-order-determines-performance/&quot;&gt;described in the last post&lt;/a&gt;, shuffling the items in the source vector leaves the string handles in contiguous sequential order while introducing disorder into the sequence of string bodies. The NShuffled “data set” is really a family of 11 related data sets, differing in the fraction of their items that were shuffled.  All sets start with the same vector &lt;code&gt;src&lt;/code&gt; of 50,000 elements, then &lt;code&gt;std::shuffle()&lt;/code&gt; is run on the first &lt;i&gt;N&lt;/i&gt; items in the vector, where &lt;i&gt;N&lt;/i&gt; ranges from 0 (no items shuffled) to 50,000 (all items shuffled) in increments of 5,000. All the data sets will have 37,500 (75% of 50,000) of their source elements copied to the result vector.&lt;/p&gt;

&lt;p&gt;These data sets allow us to correlate the degree of disorder in the string bodies with the execution time of the filter-and-transform algorithm.  More disorder in the string bodies produces more cache misses, slowing performance. I will use the NShuffle data sets to demonstrate this.&lt;/p&gt;

&lt;h2&gt;Shuffling items proportionately slows performance&lt;/h2&gt;

&lt;p&gt;The first step is to verify that shuffling produces the expected slowdown. The following graph shows the times for all 11 NShuffle data sets (right), together with the original Random data set (left), which is not shuffled:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/nshuffle-times.png&quot; alt=&quot;nshuffle-times&quot; width=&quot;495&quot; height=&quot;369&quot; class=&quot;alignnone size-full wp-image-8749&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The execution time strongly tracks the number of shuffled items.  The original unshuffled data set and the 0% NShuffle data set have the same times (3.5 ms), with each increment of 5,000 more shuffled items adding about 0.25–0.30 ms. The NShuffled data set exemplifies the performance slowdown we want to understand.&lt;/p&gt;

&lt;h2&gt;Shuffling items leaves long string bodies in disorder&lt;/h2&gt;

&lt;p&gt;The next step is to verify that this data set produces the data structure effects that we claim is causing the slowdown. I created an approximate measure of “disorder” in the loop bodies of the &lt;code&gt;src&lt;/code&gt; vector by counting “jumps”, the number of string bodies that followed their preceding string body within a single 64-byte cache line:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check_addresses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;constexpr&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size_type&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jumps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;jumps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;addr_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Total of &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;jumps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; jumps&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;std::string::data()&lt;/code&gt; member returns the address of the string body.&lt;/p&gt;

&lt;p&gt;The number of these “jumps” closely tracks the number of shuffled items:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;&lt;code&gt;n_shuffled&lt;/code&gt;&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;Jumps&lt;/td&gt;&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;0    &lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;1&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;5,000 &lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;5,000&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;10,000&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;9,999&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;15,000&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;14,998&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;20,000&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;19,997&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;25,000&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;24,997&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;30,000&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;29,999&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;35,000&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;34,999&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;40,000&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;39,999&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;45,000&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;45,000&lt;/td&gt;&lt;/tr&gt;
&lt;tr&gt;&lt;td style=&quot;text-align:right;&quot;&gt;50,000&lt;/td&gt;&lt;td style=&quot;text-align:right;&quot;&gt;49,999&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2&gt;Jumps in string body location predict benchmark times&lt;/h2&gt;

&lt;p&gt;A simple least-squares regression on benchmark time by number of shuffled items shows a strong linear fit:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/nshuffle-jumps-x-times.png&quot; alt=&quot;nshuffle-jumps-x-times&quot; width=&quot;487&quot; height=&quot;369&quot; class=&quot;alignnone size-full wp-image-8834&quot; /&gt;&lt;/p&gt;

&lt;p&gt;There are measurable performance consequences to scrambling the order in which we read the string bodies.  Is it due to cache misses?&lt;/p&gt;

&lt;h2&gt;Jumps in string body location predict L1 cache read misses&lt;/h2&gt;

&lt;p&gt;The jump count only estimates cache misses.  For example, any string body located in a lower memory address than the address of its predecessor string is counted as a jump, though they might share a cache line. We need to verify that the jump count is a reasonable proxy for cache misses.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://valgrind.org/docs/manual/cl-manual.html&quot;&gt;callgrind tool&lt;/a&gt; in the &lt;a href=&quot;http://valgrind.org/docs/manual/&quot;&gt;valgrind&lt;/a&gt; suite estimates the number of cache misses for a program by simulating execution of the program binary on a specified processor architecture, counting several types of cache misses. The tool reports L1 and last-level (last-level is L3 on the Haswell architecture used in these tests) cache data read and write misses, as well as instruction read misses.&lt;/p&gt;

&lt;p&gt;Using &lt;code class=&quot;highlighter-rouge&quot;&gt;callgrind&lt;/code&gt;, we see L1 cache read misses are perfectly correlated with the number of string body jumps in the source vector:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/nshuffle-jumps-x-l1r.png&quot; alt=&quot;nshuffle-jumps-x-l1r&quot; width=&quot;426&quot; height=&quot;448&quot; class=&quot;alignnone size-full wp-image-8841&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each core on the Haswell chip on which these tests were run has a 32K level-1 data cache and 32K level-1 instruction cache. There are negligible instruction cache misses (under 50 for every condition) because the loop is tight and cache lines for the instructions remain hot during its entire run.  In contrast, each string body jump requires loading an unread cache line from a nonsequential location, preventing prefetching. The small size of the L1 cache results in every jump causing about 5.5 read misses.  These misses are resolved from the L2 cache (unmonitored by &lt;code&gt;callgrind&lt;/code&gt;), with L2 misses resolved from the last-level L3 cache. On this chip, the L3 cache is 3 MB, shared across both cores. The benchmarks were run on a quiet system, ensuring most to all L3 cache activity was from the benchmarks and not processes on the other core.&lt;/p&gt;

&lt;h2&gt;More than 20,000 string body jumps increases L3 cache read misses&lt;/h2&gt;

&lt;p&gt;The larger size of the last-level cache allows it to accommodate more distinct string bodies before read misses arise:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/nshuffle-jumps-x-llr.png&quot; alt=&quot;nshuffle-jumps-x-llr&quot; width=&quot;420&quot; height=&quot;448&quot; class=&quot;alignnone size-full wp-image-8876&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Up to around 20,000 jumps, the number of L3 cache read misses is constant but as more jumps are added, the number of L3 cache read misses increases linearly with the jumps.&lt;/p&gt;

&lt;h2&gt;Cache write misses are harder to interpret&lt;/h2&gt;

&lt;p&gt;Increasing the number of source vector string body jumps directly affects read misses (because the string body of the loop parameter has to be copied from an unpredictable heap location) but only indirectly affects write misses.  The loop writes to two heap locations:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The string body of the loop parameter: As every string body is exactly the same length, the heap location for the last parameter body potentially can be re-used for the next.  If so, these writes will land on a hot cache location.
&lt;/li&gt;
&lt;li&gt;The 37,500 strings that pass the filter will be copied from the parameter to the next available spot in the result vector. Given that the loop parameter is an l-value, a copy-assignment must be used, which requires that a new heap location be allocated for the string body and the body from the loop parameter copied into it.  As these are the only heap operations performed in the loop, the blocks allocated for string bodies of the result vector should be in close to ascending, semi-contiguous order.
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This analysis suggests that the string body writes themselves will be to hot cache lines (the loop parameter) or in prefetchable cache lines (appending to the result vector).  However, write misses might be caused by interference from the read operations, as cache lines are evicted to make space for reads.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;callgrind&lt;/code&gt; results for L1 cache write misses show little variation by jumps:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/nshuffle-jumps-x-l1w.png&quot; alt=&quot;nshuffle-jumps-x-l1w&quot; width=&quot;431&quot; height=&quot;448&quot; class=&quot;alignnone size-full wp-image-8925&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The small range of the cache miss values relative to the y-axis is deliberate, emphasizing the small variation in L1 write misses.  The values are the same to three significant figures, only varying over the last 5,000.&lt;/p&gt;

&lt;p&gt;The results for L3 cache write misses indicate several distinct write regimes (0 jumps, 5,000–20,000 jumps, and 25,000–50,000 jumps), with a range of 200,000 misses:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/nshuffle-jumps-x-llw.png&quot; alt=&quot;nshuffle-jumps-x-llw&quot; width=&quot;426&quot; height=&quot;448&quot; class=&quot;alignnone size-full wp-image-8933&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The causes of the behaviours of each level are unclear. L1 write misses seem independent of the number of jumps but jumps, and in particular large jump counts, do affect L3 write misses.  The L3 effect may be due to cache evictions or due to greater disorder in the overall heap.  We do not have sufficient data to tell at this point.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The order in which we access the bodies of long strings, which are stored on the heap by &lt;code&gt;libstdc++&lt;/code&gt;, substantially affects the overall performance of the loop processing the vectors. Reading 50,000 string bodies in random order of addresses is 2.5 times slower than reading them in sequential order of address. Randomness in the string addresses incurs greater L1 cache read misses and, for the larger counts of random access, greater L3 cache read misses as well.&lt;/p&gt;

&lt;p&gt;Random access to string bodies has a more complicated relationship to cache write performance. In any case, the read miss performance is the dominant predictor.&lt;/p&gt;

&lt;p&gt;In my next post, I will use &lt;code&gt;callgrind&lt;/code&gt; to locate the statement where the L1 read misses arise.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>For long strings, access order determines performance</title>
   <link href="/2017/06/23/for-long-strings-access-order-determines-performance/"/>
   <updated>2017-06-23T00:00:00-07:00</updated>
   <id>/2017/06/23/for-long-strings-access-order-determines-performance</id>
   <content type="html">&lt;p&gt;In the last post, I described several possible causes of the slowdown for long strings in the by-value version of the idioms.  I concluded the most likely actual cause was the order in which the string bodies are accessed.&lt;/p&gt;

&lt;h2&gt;Structure of long strings in &lt;code&gt;libstdc++&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;To understand how the order of long strings affects performance, we must first understand the memory layout of long strings in &lt;code&gt;libstdc++&lt;/code&gt; 6.2, the version used in this series.  This implementation of &lt;code&gt;std::string&lt;/code&gt; stores a long string in two parts: the handle and the string body.&lt;/p&gt;

&lt;p&gt;The string handle occupies 32 bytes (in an environment with 64-bit pointers).  The handle has the &lt;a href=&quot;http://en.cppreference.com/w/cpp/language/storage_duration&quot;&gt;storage duration&lt;/a&gt; of its string value: automatic, static, thread, or dynamic. For a long string, the handle comprises three fields:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;An 8-byte pointer to the string body.&lt;/li&gt;
&lt;li&gt;An 8-byte string length.&lt;/li&gt;
&lt;li&gt;An 8-byte capacity of the string body.&lt;/li&gt;
&lt;li&gt;An unused 8-byte block (used only for short strings).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For the algorithms studied in these posts, the handles for the strings in the &lt;code&gt;src&lt;/code&gt; vector are stored in the vector body (itself allocated on the heap), while the handle for the loop parameter string is stored in a local variable on the stack.&lt;/p&gt;

&lt;p&gt;The string body is stored in a separate block, always allocated on the heap, regardless of the storage duration of its handle. Its size is stored in the capacity field of the handle. It must be at least long enough to hold the current string value plus a terminating null byte. In the case of the algorithms studied in these posts, all the strings have a capacity of 27, the minimum necessary for a 26-byte string.&lt;/p&gt;

&lt;h2&gt;The memory layout of the &quot;random&quot; condition&lt;/h2&gt;

&lt;p&gt;Now consider how the source vector is built in the basic, random, case using the &lt;code&gt;libstdc++&lt;/code&gt; implementations of &lt;code&gt;std::vector&lt;/code&gt; and &lt;code&gt;std::string&lt;/code&gt;. For the dataset with 75% of its entries copied to the source, the algorithm is:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Define two strings:  An &quot;included&quot; string, that will be copied to the result vector, and an &quot;excluded&quot; string, that will not be copied. Because both strings are 27 bytes long (26 characters plus a null terminator), their bodies will be stored on the heap.
&lt;/li&gt;
&lt;li&gt;The source vector is prereserved to a capacity of 50,000 entries.
&lt;/li&gt;
&lt;li&gt;A random number generator is called 50,000 times, generating integers in the range [0,99].
&lt;/li&gt;
&lt;li&gt;For a random integer in the range [0,74], a copy of the &quot;included&quot; string is constructed at the next available entry in the source vector.  For an integer in the range [75,99], a copy of the &quot;excluded&quot; string is constructed in the next available source entry.  In either case, the string's 32-byte handle will be stored directly in the vector, while its body will be copied to a 27-byte block obtained from the heap.
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Each string body is stored in a separate block.  The layout of these blocks depends upon the underlying allocator, which for these tests is the &lt;a href=&quot;https://sourceware.org/git/?p=glibc.git;a=tree;f=malloc;h=d975e2c01d63ca983379033b183f0f404da8188c;hb=ab30899d880f9741a409cbc0d7a28399bdac21bf&quot;&gt;&lt;code&gt;glibc 2.23&lt;/code&gt; implementation of &lt;code&gt;malloc&lt;/code&gt;&lt;/a&gt;. Rather than get into the specifics of this implementation, I will describe the general issues raised by all &lt;code&gt;malloc&lt;/code&gt;-style allocators.&lt;/p&gt;

&lt;p&gt;Each string body is allocated via a separate call to &lt;code&gt;malloc()&lt;/code&gt;.  Thus every string body will be in a separate block. Because most allocators will insert metadata and perhaps padding between these blocks, they will not be contiguous. However, the blocks typically will be &lt;em&gt;near&lt;/em&gt; each other, in increasing order of memory address, although the blocks can in principle be allocated at arbitrary memory locations.  For example, the &lt;code&gt;glibc 2.23&lt;/code&gt; allocator allocates the 50,000 source string bodies in adjacent 48-byte blocks, with one or two longer jumps in the sequence.&lt;/p&gt;

&lt;p&gt;The resulting memory layout of the &lt;code&gt;src&lt;/code&gt; vector will look like:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/coherent-long-string-bodies-75-pct.png&quot; alt=&quot;coherent-long-string-bodies-75-pct&quot; width=&quot;502&quot; height=&quot;383&quot; class=&quot;alignnone size-full wp-image-8665&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now consider the code (&lt;code&gt;loop_emplace()&lt;/code&gt; version) that reads that vector:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// by-value version
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The loop accesses each element of the source vector &lt;code&gt;src&lt;/code&gt; in sequential order. The string portion of the source element is copy-constructed into &lt;code&gt;p.first&lt;/code&gt;. (The element cannot be move-constructed because &lt;code&gt;src&lt;/code&gt; must not be modified.) Consequently, the string handles (stored contiguously and in sequence in the vector body, located on the heap) and the string bodies (stored semi-contiguously and in sequence as individual blocks on the heap) are accessed in sequentially-increasing order of addresses.  This maximizes the benefit from hardware prefetching, which will pull the next handle and string body into the cache before we request them.&lt;/p&gt;

&lt;h2&gt;The memory layout of the &quot;shuffled&quot; condition&lt;/h2&gt;

&lt;p&gt;Now consider the memory layout in the “shuffled” condition.  This condition begins with the same initialization as the “random” condition and then adds a fifth step:&lt;/p&gt;

&lt;ol start=&quot;5&quot;&gt;
&lt;li&gt;
    &lt;p&gt;Call &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/random_shuffle&quot;&gt;&lt;code&gt;std::shuffle&lt;/code&gt;&lt;/a&gt; on &lt;code&gt;src&lt;/code&gt;:&lt;/p&gt;

    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rbits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
    &lt;/div&gt;

    &lt;p&gt;The &lt;code&gt;libstdc++&lt;/code&gt; implementation of the &lt;code&gt;std::shuffle&lt;/code&gt; algorithm swaps string values by calling &lt;a href=&quot;http://en.cppreference.com/w/cpp/string/basic_string/swap&quot;&gt;&lt;code&gt;std::string::swap(std::string&amp;amp;)&lt;/code&gt;&lt;/a&gt;, which swaps the string handles but leaves the string bodies in their original heap locations. (This behaviour is enabled by the library standard but not required, so we have to check whether a given implementation in fact does this.)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;After the shuffle, access to the string handles in the source vector remains sequential but &lt;em&gt;access to the string bodies&lt;/em&gt; in the heap is &lt;em&gt;random&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/incoherent-long-string-bodies-75.png&quot; alt=&quot;Incoherent long string bodies-75&quot; width=&quot;502&quot; height=&quot;382&quot; class=&quot;alignnone size-full wp-image-8669&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When the string bodies are accessed in random order, copy-constructing the loop parameter will generate many cache misses.&lt;/p&gt;

&lt;h2&gt;Specifying the level of disorderly heap access&lt;/h2&gt;

&lt;p&gt;The test data sets used to date in this series only test the extremes of heap disorder.  The original (“Random”) data set and in-situ sorted data set access all string bodies sequentially, while the shuffle data set accesses all the bodies randomly.  We want to be able to specify a specific degree of randomness in the source vector access and measure its effects on runtime.&lt;/p&gt;

&lt;p&gt;We will add fifth data set, “NShuffle”, in which we can specify the proportion of source strings whose bodies are accessed randomly, while the remaining proportion of source strings are accessed sequentially.  This data set is created similarly to Shuffle, except that only the first &lt;code&gt;n_shuffle&lt;/code&gt; number of elements are shuffled, while the rest are left in their original order. The &lt;code&gt;n_shuffle&lt;/code&gt; parameter can range from 0 (all elements accessed sequentially) to 50,000 (all elements accessed randomly):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rbits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Running the benchmarks on NShuffle data sets with &lt;code&gt;n_shuffle&lt;/code&gt; ranging from 0 to 50,000, in units of 5,000, yields very interesting results.  I’ll leave that here as a teaser and present the actual results in the next post.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Sidling up to the long string slowdown</title>
   <link href="/2017/06/14/sidling-up-to-the-long-string-slowdown/"/>
   <updated>2017-06-14T00:00:00-07:00</updated>
   <id>/2017/06/14/sidling-up-to-the-long-string-slowdown</id>
   <content type="html">&lt;p&gt;In the last post, I highlighted an anomaly in the results for filtering long strings using the by-value implementation of the loop. The usual suspect for such outcomes, heap fragmentation, didn’t seem to apply in this case. What might be the actual source of the problem?&lt;/p&gt;

&lt;p&gt;The slowdown arises only for long strings, which suggests it is related to the heap, as long strings are the only form of string considered in these posts that use the heap. Unique &lt;code&gt;char const *&lt;/code&gt; strings only move pointers, while short strings, &lt;code&gt;std::string&lt;/code&gt; instances less than 16 characters, are stored in the string handle by &lt;code&gt;libstdc++&lt;/code&gt; 6.2. The degree of slowdown correlates well with the number of elements that have been moved in the source vector after it was initially created.  This suggests that the slowdown is related to some measure of the “degree of disorder” in the heap.&lt;/p&gt;

&lt;p&gt;For some reason, moving elements of the source vector slows performance. What might be the mechanisms? If memory had uniform access cost, moving the elements would not have any effect. The effect must be due to nonuniform access costs incurred by the memory hierarchy. There several possible mechanisms, in increasing order of execution cost:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data cache misses due to the heap entries being more dispersed. For example, if when shuffling the array the string bodies are copied into a more dispersed range of locations, the pass through the array by the &lt;code&gt;for&lt;/code&gt; loop will no longer be a consecutive pass through the heap memory but instead require accessing widely-separated parts of memory.  Such accesses require 1--2 cache line loads per string body, with no benefit from data prefetching.
&lt;/li&gt;
&lt;li&gt;TLB cache misses due to the heap entries being even more widely dispersed.  The TLB cache can only accommodate so many pages. For these benchmarks, the page size is 4,096 B. If the 50,000 string bodies are stored contiguously (ignoring any metadata required by the allocator), they require 330 pages.  If the strings are stored in the worst possible layout, they require 50,000 pages. If the total pages required to access the code plus all data exceeds the TLB cache capacity, TLB misses will slow the benchmark.  Given that the Haswell architecture of my chip has an L2 TLB with &lt;a href=&quot;http://www.realworldtech.com/haswell-cpu/5/&quot;&gt;1,024 8-way associative&lt;/a&gt; entries, I consider this possibility less likely than data cache misses.
&lt;/li&gt;
&lt;li&gt;Swap costs due to accesses of data pages that have been swapped. &lt;code&gt;vmstat&lt;/code&gt; reports no swaps occurred or these benchmarks, so swapping is not a factor in this case.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note that I am running the benchmarks in an Ubuntu 16.04 guest operating system under Virtual Box, in turn running on a Mac OS 10.12 host. This may add confounding effects on the actual, physical cache and TLB, as they are multiplexed between the host and guest systems by Virtual Box.&lt;/p&gt;

&lt;p&gt;In addition to memory hierarchy effects, there is the possible effect of cache fragmentation: The allocator may have to walk through more candidate blocks to find one of acceptable size (classical slowdown due to fragmentation). In addition to the basic cost of walking the data structure, increased heap walking could incur any of the above memory hierarchy costs.&lt;/p&gt;

&lt;h2&gt;The actual benchmarks make some causes unlikely&lt;/h2&gt;

&lt;p&gt;We can argue against some causes based upon how the specific benchmarks are written. As noted in the last post, the consistent size of the string bodies, all exactly 27 bytes long, ensures that classical fragmentation will not be a problem. Fragmentation is caused by sequences of allocation requests of differing sizes, whereas in this benchmark, any released blocks can be reused for the next request.&lt;/p&gt;

&lt;p&gt;The benchmark structure also ensures that the string bodies in the source vector will in fact not be moved when the vector is sorted or shuffled.  The &lt;code&gt;std::vector&lt;/code&gt; code can call the move assignment, &lt;code&gt;std::string::operator=(string&amp;amp;&amp;amp;)&lt;/code&gt;, to swap elements (although I have not verified this). The move assignment only copies the pointer to the string body, not the actual body. Consequently, sorting or shuffling the source vector should not affect the heap layout at all. The “degree of dispersal” of the heap bodies will be exactly the same, whether the source data has been reordered or not.&lt;/p&gt;

&lt;p&gt;A more subtle form of dispersal remains possible, however. Although the string bodies are never moved, &lt;em&gt;the pointers to them are moved&lt;/em&gt;. After reordering, sequential access to the pointers in the source vector produces nonsequential access to the string bodies in the heap.  This might well result in more cache misses when processing sorted or shuffled data. I will consider the evidence for this in the next post.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Microbenchmarks are highly sensitive to the heap context!</title>
   <link href="/2017/06/10/microbenchmarks-are-highly-sensitive-to-the-heap-context/"/>
   <updated>2017-06-10T00:00:00-07:00</updated>
   <id>/2017/06/10/microbenchmarks-are-highly-sensitive-to-the-heap-context</id>
   <content type="html">&lt;p&gt;Over two weeks ago, I posted an article about &lt;a href=&quot;/2017/05/22/passing-stdstring-by-value-noticeably-slows-the-idioms/&quot;&gt;by-value parameters in the loop and &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt; idioms&lt;/a&gt;. Included in one of the plots was an anomaly that, when I considered it more closely, blew up the analysis.  In fact, I’ve spent most of the past two weeks following up on the implications of this seemingly small anomaly. Ultimately, it’s given me reason to question the reliability of microbenchmarks in a wide range of circumstances. And after two weeks of work, using a variety of tools, I remain unclear about the underlying phenomenon. I’m writing a series of posts to clarify what I’ve learned to date and to set my future agenda.&lt;/p&gt;

&lt;h2&gt;The anomaly&lt;/h2&gt;

&lt;p&gt;But this is getting ahead of the story. I’ll begin with the results that started it all: The upper-left corner plot in the overview section of that two-week-old post. I’ve isolated the relevant data in the following plot, together with some new replication runs that demonstrate the effect is reliable:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/loop_emp_long_copy.png&quot; alt=&quot;loop_emp_long_copy&quot; width=&quot;495&quot; height=&quot;369&quot; class=&quot;alignnone size-full wp-image-7915&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The plot compares the results for the two versions of the loop, which differ only in using either &lt;code&gt;emplace_back()&lt;/code&gt; or &lt;code&gt;push_back()&lt;/code&gt; in their body. The by-value version of the loop parameter was used in both cases:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_loop_emplace&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_loop_push&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Each version has been compiled with &lt;code&gt;-O2&lt;/code&gt; and run twice on random data sets, with from 0–100% of the source data set copied to the result.&lt;/p&gt;

&lt;p&gt;At first glance, the result wasn’t surprising. The loop using &lt;code&gt;push_back()&lt;/code&gt; was slower, which I would expect, given that it constructs an extra &lt;code&gt;pair&lt;/code&gt; compared to the one using &lt;code&gt;emplace_back()&lt;/code&gt;. This is borne out by an analysis of the generated object code.  Summarizing their object code in pseudo-C:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// str_loop_emplace_long_by_copy:

goto begin

loop: V &amp;lt;- src_i-&amp;gt;second ^ 2
 if (res.cap_end() == res_i) goto expand_capacity [never taken]
 res_i-&amp;gt;first &amp;lt;- p.first
 res_i-&amp;gt;second &amp;lt;- V
 ++res_i
next: p.first.~string()
 if (++src_i == src.end()) goto end
begin: p &amp;lt;- *src_i
 if (exclude != p.first) goto loop
 else goto next
end:

// str_loop_push_long_by_copy:

goto begin

loop: T.first &amp;lt;- p. first
 T.second &amp;lt;- src_i-&amp;gt;second ^ 2
 res.emplace_back(T)
 T.first.~string()
next: p.first.~string()
 if (++src_i == src.end()) goto end
begin: p &amp;lt;- *src_i
 if (exclude != p.first) goto loop
 else goto next
end:
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Spot the problem?  I’ll take solace if you didn’t; I looked at the original plot for weeks before seeing it myself.&lt;/p&gt;

&lt;p&gt;Here’s the anomaly: For a data set in which no values are copied (a 0% data set), &lt;em&gt;the executed code is identical&lt;/em&gt; but in the above plot the &lt;code&gt;push_back()&lt;/code&gt; loop is &lt;em&gt;75% slower&lt;/em&gt; on that data set.  (Note that the &lt;code&gt;push_back()&lt;/code&gt; loop could be slower on other data sets that actually require copying data. The two loops only execute identical code for the 0% case.)&lt;/p&gt;

&lt;h2&gt;The order effect&lt;/h2&gt;

&lt;p&gt;Results such as this strongly suggest an order effect: The &lt;code&gt;emplace_back()&lt;/code&gt; loop is faster because it is executed first. Given that the &lt;code&gt;nonius&lt;/code&gt; benchmarking framework executes complex code as it analyses the results after each benchmark, there could easily be such an effect. And in fact when the order of the two benchmarks is reversed, the &lt;code&gt;push_back()&lt;/code&gt; loop becomes faster than the &lt;code&gt;emplace_back()&lt;/code&gt; loop.&lt;/p&gt;

&lt;p&gt;I revised the structure of the benchmark calls so that a given run executes only a single benchmark, followed by computing the analysis.  When the loops are re-benchmarked under the revised structure, we get the following results (new values in right column of each lane, in green):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/loop_emp_long_copy_by_run.png&quot; alt=&quot;loop_emp_long_copy_by_run&quot; width=&quot;495&quot; height=&quot;369&quot; class=&quot;alignnone size-full wp-image-7916&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;emplace_back()&lt;/code&gt; loop has the same times whether run individually or first in a sequence, whereas the &lt;code&gt;push_back()&lt;/code&gt; loop is much slower than the other loop when run second in sequence but achieves comparable speed when measured in its own run. A similarly dramatic speedup occurs (shown later) when the &lt;code&gt;transform&lt;/code&gt; idiom is measured in its own run rather than following the loop benchmarks.  Given such clear evidence of an order effect, the benchmarks should all be run individually rather than in sequence.&lt;/p&gt;

&lt;p&gt;The confounding effect of order means that all the microbenchmark results in my previous posts in this series should be considered tentative until they can be replicated using individual runs. Most likely only the long string, by-value runs will require revision but this needs to be verified. I will do those tests later. For now, let us continue exploring the order effect.&lt;/p&gt;

&lt;h2&gt;The likely source of the order effect&lt;/h2&gt;

&lt;p&gt;When does order matter? The effect doesn’t appear on any runs with with short or unique strings nor on runs with long strings and by-reference parameters, only on runs with long strings and by-value parameters. These runs make the heaviest use of the heap. Short and unique strings do not use the heap at all and the by-reference code for long strings use the heap far less than the by-value ones.&lt;/p&gt;

&lt;p&gt;The traditional first response to an outcome like this is “heap fragmentation”. But when considered in detail, fragmentation doesn’t seem to be the likely cause of this performance.  Fragmentation has two observable outcomes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;An allocation request fails despite there being sufficient available space to satisfy it (because that available space is spread across multiple smaller blocks, none of which is individually large enough), or
&lt;/li&gt;
&lt;li&gt;Allocation requests become progressively slower (because the allocator has to consider progressively more available blocks before finding one sufficiently large for the request).
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The first result is manifestly not occurring—all requests succeed.  The second result is unlikely to arise in these benchmarks because for our test datasets, every long string body is exactly 27 bytes long.  Thus &lt;em&gt;any&lt;/em&gt; previously-freed block for a string body would be sufficient to satisfy a new request.&lt;/p&gt;

&lt;p&gt;If classical heap fragmentation is not the source of the order effect, what is?  The cause is most likely due to some interaction between the heap layout and the sequence of heap requests, just not due to a sequence of progressively-larger requests that induce classical fragmentation.  The cause of the slowdown seen in these benchmarks is related but more subtle.&lt;/p&gt;

&lt;p&gt;Consider the following plot:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/06/long-strings-by-value-consec-vs-ind-runs.png&quot; alt=&quot;long-strings-by-value-consec-vs-ind-runs&quot; width=&quot;906&quot; height=&quot;476&quot; class=&quot;alignnone size-full wp-image-8086&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The left-hand facet (BY_REF=Ref) is the original by-reference results, run using the old structure, with all four benchmarks consecutively in a single run. The right-hand facet (BY_REF=Copy) is the by-value results, including both the older consecutive structure (blue) and the newer individual (green) structure. The plot compares results for the loop with &lt;code&gt;emplace_back()&lt;/code&gt; and the &lt;code&gt;transform&lt;/code&gt; idiom with &lt;code&gt;push_back()&lt;/code&gt;.  The two idioms are run on four data sets, including the random (R) and sorted (S) used in previous benchmarks, together with two new data sets, the shuffled (H) and in-situ sorted (I).  We’ll get to the new data sets in a bit; for now, we’ll focus on the random and sorted data sets, specifically the left four lanes (lp_em(R), lp_em(S)) on the right facet.&lt;/p&gt;

&lt;p&gt;These four lanes are timings for the &lt;code&gt;emplace_back()&lt;/code&gt; loop, for random and sorted data sets, run first in a consecutive run (followed by three other benchmarks) and individually (no benchmarks following). Previous results suggest that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The times for a first-in-consecutive run and an individual run on the same data set should be identical. There is no prior benchmark affecting the heap.
&lt;/li&gt;
&lt;li&gt;For the random and sorted data sets, the times for 0% and 100% copies should be the same but the times for 25%, 50%, and 75% copied should be shorter for sorted data.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But these are not the patterns that we see in the above plot.  Instead:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For sorted data, the individual runs are &lt;em&gt;slower&lt;/em&gt; than the first-in-consecutive runs, despite the nominal similarity of the setup preceding them.
&lt;/li&gt;
&lt;li&gt;For individual runs, sorted data sets with 75% and 100% copies are &lt;em&gt;slower&lt;/em&gt; than random data sets, despite the branch prediction benefits of sorted data.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These results both seem to result from heap effects:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The setup sequence for the individual runs is not identical to that for consecutive runs but in fact does more heap operations.  This seems to slow down the benchmark code that follows, at least on sorted data.
&lt;/li&gt;
&lt;li&gt;The sorted data set is created by applying &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/sort&quot;&gt;&lt;code&gt;std::sort&lt;/code&gt;&lt;/a&gt; to the random data set. Moving the source array values around seems to slow down the code, at least when it is copying large parts of the source array into the result (75% and 100%).
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In short, performing more heap operations before running the benchmarks seems to slow the code.  To test this with more extreme cases, I added two new data sets:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Shuffled (H):  The random data set is fully shuffled via &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/random_shuffle&quot;&gt;&lt;code&gt;std::shuffle&lt;/code&gt;&lt;/a&gt;.  As a full shuffle, this does many more moves than a sort on a data set with only two distinct values.
&lt;/li&gt;
&lt;li&gt;In-situ sorted (I): Where the &quot;sorted&quot; data set was created by sorting the random data set, which required moving some values, this data set was created by building the values in sorted order directly in their original locations.  Consequently, no element in this data set has been moved.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you can see in the above plot (lanes suffixed (H) and (I)), number of element moves is strongly predictive of time:  The in-situ sorted data covers the same range as the random data (no moves in either data set), while the shuffled data set (with many moves) is the slowest by far, for both idioms.&lt;/p&gt;

&lt;h2&gt;What next?&lt;/h2&gt;

&lt;p&gt;These results highlight two potentially-related effects that arise when the by-value versions of these idioms process strings whose bodies lie on the heap:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The number and type of heap operations in the setup modestly affect the idioms' speed.
&lt;/li&gt;
&lt;li&gt;The number of times elements in the source vector have been moved in the setup strongly affects the idioms' speed.
&lt;/li&gt;
&lt;li&gt;The uniform length of the string bodies (27 bytes) manipulated by the idioms indicates that the timing effects are not due to classical heap fragmentation.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What is the problem and what tools might we use to identify it? That, reader, is the tale to come.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>The elegant machine code for char const *</title>
   <link href="/2017/05/24/the-elegant-machine-code-for-char-const/"/>
   <updated>2017-05-24T00:00:00-07:00</updated>
   <id>/2017/05/24/the-elegant-machine-code-for-char-const</id>
   <content type="html">&lt;p&gt;Unique strings—null-terminated strings uniquely identified by their &lt;code&gt;char const *&lt;/code&gt;—are the simplest type considered in this series of posts. Constructing, copying, moving, and assigning these strings are trivial operations on a single pointer. No destructor code is required.&lt;/p&gt;

&lt;p&gt;This simplicity was reflected in the benchmarks. Unique strings were
&lt;a href=&quot;/2017/05/19/benchmarking-the-transform-and-loop-idioms/&quot;&gt;substantially faster than &lt;code class=&quot;highlighter-rouge&quot;&gt;std::string&lt;/code&gt;&lt;/a&gt; and they
generated identical code and &lt;a href=&quot;/2017/05/22/passing-stdstring-by-value-noticeably-slows-the-idioms/&quot;&gt;the same performance whether passed by-value or by-reference&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Even when presented this simple data type, however, the &lt;code&gt;transform&lt;/code&gt; idiom was &lt;a href=&quot;/2017/05/19/benchmarking-the-transform-and-loop-idioms/&quot;&gt;two times slower&lt;/a&gt; than the basic loop.&lt;/p&gt;

&lt;p&gt;In this post, I explore the machine code generated by the two idioms for unique strings. For both idioms, the generated code is much simpler for unique strings than for &lt;code&gt;std::string&lt;/code&gt;.  On the other hand, the ability of the loop idiom to inline &lt;code&gt;vector::emplace_back()&lt;/code&gt; appears to give the loop its speed advantage over &lt;code&gt;transform&lt;/code&gt;, which does not inline the call.&lt;/p&gt;

&lt;h2&gt;Machine code for the loop&lt;/h2&gt;

&lt;p&gt;The benchmark form of the loop idiom was:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_loop_emplace&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The loop (Lines 3–6) generates the following elegant machine code (the same code is generated for both by-value and by-reference versions):&lt;/p&gt;

&lt;!-- highlight=&quot;12,13&quot; gutter=&quot;false&quot;--&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// Loop
// %rbp: res_i
// %rbx: src_i
// %r14: &amp;amp; res
// %r15: src.end()
&amp;lt;+80&amp;gt;:	mov    (%rbx),%rdx               %rdx &amp;lt;- res_i-&amp;gt;province
&amp;lt;+83&amp;gt;:	cmp    0x26c656(%rip),%rdx        # 0x673f70 &amp;lt;exclude&amp;gt;
&amp;lt;+90&amp;gt;:	je     0x40793f &amp;lt;+127&amp;gt;
&amp;lt;+92&amp;gt;:	mov    0x8(%rbx),%ecx            %ecx &amp;lt;- src_i-&amp;gt;value
&amp;lt;+95&amp;gt;:	mov    0x10(%r14),%rsi           %rsi &amp;lt;- res.cap_end()
&amp;lt;+99&amp;gt;:	imul   %ecx,%ecx                 %ecx &amp;lt;- src_i-&amp;gt;value ^ 2
&amp;lt;+102&amp;gt;:	cmp    %rbp,%rsi                 res_i ==? res.cap_end()
&amp;lt;+105&amp;gt;:	je     0x407968 &amp;lt;+168&amp;gt;           if at capacity, branch to
                                         reallocate vector
&amp;lt;+107&amp;gt;:	test   %rbp,%rbp                 res_i ==? 0
&amp;lt;+110&amp;gt;:	je     0x407937 &amp;lt;+119&amp;gt;
&amp;lt;+112&amp;gt;:	mov    %rdx,0x0(%rbp)            res_i-&amp;gt;province &amp;lt;-
                                                res_i-&amp;gt;province
&amp;lt;+116&amp;gt;:	mov    %ecx,0x8(%rbp)            res_i-&amp;gt;value&amp;lt;-srt_i-&amp;gt;value^2
&amp;lt;+119&amp;gt;:	add    $0x10,%rbp                ++res_i
&amp;lt;+123&amp;gt;:	mov    %rbp,0x8(%r14)            res.end() &amp;lt;- res_i

&amp;lt;+127&amp;gt;:	mov    %r8,%rax                  %rax &amp;lt;- res.begin()
&amp;lt;+130&amp;gt;:	add    $0x10,%rbx                ++src_i
&amp;lt;+134&amp;gt;:	cmp    %rbx,%r15                 src_i ==? src.end()
&amp;lt;+137&amp;gt;:	jne    0x407910 &amp;lt;+80&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The code allocates &lt;code&gt;%rbx&lt;/code&gt; to the source iterator to and &lt;code&gt;%rbp&lt;/code&gt; to the result iterator, walking each through their respective vectors. Instructions &lt;code&gt;&lt;/code&gt;–&lt;code&gt;&lt;/code&gt; (highlighted) test whether the result iterator has reached the vector’s capacity, branching to &lt;code&gt;&lt;/code&gt; if it has.  The code at &lt;code&gt;&lt;/code&gt; (not shown) allocates a larger array, copies the values, and deletes the old array.&lt;/p&gt;

&lt;p&gt;The caller of this function has already reserved enough space in the result vector, so the branch to &lt;code&gt;&lt;/code&gt; is never taken.  In actual runs, the instructions from &lt;code&gt;&lt;/code&gt;–&lt;code&gt;&lt;/code&gt; are the only ones executed for the loop.  This tight, simple code accounts for the high performance observed in the unique string benchmarks.&lt;/p&gt;

&lt;h2&gt;Machine code for &lt;code&gt;transform&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The benchmark form of &lt;code&gt;transform&lt;/code&gt; had two parts. The loop part:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_option&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;and the part extending the result vector (identical code was produced from a call to &lt;code&gt;vector::push_back()&lt;/code&gt;, which simply expanded to a call to &lt;code&gt;vector::emplace_back()&lt;/code&gt;):&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  &lt;span class=&quot;k&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_not_self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opt_back_emplace_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;amp;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;has_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;There are two crucial differences between this source and the loop source:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The two aspects, filtering and appending, are separate functions communicating via the temporary result from the lambda expression.  The loop code, by contrast, uses the single value &lt;code&gt;p&lt;/code&gt; for both filtering and appending.
&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;transform&lt;/code&gt; idiom resolves to a different instance of &lt;code&gt;vector::emplace_back()&lt;/code&gt; from the instance resolved by the loop. The &lt;code&gt;transform&lt;/code&gt; idiom resolves to the form taking a single value (in this case, the rvalue temporary result of the lambda), while the loop resolves to the form taking the arguments to the &lt;code&gt;std::pair()&lt;/code&gt; constructor, which is called to directly construct the pair at the result vector's next available location.
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These differences combine to generate different code from the loop. The code merges &lt;code&gt;transform&lt;/code&gt; and the output iterator into a single routine, but it retains a call to &lt;code&gt;emplace_back()&lt;/code&gt; rather than inlining the routine. This code is twice as slow as its loop counterpart:&lt;/p&gt;

&lt;!-- highlight=&quot;19&quot; gutter=&quot;false&quot; --&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// Loop
// %rsp: RT
//    0x0  char const *
//    0x8  value
//    0x10 has_value
// %rbx: src_i
// %rbp: src.end()
// %r12: &amp;amp; res
&amp;lt;+64&amp;gt;:  mov    (%rbx),%rdx               %rdx &amp;lt;- char const *
&amp;lt;+67&amp;gt;:  cmp    0x26cf56(%rip),%rdx        # 0x674f70 &amp;lt;exclude&amp;gt;
&amp;lt;+74&amp;gt;:  mov    0x8(%rbx),%eax            %eax &amp;lt;- src_i-&amp;gt;value
&amp;lt;+76&amp;gt;:  je     0x40803a &amp;lt;+106&amp;gt;
&amp;lt;+79&amp;gt;:  imul   %eax,%eax                 %eax &amp;lt;- src_i-&amp;gt;value ^ 2
&amp;lt;+82&amp;gt;:  mov    %rsp,%rsi                 %rsi &amp;lt;- &amp;amp; RT
&amp;lt;+85&amp;gt;:  mov    %r12,%rdi                 %rdi &amp;lt;- &amp;amp; res
&amp;lt;+89&amp;gt;:  mov    %rdx,(%rsp)               RT.province &amp;lt;- char const * 
&amp;lt;+94&amp;gt;:  movb   $0x1,0x10(%rsp)           RT.has_value &amp;lt;- 1
&amp;lt;+97&amp;gt;:  mov    %eax,0x8(%rsp)            RT.value &amp;lt;- src_i-&amp;gt;value ^ 2
&amp;lt;+101&amp;gt;: callq  0x413590 &amp;lt;std::vector::emplace_back(std::pair&amp;lt;char const*, int&amp;gt;&amp;amp;&amp;amp;)&amp;gt;
&amp;lt;+106&amp;gt;: add    $0x10,%rbx                ++src_i
&amp;lt;+110&amp;gt;: cmp    %rbx,%rbp                 src_i ==? src.end()
&amp;lt;+113&amp;gt;: jne    0x408010 &amp;lt;+64&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The above code calls the single-argument version of &lt;code&gt;emplace_back()&lt;/code&gt; (highlighted line), which is straightforward for the case where the vector has remaining capacity:&lt;/p&gt;

&lt;!-- gutter=&quot;false&quot; --&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// vec: this (std::vector&amp;lt;std::pair&amp;lt;char const *, int&amp;gt;&amp;gt;*)
// RT: parameter to emplace_back (std::pair&amp;lt;char const*, int&amp;gt;&amp;amp;&amp;amp;)
// %rax: vec.end()
&amp;lt;+0&amp;gt;:  mov    0x8(%rdi),%rax            %rax &amp;lt;- vec.end()
&amp;lt;+4&amp;gt;:  cmp    0x10(%rdi),%rax           vec.cap_end() ==? vec.end()
&amp;lt;+8&amp;gt;:  je     0x4131b0 &amp;lt;+48&amp;gt;            call emplace_back_aux to allocate larger buffer, copy, and delete old
&amp;lt;+10&amp;gt;: test   %rax,%rax                 vec.end() ==? 0
&amp;lt;+13&amp;gt;: je     0x41319d &amp;lt;+29&amp;gt;            Skip emplace if == 0 [Never taken in this program]
&amp;lt;+15&amp;gt;: mov    (%rsi),%r9                %r9 &amp;lt;- RT.province (8-byte char const *)
&amp;lt;+18&amp;gt;: mov    0x8(%rsi),%r10            %r10 &amp;lt;- RT.value (8 bytes moved, of which 4 are value)
&amp;lt;+22&amp;gt;: mov    %r9,(%rax)                vec.end()-&amp;gt;province &amp;lt;- RT.province
&amp;lt;+25&amp;gt;: mov    %r10,0x8(%rax)            vec.end()-&amp;gt;value &amp;lt;- RT.value
&amp;lt;+29&amp;gt;: add    $0x10,%rax                
&amp;lt;+33&amp;gt;: mov    %rax,0x8(%rdi)            ++vec.end()
&amp;lt;+37&amp;gt;: retq   
&amp;lt;+38&amp;gt;: nopw   %cs:0x0(%rax,%rax,1)
&amp;lt;+48&amp;gt;: jmpq   0x413060 &amp;lt;std::vector&amp;lt;&amp;gt;::_M_emplace_back_aux&amp;lt;std::pair&amp;lt;char const*, int&amp;gt; &amp;gt;(std::pair&amp;lt;char const*, int&amp;gt;&amp;amp;&amp;amp;)&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Most of the machine code for the &lt;code&gt;transform&lt;/code&gt; loop matches that for the &lt;code&gt;for&lt;/code&gt; loop.  This code also allocates &lt;code&gt;%rbx&lt;/code&gt; to the source vector iterator.  However, in this case no register is allocated to the iterator for the result vector. Instead,  &lt;code&gt;%r12&lt;/code&gt; is allocated to the address of the result vector.&lt;/p&gt;

&lt;p&gt;The different register allocation results from the lack of inlining.  Where the loop code inlined the call to the multiple-argument version of &lt;code&gt;emplace_back()&lt;/code&gt;, the &lt;code&gt;transform&lt;/code&gt; idiom’s single-argument version is retained as a function call in at Instruction &lt;code&gt;&lt;/code&gt; (highlighted).&lt;/p&gt;

&lt;p&gt;In &lt;code&gt;emplace_back()&lt;/code&gt;, the next available location is loaded into &lt;code&gt;%rax&lt;/code&gt;, the values are stored indirectly through that register, and &lt;code&gt;vec.end()&lt;/code&gt; is incremented.  For every copied value, this code incurs an extra subroutine call, an extra load from memory, and an extra store from memory.  Of these three, the subroutine call is likely the largest contributor to &lt;code&gt;transform&lt;/code&gt;’s slower performance, as the memory references will consistently resolve to the L1 cache. All three would have been eliminated by inlining the function.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The simple structure of the &lt;code&gt;char const *&lt;/code&gt; datatype allows the gcc optimizer to strut its stuff.  The code for both the loop and &lt;code&gt;transform&lt;/code&gt; is simple and elegant, their respective algorithms pared to essentials.  For this case, the C++ metaprogramming facilities allow the Standard Template Library to fulfill its promise of an abstract notation that nonetheless can generate code precisely targeted to the provided type. The range &lt;code&gt;for&lt;/code&gt; over a &lt;code&gt;std::vector&lt;std::pair&gt;&amp;lt;/code&amp;gt; generates code as efficient as any C program directly iterating pointers.&lt;/std::pair&gt;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Yet there remains a cost for a higher level of abstraction, the &lt;code&gt;std::transform&lt;/code&gt; algorithm returning a &lt;code&gt;std::optional&lt;/code&gt; temporary to a conditional output iterator. In this case, the optimizer did not inline the call to &lt;code&gt;emplace_back()&lt;/code&gt; and the cost of that call appreciably slowed the resulting code. Even for this simple data type, the STL abstraction imposed a cost.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Passing std::string by-value noticeably slows the idioms</title>
   <link href="/2017/05/22/passing-stdstring-by-value-noticeably-slows-the-idioms/"/>
   <updated>2017-05-22T00:00:00-07:00</updated>
   <id>/2017/05/22/passing-stdstring-by-value-noticeably-slows-the-idioms</id>
   <content type="html">&lt;p&gt;The &lt;a href=&quot;/2017/05/19/benchmarking-the-transform-and-loop-idioms/&quot;&gt;benchmarks comparing &lt;code&gt;transform&lt;/code&gt; to a
loop&lt;/a&gt; also highlighted the substantial contribution that copying values made to their performance. Copying costs become especially noticeable for complex types, such as standard strings too long to fit in the short string optimization.&lt;/p&gt;

&lt;p&gt;In my original presentation of the &lt;code&gt;transform&lt;/code&gt; idiom, I slipped up and used a by-value parameter to the lambda expression rather than by-reference. For the actual benchmarks, I corrected that and specified a by-reference parameter.  How much of an effect would the original by-value parameter have had?&lt;/p&gt;

&lt;p&gt;I have rerun the benchmarks with that single change: The index of the &lt;code&gt;for&lt;/code&gt; loop is by-value and the parameter to the lambda is by-value. The &lt;code&gt;exclude&lt;/code&gt; value remained a global, evaluated once rather than every loop iteration.&lt;/p&gt;

&lt;p&gt;The resulting functions are (modified lines are highlighted):&lt;/p&gt;

&lt;h3&gt;&lt;code&gt;str_loop_emplace&lt;/code&gt;: Basic loop using &lt;code&gt;emplace_back()&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_loop_emplace&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;code&gt;str_loop_push&lt;/code&gt;: Basic loop using &lt;code&gt;push_back()&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_loop_push&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;code&gt;str_option_emp&lt;/code&gt;: &lt;code&gt;transform&lt;/code&gt; idiom using an output iterator calling &lt;code&gt;emplace_back()&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_option_emp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_emplacer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;code&gt;str_option&lt;/code&gt;: &lt;code&gt;transform&lt;/code&gt; idiom using an output iterator calling &lt;code&gt;push_back()&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_option&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h2&gt;Results&lt;/h2&gt;

&lt;p&gt;All other conditions of the benchmarks were the same as the &lt;a href=&quot;/2017/05/19/benchmarking-the-transform-and-loop-idioms/&quot;&gt;previous post&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Overview&lt;/h3&gt;

&lt;p&gt;First, a general comparison between the results for by-reference (“Ref”) and by-value (“Copy”):&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/05/overview_by_ref.png&quot; alt=&quot;overview_by_ref&quot; width=&quot;482&quot; height=&quot;681&quot; class=&quot;alignnone size-full wp-image-7600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The by-value construct essentially doubles the time for the complex, long string, increases it for optimized, short strings, and has little to no effect for &lt;code&gt;char const *&lt;/code&gt; strings.  Bear in mind that this change adds an extra copy for &lt;em&gt;every&lt;/em&gt; value, not just the ones that will be appended to the result vector.&lt;/p&gt;

&lt;h3&gt;Long strings&lt;/h3&gt;

&lt;p&gt;The left subplot below is the (by-reference) long string plot from the last post, rescaled to match the plot for the by-value version on the right:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/05/long_by_ref.png&quot; alt=&quot;long_by_ref&quot; width=&quot;621&quot; height=&quot;318&quot; class=&quot;alignnone size-full wp-image-7598&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The means have all been roughly doubled. Long strings are so complex that adding another copy dominates the time.&lt;/p&gt;

&lt;h3&gt;Short strings&lt;/h3&gt;

&lt;p&gt;Again, the left subplot below is the (by-reference) short string plot from the last post, rescaled to match the plot for the by-value version on the right:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/05/short_by_ref.png&quot; alt=&quot;short_by_ref&quot; width=&quot;620&quot; height=&quot;318&quot; class=&quot;alignnone size-full wp-image-7599&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For short strings, the means are mostly about 50% higher, though the mean for 0% copied is around three times higher. The extra copy has a proportionately higher effect on the 0% data set because its entire time is due to the loop processing time, which is increased by the extra copy.&lt;/p&gt;

&lt;h3&gt;Unique strings&lt;/h3&gt;

&lt;p&gt;Repeating the above structure for unique &lt;code&gt;char const *&lt;/code&gt; strings:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/05/unique_by_ref.png&quot; alt=&quot;unique_by_ref&quot; width=&quot;620&quot; height=&quot;318&quot; class=&quot;alignnone size-full wp-image-7597&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Unlike standard strings, strings uniquely identified by their pointer show no effect from an extra copy.  Indeed, for this type, by-reference is arguably slower than by-value, as the by-reference value requires an indirect load.  In the optimized code, however, the lambda function is inlined and the two cases produce identical object code for &lt;code&gt;char const *&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Passing complex types by reference is considerably faster than passing by value. The semantics require an extra copy for by-value passing; it will not be eliminated by inlining the function.&lt;/p&gt;

&lt;p&gt;This isn’t news.  It is &lt;a href=&quot;http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rf-in&quot;&gt;Recommendation F.16 of the C++ Core Guidelines&lt;/a&gt;. The contribution of this small post is merely to relate the cost of by-value to the relative costs of the idioms. For &lt;code&gt;std::string&lt;/code&gt; (as implemented by &lt;code&gt;libstdc++&lt;/code&gt; 6.2), on average you save twice as much by passing by-reference (a matter of adding a single &lt;code&gt;&amp;amp;&lt;/code&gt;) than by choosing the loop over the &lt;code&gt;transform&lt;/code&gt; idiom.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Benchmarking the transform and loop idioms</title>
   <link href="/2017/05/19/benchmarking-the-transform-and-loop-idioms/"/>
   <updated>2017-05-19T00:00:00-07:00</updated>
   <id>/2017/05/19/benchmarking-the-transform-and-loop-idioms</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;Update: Mon Aug 20, 2018:&lt;/strong&gt; Also see this &lt;a href=&quot;/2018/08/20/dont-let-your-babies-grow-up-to-be-microbenchmarkers/&quot;&gt;semi-rant about the limitations of microbenchmarkering&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The last posts compared the machine code generated by &lt;code&gt;transform&lt;/code&gt; and the equivalent idiom using an explicit &lt;code&gt;for&lt;/code&gt; loop and &lt;code&gt;if&lt;/code&gt; statement.  The &lt;code&gt;transform&lt;/code&gt; idiom generated more intermediate copies of the &lt;code&gt;std::string&lt;/code&gt; member than the loop.&lt;/p&gt;

&lt;p&gt;As I noted in the posts, code differences indicate the degree to which the optimizer was able to reduce the standard library abstractions to the essential underlying algorithm but only approximately predict differences in performance. The performance effects must ultimately be assessed by benchmarks.&lt;/p&gt;

&lt;p&gt;There are a wide range of methods and levels at which benchmarks might be used to compare these two idioms.  I will focus on microbenchmarking, timing short code sequences under several conditions of underlying data type and order.  This does not predict the effect of choosing these idioms in a full application, where their contribution will typically be small.  But it does provide insight into the effectiveness of the different machine code sequences that the optimizer generated for each idiom.&lt;/p&gt;

&lt;p&gt;I emphasize that the most important outcome of these benchmarks is the relative performance of the various constructs, not their absolute values.  Your performance will certainly vary. See the Caveats and Appendix sections for further discussion of the limits of these results.&lt;/p&gt;

&lt;h2&gt;Conditions&lt;/h2&gt;

&lt;p&gt;I ran initial tests exploring the effect of various factors on performance and settled on the following factors as most important:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Type of the elements: The samples that I presented in earlier posts used elements that were &lt;code&gt;std::pair&lt;/code&gt;, with the first part, the &lt;code&gt;std::string&lt;/code&gt;, used for the filter. The &lt;code&gt;libstdc++&lt;/code&gt; implementation of a &lt;code&gt;string&lt;/code&gt; is complex, offering different performance profiles for short strings (15 character or less) versus long strings and for operations that only use the string length versus those that require accessing the string body.&lt;/p&gt;

&lt;p&gt;The second member, the &lt;code&gt;int&lt;/code&gt;, generated simple code that had no performance impact.&lt;/p&gt;

To sample the performance range of string data, I ran microbenchmarks with three different string representations as the first member of the pair:

&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Short:&lt;/b&gt; &lt;code&gt;std::string&lt;/code&gt; values exactly 3 characters long. Strings of this length are stored in the string handle and can only be distinguished by  comparing the actual string bodies.
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Long:&lt;/b&gt; &lt;code&gt;std::string&lt;/code&gt; values exactly 26 characters long. Strings of this length are stored in heap-allocated storage and can only be distinguished by comparing the actual string bodies.
&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Unique:&lt;/b&gt; Null-terminated &lt;code&gt;char const *&lt;/code&gt; values that are uniquely identified by their address. Copies, moves, and comparisons of these values are all trivial, requiring only manipulation of eight-byte pointers.
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;
There are further possibilities, such as short &lt;code&gt;std::string&lt;/code&gt; values that can be distinguished simply by their differing lengths, as well as far more complicated types, but the above three represent an initial sample of three distinct performance profiles.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Using &lt;code&gt;vector::push_back()&lt;/code&gt; versus using &lt;code&gt;vector::emplace_back()&lt;/code&gt;: Both the loop and the &lt;code&gt;transform&lt;/code&gt; idiom can be written to push a previously-constructed temporary value onto the end of the &lt;code&gt;vector&lt;/code&gt; (&lt;code&gt;push_back()&lt;/code&gt;) or to construct a value directly in uninitialized storage at the &lt;code&gt;vector&lt;/code&gt;'s end (&lt;code&gt;emplace_back()&lt;/code&gt;). Typically, &lt;code&gt;emplace_back()&lt;/code&gt; is faster, as it does not generate a temporary value.&lt;/p&gt;
&lt;p&gt;
The sample idioms that I presented in previous posts differed in this.
The &lt;code&gt;transform&lt;/code&gt; idiom used &lt;code&gt;push_back()&lt;/code&gt;. I verified that &lt;code&gt;gcc&lt;/code&gt; 6.2 generated the same machine code when the idiom was written using &lt;code&gt;emplace_back()&lt;/code&gt;. By contrast, I presented the loop code using &lt;code&gt;emplace_back()&lt;/code&gt; and the code generated for that was simpler than when &lt;code&gt;push_back()&lt;/code&gt; was used. In this post, I microbenchmark both versions of both idioms.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Proportion of elements copied: The source vector contains pairs whose first member value is one of two string values of the given representation. One of those values is the one to be filtered out, while the other value is the one to be copied. The benchmarks were run with five different source data sets, with different fractions of values to be copied: 0%, 25%, 50%, 75%, and 100%.   The string comparison is performed for every element in the source vector, but only the copied proportion of the elements are appended to the result vector.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Order of the data elements: Both idioms are at heart a branch located inside a loop. For such algorithms, the order of the elements affects the branch prediction rate. For example, if 50% of the values are copied, then 50% of the branches will be taken and 50% will not. If the successful branches are all collected together at the start or end of the source vector, the hardware branch predictor will perfectly predict the branch (with a small number of failed predictions at the transition), whereas if the copied and not-copied elements are randomly mingled, the predictor will consistently fail.  The benchmarks were run with the five data sets presented in random order and in sorted order.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;

&lt;h2&gt;Method&lt;/h2&gt;

&lt;p&gt;I chose the &lt;a href=&quot;http://nonius.io&quot;&gt;Nonius C++ microbenchmarking framework&lt;/a&gt;, due to its strong statistical design.  The two idioms were placed in functions called by the framework. Each idiom was written in both &lt;code&gt;push_back()&lt;/code&gt; and &lt;code&gt;emplace_back()&lt;/code&gt; versions:&lt;/p&gt;

&lt;h3&gt;&lt;code&gt;str_loop_emplace&lt;/code&gt;: Basic loop using &lt;code&gt;emplace_back()&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_loop_emplace&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;code&gt;str_loop_push&lt;/code&gt;: Basic loop using &lt;code&gt;push_back()&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_loop_push&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;code&gt;str_option_emp&lt;/code&gt;: &lt;code&gt;transform&lt;/code&gt; idiom using an output iterator calling &lt;code&gt;emplace_back()&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_option_emp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_emplacer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;h3&gt;&lt;code&gt;str_option&lt;/code&gt;: &lt;code&gt;transform&lt;/code&gt; idiom using an output iterator calling &lt;code&gt;push_back()&lt;/code&gt;&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_option&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;There are two blemishes in the above code that I only noticed after gathering all the data. Neither of them substantively affects the benchmark results:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;The initial &lt;code&gt;assert()&lt;/code&gt; calls, checking that the result vector is empty, were a legacy of initial testing that the benchmarking code worked as expected. Left in the benchmark, they add a small amount of unnecessary computation. This will have no effect on the relative performance, as the same cost is paid for every benchmark and the dominant cost is the processing of the 50,000 vector elements. Nonetheless, in future runs, the &lt;code&gt;assert&lt;/code&gt; calls should be deleted.
&lt;/li&gt;
&lt;li&gt;The two &lt;code&gt;transform&lt;/code&gt; benchmark functions, &lt;code&gt;str_option&lt;/code&gt; and &lt;code&gt;str_option_emp&lt;/code&gt;, declare a result but do not return one.  Accepting such functions without warning is a &quot;feechure&quot; of gcc. The result actually returned from these function is gibberish (by chance, it is the square of the second member for the last copied element). The only purpose of the results of the benchmark functions is to force the optimizer to call the functions; the return value is never used. Reviewing the generated code, the function logic is generated and the function called, so the declared return value serves its purpose despite being gibberish and the performance results are unaffected. Nonetheless, in future runs, these two functions should have explicit &lt;code&gt;return&lt;/code&gt; statements.
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Reviewing the generated code, the two implementations of the &lt;code&gt;transform&lt;/code&gt; idiom produced identical code, both calling &lt;code&gt;emplace_back()&lt;/code&gt;.  This arose because the &lt;code&gt;libstdc++&lt;/code&gt; implementation of &lt;code&gt;push_back()&lt;/code&gt; includes an overload that simply maps to &lt;code&gt;emplace_back()&lt;/code&gt; and this overload was the one resolved for the &lt;code&gt;opt_back_insert_iterator()&lt;/code&gt; used as the output iterator for &lt;code&gt;str_option&lt;/code&gt;. In the benchmark results, the two &lt;code&gt;transform&lt;/code&gt; implementations performed identically.&lt;/p&gt;

&lt;p&gt;Refactoring the code into functions changed the generated code in small ways from the code discussed in the two prior posts: The &lt;code&gt;res&lt;/code&gt; vector is now a by-reference parameter rather than a local variable, while the &lt;code&gt;src&lt;/code&gt; vector and &lt;code&gt;exclude&lt;/code&gt; constant are now global rather than local.  The actual changes to the generated code are modest; the performance results for these functions should correlate well with the performance of the code described earlier.&lt;/p&gt;

&lt;p&gt;The source array always had 50,000 elements.  Each benchmark was run 10,000 times and their arithmetic mean is reported.  For every reported result, the size of the 95% confidence interval reported by Nonius was less than 3% of the mean.   Full details of the benchmark conditions are given in the Appendix.&lt;/p&gt;

&lt;h2&gt;Overview of results&lt;/h2&gt;

&lt;p&gt;I’ll start with an overview of the benchmark results:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/05/overview_plot.png&quot; alt=&quot;overview_plot&quot; width=&quot;577&quot; height=&quot;662&quot; class=&quot;alignnone size-full wp-image-7077&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each dot represents the mean of 10,000 samples.  The number of dots varies by condition because I ran the benchmark varying numbers of times, from one run for each condition with unique strings, to five runs for the sorted datasets of short strings.&lt;/p&gt;

&lt;p&gt;The largest effect is due to string type (comparing rows of plots): Using the short strings (middle row) as a reference point, long strings (top row) are roughly twice as slow and unique strings (bottom row) are twice as fast.&lt;/p&gt;

&lt;p&gt;The next largest effect is proportion of items actually copied (order of colours within each lane; see legend correlating colours to proportion). Within each string type, copying more values into the result vector requires more time. This is hardly surprising but it does emphasize the cost of moving data, even for simple data types such as short strings (32 bytes to copy in a 64-bit implementation) and &lt;code&gt;char const *&lt;/code&gt; (8 bytes to copy in a 64-bit implementation).&lt;/p&gt;

&lt;p&gt;Using &lt;code&gt;vector::emplace_back()&lt;/code&gt; versus &lt;code&gt;vector::push_back()&lt;/code&gt; had a substantial effect for the loop (leftmost lane is loop with &lt;code&gt;emplace_back()&lt;/code&gt;, second lane from left is loop with &lt;code&gt;push_back()&lt;/code&gt;) but as expected had no effect for &lt;code&gt;std::transform()&lt;/code&gt; (rightmost lane is &lt;code&gt;transform&lt;/code&gt; with &lt;code&gt;emplace_back()&lt;/code&gt;, second lane from right is &lt;code&gt;transform&lt;/code&gt; with &lt;code&gt;push_back()&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Finally, consider the question motivating this analysis:  How did the performance of &lt;code&gt;transform&lt;/code&gt; compare with that of the loop? I will take the &lt;code&gt;emplace_back()&lt;/code&gt; implementation as representative of the loop’s performance (it is trivially easy to use &lt;code&gt;emplace_back()&lt;/code&gt; in the loop, as well as widely-recommended—for example, see Item 42 of Scott Meyers’s &lt;a href=&quot;http://www.aristeia.com/books.html&quot;&gt;&lt;i&gt;Effective Modern C++&lt;/i&gt;&lt;/a&gt;). The choice is arbitrary for &lt;code&gt;transform&lt;/code&gt; given the two implementations’ equivalent performance and identical code, so I will take the &lt;code&gt;push_back()&lt;/code&gt; implementation.  These choices produce a comparison between the leftmost lane of the plots (the loop with &lt;code&gt;emplace_back()&lt;/code&gt;) and the second lane from the right (&lt;code&gt;transform&lt;/code&gt; with &lt;code&gt;push_back()&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;Within each subplot, the loop is faster than &lt;code&gt;transform&lt;/code&gt; for the cases where at least some elements are copied to the result vector. The two idioms offer equivalent performance for the case where no data elements were copied.&lt;/p&gt;

&lt;p&gt;Finally, I note some anomalies in the plots:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For the case of 75% copied of sorted data (upper right subplot), three of the implementations have a single run that was anomalously slow. I speculate that the conditions in my machine were substantively different during those runs---perhaps some background OS housekeeping process was running. The other two runs for this case also seem unexpectedly high, the only cases in all plots where algorithms ran more slowly on sorted data. I am not aware what the actual cause was and it does not seem to have arisen during the &lt;code&gt;str_loop_emplace&lt;/code&gt; benchmark, which was run first.
&lt;/li&gt;
&lt;li&gt;For the loop processing unsorted short strings and unique strings (the left lane of the two bottom left plots), the performance is not predicted by the proportion of copies. I will discuss this in detail below.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the rest of the post, I will focus on the &lt;code&gt;emplace_back()&lt;/code&gt; version of the loop and the &lt;code&gt;push_back()&lt;/code&gt; version of the idiom.&lt;/p&gt;

&lt;h2&gt;Comparison of long &lt;code&gt;std::string&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The results for long strings are the most straightforward to interpret:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/05/long_plot.png&quot; alt=&quot;long_plot&quot; width=&quot;495&quot; height=&quot;369&quot; class=&quot;alignnone size-full wp-image-7079&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The long strings are two 26-character strings, differing only in the last character. As such, they require a utility routine call to compare the string bodies, which are stored in the heap and likely cause cache misses. Move constructions and assignments remain cheap, because the heap pointer can simply be moved to the target, which accepts ownership of the heap object. By contrast, copy constructions and assignments are expensive, requiring a heap allocation for the copy of the string body, again incurring cache misses.&lt;/p&gt;

&lt;p&gt;Given the high cost of string operations, the dominant factor in performance is the number of items to copy, which predicts the order of results: More copies mean slower performance.&lt;/p&gt;

&lt;p&gt;We see a mild effect of branch misprediction in the case of 50% copied: The loop processes sorted input (second lane from left) about .25 ms faster than unsorted input (leftmost lane).  This effect is barely present for &lt;code&gt;transform&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The loop is faster than &lt;code&gt;transform&lt;/code&gt; directly proportional to the number of copies.  The two idioms are most different for 100% and 75% copies, while they are equivalent for 0%.  For long strings, the slower performance of &lt;code&gt;transform&lt;/code&gt; appears to be due to extra temporary values constructed when copying into the result vector.&lt;/p&gt;

&lt;p&gt;I consider the results for &lt;code&gt;transform&lt;/code&gt; on the 75% copied case (top of two right lanes) more tentative than the others, as they are anomalous in two ways. First, the three means for the sorted data are not clustered, with one 75% mean instead clustered with the two means for the 100% copied data.  Second, all three means for the &lt;code&gt;transform&lt;/code&gt; of sorted data are higher than the corresponding means for unsorted data.  This is the only instance of processing sorted data more slowly than unsorted and I cannot think of a reasonable explanation.  Due to these anomalies, I accord these data points less confidence than the others.&lt;/p&gt;

&lt;h2&gt;Comparison of short &lt;code&gt;std::string&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The results for short strings are more complex:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/05/short_plot.png&quot; alt=&quot;short_plot&quot; width=&quot;495&quot; height=&quot;369&quot; class=&quot;alignnone size-full wp-image-7078&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The short strings are both 3 characters long, differing in their final character.  All operations can be performed by access to the string handle (&lt;code&gt;libstdc++&lt;/code&gt; stores string bodies of less than 16 characters in the handle rather than the heap), avoiding heap accesses and highly reducing the likelihood of cache misses. As noted in the overview, the improvement is clear: Short strings are about twice as fast as long strings.&lt;/p&gt;

&lt;p&gt;The reduced effect of string copying allows other effects to appear, particularly the effect of branch misprediction. As the misprediction effect is most noticeable for the loop, I will begin with the more straightforward &lt;code&gt;transform&lt;/code&gt; results (the two right lanes).&lt;/p&gt;

&lt;p&gt;The dominant factor in performance of &lt;code&gt;transform&lt;/code&gt; on short strings is the percent of values copied to the result. On sorted data, the means are directly proportional to this percentage. For unsorted data, branch misprediction effects appear.  For the 100% and 0% copied cases, branch prediction should be perfect irrespective of data order, as the branch will succeed or fail for every element. This is confirmed by the means for these cases, which are the same for unsorted and sorted data sets.&lt;/p&gt;

&lt;p&gt;However, for the 50% copied case, branch prediction will nearly always be wrong for unsorted data but essentially perfect for sorted data, only mispredicting at the transition from excluded to included values.  The means for 50% copies show a substantial improvement for sorted data.&lt;/p&gt;

&lt;p&gt;For the data sets that have 75% and 25% of their values copied, there will be two contending effects.  For both cases, branch prediction will be modestly effective even for unsorted data, as occasional runs of inclusion or exclusion in the data will support successful prediction. However, the 25% data set requires substantially fewer copies than the 75% data set, making it faster.  These effects are apparent in the means: &lt;code&gt;transform&lt;/code&gt; is substantially faster on sorted data than unsorted for the 25% case, where branch misprediction is a large contributor, but the idiom is only slightly faster for sorted data in the 75% case, where the cost of copying values dominates.&lt;/p&gt;

&lt;p&gt;Branch misprediction has a much larger effect on the loop (two left lanes).  When this idiom processes unsorted data (leftmost lane), the proportion of values copied no longer predicts the relative performance of the data sets. The two fastest unsorted data sets are those for which branch prediction is perfect, with 0% and 100% copied. All datasets for which branch prediction is imperfect, the 25%, 50%, and 75%, are slower. Indeed, the 50% and 75% cases have almost the same performance, due to near-total branch misprediction (in the 50% case) having almost as much effect as half again more string copies (in the 75% case).&lt;/p&gt;

&lt;p&gt;When the loop runs on sorted data (second lane from left), branch prediction is perfect, leaving only the proportion of copies as a factor.  The more copies required, the slower the processing.&lt;/p&gt;

&lt;p&gt;Finally, comparing the results for the two idioms, &lt;code&gt;transform&lt;/code&gt; is 25–50% slower than the loop, with the gap proportional to the number of values copied.  For 0% copied, the two idioms are equivalent.&lt;/p&gt;

&lt;h2&gt;Comparison of unique &lt;code&gt;char const *&lt;/code&gt; strings&lt;/h2&gt;

&lt;p&gt;The unique &lt;code&gt;char const *&lt;/code&gt; strings are trivially fast to copy or compare, requiring only manipulation of 8-byte pointers. Consequently, the influence of dataset order is even stronger for these strings:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://ted376.files.wordpress.com/2017/05/unique_plot.png&quot; alt=&quot;unique_plot&quot; width=&quot;501&quot; height=&quot;369&quot; class=&quot;alignnone size-full wp-image-7080&quot; /&gt;&lt;/p&gt;

&lt;p&gt;For both idioms, order once again has no effect on performance for datasets where 0% or 100% of the elements are copied, due to perfect branch prediction.  For &lt;code&gt;transform&lt;/code&gt; (right two lanes), the 50% copied case suffered the greatest loss due to branch misprediction, with the unsorted data about a third slower than the sorted data. Misprediction had no discernible effect on the 75% copied data and only a slight effect on the 25% copied data.  For &lt;code&gt;transform&lt;/code&gt;, the relative ordering of the means was always determined by the proportion of copies.&lt;/p&gt;

&lt;p&gt;For the loop, branch misprediction had a larger effect (left two lanes). As with the short string case, the order of the results for the unsorted data (leftmost lane) corresponded to the number of correctly-predicted branches, not the number of copies. The datasets with perfect prediction (0% and 100% copied) were fastest, while the unpredictable dataset (50% copied) was slowest, with the partially-predictable datasets (25% and 75%) in between. Within each level of branch predictability, the number of copies determined the relative ranking.&lt;/p&gt;

&lt;p&gt;For the sorted case, the loop performance was directly proportional to the number of copies made, as branch prediction was near-perfect for every dataset.&lt;/p&gt;

&lt;p&gt;Comparing the two idioms, &lt;code&gt;transform&lt;/code&gt; was surprisingly slow, from 2.5 times to the same rate. Once again, the number of extraneous temporaries made by &lt;code&gt;transform&lt;/code&gt; seems to be the source of the difference, as the two algorithms take identical times for datasets where no elements are copied.&lt;/p&gt;

&lt;h2&gt;Caveats&lt;/h2&gt;

&lt;p&gt;These results reflect a small number of samples (only a single sample in the case of the unique strings) on a single OS/machine configuration (see Appendix for details).  For the cases where I have multiple samples, they seem reliable, with the lone exception of the sorted data set of long strings with 75% copies for &lt;code&gt;transform&lt;/code&gt;. My confidence is increased by the consistency between these results, my analysis of the machine code, and well-understood theories of performance on modern processors.  Nonetheless, the numbers are more suggestive than definitive. I would like to run more tests in future but I have put enough time into this analysis already and want to post it.  These results at least tell a consistent, believable story.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Is the &lt;code&gt;transform&lt;/code&gt; idiom a useful alternative to the loop?  I confess that the analysis of the code and benchmarks is making me question the &lt;code&gt;transform&lt;/code&gt; idiom’s utility.  The loop idiom is immediately understandable to anyone who’s programmed in any language, robust, and has a more direct expression of the underlying algorithm that permits the compiler to generate code without extraneous temporaries.  More familiar &lt;em&gt;and&lt;/em&gt; faster: a hard pair to beat.&lt;/p&gt;

&lt;p&gt;The only advantages of the &lt;code&gt;transform&lt;/code&gt; idiom, such as they may be, include increased familiarity with the standard algorithm family.  I still believe that there are many cases where a standard algorithm is preferable to a hand-crafted alternative.  I don’t want to write my own sort or even my own unique-values algorithm, thank you.  But the filter-and-transform embodied by the basic Python list comprehension maps cleanly to a range &lt;code&gt;for&lt;/code&gt; loop and &lt;code&gt;if&lt;/code&gt; statement.  Introducing a &lt;code&gt;std::optional&lt;/code&gt; value and an optional-aware output iterator just to use &lt;code&gt;transform&lt;/code&gt; now seems too clever by half. In my own code, I expect I’ll stick with a &lt;code&gt;for&lt;/code&gt; loop in this case.&lt;/p&gt;

&lt;p&gt;In future posts, I’ll extend this analysis to a few more cases but my focus will likely shift to the impact of temporary values on execution speed.  The biggest lesson of these benchmarks is how much impact extraneous temporaries have.&lt;/p&gt;

&lt;h2&gt;Appendix: Detailed method description&lt;/h2&gt;

&lt;p&gt;This appendix presents the technical specifics of the benchmarks.&lt;/p&gt;

&lt;h3&gt;Nonius calls&lt;/h3&gt;

&lt;p&gt;The code for running the &lt;code&gt;str_loop_emplace&lt;/code&gt; benchmark:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// NOT USED IN BENCHMARKS
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;check&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;cp&quot;&gt;#if PRINT_SIZE
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cerr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;LEFT &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LEFT&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; res.size() &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;cp&quot;&gt;#endif
&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cerr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;res.size() &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, included &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cerr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;endl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#ifdef DO_LOOP_EMPLACE
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;size_t&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_loop_emplace&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BY&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;NONIUS_BENCHMARK&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;str_loop_emplace&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nonius&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chronometer&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;meter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;meter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;runs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;meter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;measure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;str_loop_emplace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;check&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#endif
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The code for the other three benchmarks was the same, substituting the appropriate function from the beginning of this post for &lt;code&gt;str_loop_emplace&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Vector &lt;code&gt;src&lt;/code&gt; was loaded before any benchmarks were run and re-used for every benchmark. The code is given below.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;NONIUS_BENCHMARK&lt;/code&gt; function may execute a given benchmark several times if the measured clock resolution is insufficiently accurate to measure just one execution.  The number of runs is available via &lt;code&gt;meter.runs()&lt;/code&gt;.  To ensure the executions are independent, a separate result vector is created for each, represented as vector &lt;code&gt;res&lt;/code&gt;, local to the function that ran the benchmark. Each benchmark was passed its own &lt;code&gt;res[i]&lt;/code&gt; to receive the result.&lt;/p&gt;

&lt;p&gt;The global &lt;code&gt;res&lt;/code&gt; vector declared in Line 6 is a remnant of earlier versions and was not used in these benchmarks. The local &lt;code&gt;res&lt;/code&gt; vector of vectors defined in Line 36 was used instead.&lt;/p&gt;

&lt;p&gt;Several preprocessing macros determined the final code:&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;&lt;code&gt;PRINT_SIZE&lt;/code&gt;&lt;/dt&gt;&lt;dd&gt;&lt;code&gt;1&lt;/code&gt; when testing the benchmark code. &lt;code&gt;0&lt;/code&gt; for actual benchmarks.&lt;/dd&gt;
&lt;dt&gt;&lt;code&gt;BY&lt;/code&gt;&lt;/dt&gt;&lt;dd&gt;Set to &lt;code&gt;&amp;amp;&lt;/code&gt; for actual benchmarks.  The functions given in the main post present the code after this macro had been expanded to an ampersand. In future, will be set to empty to test performance impact of pass-by-value.&lt;/dd&gt;
&lt;dt&gt;&lt;code&gt;DO_LOOP_EMPLACE&lt;/code&gt;&lt;/dt&gt;&lt;dd&gt;Set to &lt;code&gt;1&lt;/code&gt; when running actual benchmarks. In testing, can be set to &lt;code&gt;0&lt;/code&gt; to not compile a benchmark.&lt;/dd&gt;
&lt;dt&gt;&lt;code&gt;NONIUS_BENCHMARK&lt;/code&gt;&lt;/dt&gt;&lt;dd&gt;Standard macro for defining a Nonius benchmark harness.&lt;/dd&gt;
&lt;/dl&gt;

&lt;h3&gt;Initialization of &lt;code&gt;src&lt;/code&gt; vector&lt;/h3&gt;

&lt;p&gt;The source vector was initialized and Nonius called by the following code:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;British Columbia&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Alberta&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Saskatchewan&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Manitoba&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Ontario&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Quebec&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Newfoundland and Labrador&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;New Brunswick&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Prince Edward Island&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Nova Scotia&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Yukon&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Northwest Territories&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Nunuvat&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;long_regs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Newfoundland and Labrador0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;Newfoundland and Labrador1&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;short_regs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;NL0&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
  &lt;span class=&quot;s&quot;&gt;&quot;NL1&quot;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proportion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proportion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;      
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SeedType&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rbits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_unique&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RBits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// Range of random #s includes both bounds: [0, 99]
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;MRandInt&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rbits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;99&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  
&lt;span class=&quot;cp&quot;&gt;#if LEFT == 1
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;regions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#elif LEFT == 2 || LEFT == 6 || LEFT == 7 || LEFT == 10 || LEFT == 11 
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;long_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#elif LEFT == 3 || LEFT == 4 || LEFT == 5 || LEFT == 8 || LEFT == 9
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;exclude&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;short_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#else
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;static_assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Missing case in init &quot;&lt;/span&gt; &lt;span class=&quot;err&quot;&gt;##&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LEFT&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#endif
&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#if LEFT == 1
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;regions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 2
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;long_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 3
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;short_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 4
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;short_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 5
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;short_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 6
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;long_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 7
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;long_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 8
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;short_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 9
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;short_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 10
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;long_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#elif LEFT == 11
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;set_copied&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;75&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;long_regs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;included&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#else
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;static_assert&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;false&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;src proportions undefined&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;cp&quot;&gt;#endif
&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;cp&quot;&gt;#if SORTED == 1
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;cp&quot;&gt;#elif SORTED == 2
&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rbits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;cp&quot;&gt;#endif
&lt;/span&gt;  &lt;span class=&quot;cm&quot;&gt;/* 
  // Following just for ensuring correctness
  for (const auto&amp;amp; p : src)
    std::cerr &amp;lt;&amp;lt; '(' &amp;lt;&amp;lt; p.first &amp;lt;&amp;lt; &quot;, &quot; &amp;lt;&amp;lt; p.second &amp;lt;&amp;lt; &quot;)\n&quot;;
  std::cerr &amp;lt;&amp;lt; std::endl;
  */&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;MRandInt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getSeed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nonius&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;main&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;argc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;argv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The following macros determined the compiled code:&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;&lt;code&gt;LEFT&lt;/code&gt;&lt;/dt&gt;&lt;dd&gt;Selected the combination of string type and proportion of copies for a given run. Ranged from 1 to 11.&lt;/dd&gt;
&lt;dt&gt;&lt;code&gt;SIZE&lt;/code&gt;&lt;/dt&gt;&lt;dd&gt;Number of entries in &lt;code&gt;src&lt;/code&gt; vector. Set to 50,000 for all benchmarks.&lt;/dd&gt;
&lt;dt&gt;&lt;code&gt;SORTED&lt;/code&gt;&lt;/dt&gt;&lt;dd&gt;Defined whether the &lt;code&gt;src&lt;/code&gt; vector was in random order (&lt;code&gt;SORTED==0&lt;/code&gt;), sorted (&lt;code&gt;SORTED==1&lt;/code&gt;), or shuffled (&lt;code&gt;SORTED==2&lt;/code&gt;).  Both the random and sorted cases were used in benchmarks; the shuffled case was not used.&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Class &lt;code&gt;MRandInt&lt;/code&gt; generates random integers over a specified inclusive range.  For these benchmarks, it generated values between 0 and 99 (inclusive), which were used to randomly select whether the included or excluded value.  A different random seed was used for every run. The proportions of values copied consequently changed from run to run but all were close to the target.&lt;/p&gt;

&lt;p&gt;I made a slight variation of the main Nonius function to allow me to call &lt;code&gt;init&lt;/code&gt; before calling &lt;code&gt;nonius::main&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;Run conditions&lt;/h3&gt;

&lt;p&gt;All benchmarks were run on a guest Ubuntu 16.04 system, running under VirtualBox 5.0.20r106931, on a host Mac OS 10.12.4.  The hardware was a MacBook Pro with a 2.4 GHz Intel Core i5 and 8 GB memory.&lt;/p&gt;

&lt;p&gt;No other user-facing applications were running on either the guest or host system (though both had ample numbers of background daemons running) and the host machine had its network turned off.&lt;/p&gt;

&lt;p&gt;Each run specified a Nonius sample size of 10,000 and the default bootstrap resample size of 100,000.&lt;/p&gt;

&lt;p&gt;For every benchmark, the 95% confidence interval returned by the bootstrap was less than or equal to 3% of the sample mean.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Analysis of code generated from the transform idiom</title>
   <link href="/2017/05/03/analysis-of-code-generated-from-the-transform-idiom/"/>
   <updated>2017-05-03T00:00:00-07:00</updated>
   <id>/2017/05/03/analysis-of-code-generated-from-the-transform-idiom</id>
   <content type="html">&lt;p&gt;The last post presented the baseline C++ code and its generated machine code. Now it’s time to compare the code generated by the &lt;code class=&quot;highlighter-rouge&quot;&gt;std::transform&lt;/code&gt; idiom and see how well it fares.&lt;/p&gt;

&lt;h2&gt;Removing two inefficiencies&lt;/h2&gt;

&lt;p&gt;I’m going to analyze a slightly improved version of the &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt; idiom. When I examined the code generated by the &lt;a href=&quot;/2017/03/26/a-single-stl-statement-equivalent-to-the-basic-python-list-comprehension/&quot;&gt;version I presented originally&lt;/a&gt;, I saw two simple inefficiencies I’d left in, two rookie errors:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The lambda parameter `p` is passed by copy rather than by reference, constructing a new string, including a heap allocation, for every invocation.
&lt;/li&gt;
&lt;li&gt;The `string(&quot;us&quot;)` expression inside the lambda filter inserted a conversion from `char const *` to `std::string` for every invocation, just to create a constant string.
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I improved the code by eliminating these conversions from the loop. I eliminated the first by simply passing the lambda parameter by-reference.&lt;/p&gt;

&lt;p&gt;I could not eliminate the second conversion altogether, so I moved it outside the &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt; call, declaring &lt;code class=&quot;highlighter-rouge&quot;&gt;const string us&lt;/code&gt; and then capturing it by-copy in the lambda call.&lt;/p&gt;

&lt;p&gt;Here is the revised code with the revised lines highlighted:&lt;/p&gt;

&lt;!-- highlight=&quot;5,8,9&quot;--&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;us&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;us&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The copy-capture of &lt;code class=&quot;highlighter-rouge&quot;&gt;us&lt;/code&gt; in the lambda expression only generates a single copy-constructor call. The above code compiles to something like:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda_type&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_us&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lambda_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;us&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_us&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;us&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;operator&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l_us&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;...&lt;/span&gt;  &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;lambda_type&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;us&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(...,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The member variable &lt;code class=&quot;highlighter-rouge&quot;&gt;l_us&lt;/code&gt; is constructed once, &lt;em&gt;before&lt;/em&gt; the call to &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt;, then its destructor is called immediately following.  The calls to &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda_type::operator(ppair&amp;amp; p)&lt;/code&gt; inside &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt; are efficient references to a local variable, internally represented as offsets &lt;code class=&quot;highlighter-rouge&quot;&gt;0x80–0x9f&lt;/code&gt; from the stack pointer &lt;code class=&quot;highlighter-rouge&quot;&gt;%rsp&lt;/code&gt; in the machine code. The extra &lt;code class=&quot;highlighter-rouge&quot;&gt;l_us&lt;/code&gt; variable does increase the stack requirements by 32 bytes, though.&lt;/p&gt;

&lt;h2&gt;Machine code generated by the more efficient version&lt;/h2&gt;

&lt;p&gt;With those changes made, the &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt; call is compiled to the following machine code (again, gcc 6.2 with &lt;code class=&quot;highlighter-rouge&quot;&gt;libstdc++&lt;/code&gt;, compiled with &lt;code class=&quot;highlighter-rouge&quot;&gt;-O2&lt;/code&gt;, as disassembled by gdb).  It’s a bit of a slog, so just glance at it and I’ll see you on the other side:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// LOOP
// 941 - 600 = 341 bytes (6-7 instruction cache lines)
//         PLUS 69 bytes in outside branch targets (2 instruction cache lines)
//           = 410 bytes (8-9 instruction cache lines)

// Register usage
// %rax == res_i (for most of the loop body, lines +721 to end)
// %rbx == src_i
// %r12 == &amp;amp; RT.province.zstring
// %r13 == src.end()
// %r14 == &amp;amp; RT
// %r15 == &amp;amp; T1.province.zstring

// Local variables
// Range for local variables used in loop: 0x100 = 256 bytes = 4-5 data cache
//                                                             lines
// (includes 0x18+0x8+0x28 = 0x48 = 52 bytes = 1-2 extra cache lines for
//                                                 padding and locals unused
//                                                 in the loop)
// Local variable offsets (hexadecimal) from %rsp:
//  0 TEMP0 (saves %rcx across call to memcmp)
//(18 bytes of padding and other locals)
// 20 src
//   20 begin()
//   28 end()
//   30 cap_end() Pointer to byte following the reserved capacity
//( 8 bytes of padding)
// 40 res
//   40 begin()
//   48 end()
//   50 cap_end() Pointer to byte following the reserved capacity
//(28 bytes of padding and other locals)
// 80 l_us lambda capture by copy (copy-constructed once, before loop body,
//                                 destructor called after loop body)
//   80 str_buff Pointer to string value (null-terminated)
//   88 string length (not counting null)
//   90 Union
//      zstring 16-byte buffer for null-terminated strings of length &amp;lt; 16
//      capacity 8-byte size of heap buffer for strings of length &amp;gt;= 16
// a0 T1 Rvalue ppair constructed in lambda via aggregate initialization
//   a0 province
//     a0 str_buff Pointer to string value (null-terminated)
//     a8 string length (not counting null)
//     b0 Union
//      zstring 16-byte buffer for null-terminated strings of length &amp;lt; 16
//      capacity 8-byte size of heap buffer for strings of length &amp;gt;= 16
//   c0 value
// d0 RT move-constructed parameter (type oppair) t of
//      opt_back_emplace_iterator::operator=(T&amp;amp;&amp;amp; t)
//   d0 province
//     d0 str_buff Pointer to string value (null-terminated)
//     d8 string length (not counting null)
//     e0 Union
//      zstring 16-byte buffer for null-terminated strings of length &amp;lt; 16
//      capacity 8-byte size of heap buffer for strings of length &amp;gt;= 16
//   f0 value
//   f8 has_value

// Heap references (arrays for src and res, strings longer than 15 chars)
// src and res: Single pass in monotonically-increasing order (data prefetching
//   should work)
// strings: single memcpy call for every string &amp;gt; 15 chars (most likely two
//   distinct heap locations = 2 data cache lines)
//          When us.len &amp;gt; 15:
//            single memcmp call for every string of same length as us
//            (most likely two distinct heap locations = 2 data cache lines)

// Body: Build optional&amp;lt;pair&amp;lt;string,int&amp;gt;&amp;gt; and append to res (value is ensured)
// T1 = (src_i-&amp;gt;province, src_i-&amp;gt;value ^ 2)
&amp;lt;+600&amp;gt;:	mov    0x20(%rbx),%ebp           %ebp &amp;lt;- src_i-&amp;gt;value
&amp;lt;+603&amp;gt;:	mov    %r15,0xa0(%rsp)           T1.province.addr &amp;lt;- &amp;amp;T1.province.zstring
&amp;lt;+611&amp;gt;:	lea    0xa0(%rsp),%rdi           %rdi &amp;lt;- &amp;amp;T1.province
&amp;lt;+619&amp;gt;:	mov    (%rbx),%rsi               %rsi &amp;lt;- &amp;amp;src_i-&amp;gt;province.zstring
&amp;lt;+622&amp;gt;:	imul   %ebp,%ebp                 %ebp &amp;lt;- src_i-&amp;gt;value ^ 2
&amp;lt;+625&amp;gt;:	lea    (%rsi,%rcx,1),%rdx        %rdx &amp;lt;- &amp;amp;src_i-&amp;gt;province.zstring[len+1]
&amp;lt;+629&amp;gt;:	callq  0x401550 std::string::_M_construct&amp;lt;char*&amp;gt;(char*, char*, std::forward_iterator_tag) HEAP STRING REFERENCE (for string &amp;gt; 15 chars)
&amp;lt;+634&amp;gt;:	mov    0xa0(%rsp),%rax           %rax &amp;lt;- &amp;amp; T1.province.zstring
&amp;lt;+642&amp;gt;:	mov    %ebp,0xc0(%rsp)           T1.value &amp;lt;- src_i-&amp;gt;value ^ 2
// RT = (T1.province, src_i-&amp;gt;value ^ 2, true)
&amp;lt;+649&amp;gt;:	mov    %r12,0xd0(%rsp)           RT.province.str_buff &amp;lt;- &amp;amp; RT.province.zstring
&amp;lt;+657&amp;gt;:	cmp    %r15,%rax                 Was T1.str_buff changed?
&amp;lt;+660&amp;gt;:	je     0x401238 &amp;lt;main()+1256&amp;gt;    Jump if no change (taken when string is of length &amp;lt; 16)
/*
  Direct move of T1.province.str_buff to
  RT.province.str_buff. T1.province has no destructor called. RT is
  directly initialized and T1 &quot;never really existed&quot; This approach
  allows RT.province to be initialized without any heap accesses
 */
&amp;lt;+666&amp;gt;:	mov    %rax,0xd0(%rsp)           RT.province.str_buff &amp;lt;- T1.province.str_buff
&amp;lt;+674&amp;gt;:	mov    0xb0(%rsp),%rax
&amp;lt;+682&amp;gt;:	mov    %rax,0xe0(%rsp)           RT.province.capacity &amp;lt;- T1.province.capacity
&amp;lt;+690&amp;gt;:	mov    0xa8(%rsp),%rax           %rax &amp;lt;- T1.province.len
&amp;lt;+698&amp;gt;:	mov    %ebp,0xf0(%rsp)           RT.value &amp;lt;- src_i-&amp;gt;value ^ 2
&amp;lt;+705&amp;gt;:	movb   $0x1,0xf8(%rsp)           RT.optional &amp;lt;- true
&amp;lt;+713&amp;gt;:	mov    %rax,0xd8(%rsp)           RT.province.len &amp;lt;- T1.province.len
// *res_i = (RT.province, RT.value)
// For rest of loop body, %rax == res_i
&amp;lt;+721&amp;gt;:	mov    0x48(%rsp),%rax           %rax &amp;lt;- res.end()
&amp;lt;+726&amp;gt;:	cmp    0x50(%rsp),%rax           res.cap_end() ==? &amp;amp;res.end()
&amp;lt;+731&amp;gt;:	je     0x401295 &amp;lt;main()+1349&amp;gt;    Jump if equal; extend res (never taken, sufficient space reserved)
&amp;lt;+737&amp;gt;:	test   %rax,%rax                 
&amp;lt;+740&amp;gt;:	je     0x40108f &amp;lt;main()+831&amp;gt;     Jump if res.end() == nullptr (never taken, space has already been reserved)
&amp;lt;+742&amp;gt;:	lea    0x10(%rax),%rdx           %rdx &amp;lt;- &amp;amp;res.end().zstring
&amp;lt;+746&amp;gt;:	mov    %rdx,(%rax)               res.end()-&amp;gt;str_buff &amp;lt;- &amp;amp;res.end().zstring

&amp;lt;+749&amp;gt;:	mov    0xd0(%rsp),%rdx           %rdx &amp;lt;- RT.province.str_buff
&amp;lt;+757&amp;gt;:	cmp    %r12,%rdx                 Is RT buffer local?
&amp;lt;+760&amp;gt;:	je     0x401260 &amp;lt;main()+1296&amp;gt;    if == ... (string length &amp;lt; 16---Move the 16 bytes from RT.province.zstring
                                         to res_i-&amp;gt;province.zstring
                                         else move-assign the heap buffer res_i-&amp;gt;province &amp;lt;- RT
/* 
   Unlike RT &amp;lt;- T1 assignment above, res_i-&amp;gt;province &amp;lt;- RT.province is
   an actual move assignment.  RT.str_buff is copied to
   res_i-&amp;gt;province.str_buff (transferring ownership of the heap
   object) and later (see below) RT.province will be reset to an empty
   string and still later have its destructor called.  The destructor
   will not reference the heap because RT.province is a null string.
*/
  &amp;lt;+766&amp;gt;:	mov    %rdx,(%rax)               res_i-&amp;gt;province.str_buff &amp;lt;- RT.province.str_buff
  &amp;lt;+769&amp;gt;:	mov    0xe0(%rsp),%rdx           
  &amp;lt;+777&amp;gt;:	mov    %rdx,0x10(%rax)           res_i-&amp;gt;province.capacity &amp;lt;- RT.province.capacity
                                           // endif
&amp;lt;+781&amp;gt;:	mov    0xd8(%rsp),%rdx
&amp;lt;+789&amp;gt;:	mov    %rdx,0x8(%rax)            res.end()-&amp;gt;province.len &amp;lt;- RT.province.len
&amp;lt;+793&amp;gt;:	mov    0xf0(%rsp),%edx           %edx &amp;lt;- RT.value
// RT.province &amp;lt;- &quot;&quot; due to move assignment to res.end()-&amp;gt;province
&amp;lt;+800&amp;gt;:	mov    %r12,0xd0(%rsp)           RT.province.str_addr &amp;lt;- &amp;amp; RT.province.zstring
&amp;lt;+808&amp;gt;:	movq   $0x0,0xd8(%rsp)           RT.province.strlen &amp;lt;- 0
&amp;lt;+820&amp;gt;:	movb   $0x0,0xe0(%rsp)           RT.province.zstring &amp;lt;- '\000'
&amp;lt;+828&amp;gt;:	mov    %edx,0x20(%rax)           res_i-&amp;gt;value &amp;lt;- RT.value
// res_i++
&amp;lt;+831&amp;gt;:	addq   $0x28,0x48(%rsp)          res_i++
&amp;lt;+837&amp;gt;:	cmpb   $0x0,0xf8(%rsp)           (! RT.has_value())?  VESTIGIAL---never true
&amp;lt;+845&amp;gt;:	je     0x4010b1 &amp;lt;main()+865&amp;gt;     Branch if no value---never taken
// RT.province.~string()
&amp;lt;+847&amp;gt;:	mov    0xd0(%rsp),%rdi           %rdi &amp;lt;- RT.province.str_addr
&amp;lt;+855&amp;gt;:	cmp    %r12,%rdi                 &amp;amp;RT.province.zstring ==? RT.province.str_buff (always true due to move assignment)
&amp;lt;+858&amp;gt;:	je     0x4010b1 &amp;lt;main()+865&amp;gt;     Always taken (due to move assignment)
 &amp;lt;+860&amp;gt;:	callq  0x400c00 &amp;lt;_ZdlPv@plt&amp;gt; operator delete()@plt Delete non-local string buffer for RT.province (never necessary)

// Increment counter and check for loop completion
// %rbx      == src_i
// %r13      == src.end()

// Increment and check src_i
&amp;lt;+865&amp;gt;:	add    $0x28,%rbx                src_i++
&amp;lt;+869&amp;gt;:	cmp    %rbx,%r13                 src_i ==? src.end()
&amp;lt;+872&amp;gt;:	je     0x401100 &amp;lt;main()+944&amp;gt;     Cleanup: l_us.~string()

// Process *src_i: Check src_i-&amp;gt;province ==? l_us
&amp;lt;+874&amp;gt;:	mov    0x8(%rbx),%rcx            %rcx &amp;lt;- src_i-&amp;gt;province.len()
&amp;lt;+878&amp;gt;:	cmp    0x88(%rsp),%rcx           l_us.len() ==? src_i-&amp;gt;province.len()
&amp;lt;+886&amp;gt;:	jne    0x400fa8 &amp;lt;main()+600&amp;gt;     =&amp;gt; Not equal: Build result
&amp;lt;+892&amp;gt;:	test   %rcx,%rcx                 src_i-&amp;gt;province ==? &quot;&quot; (and also l_us, because equal lengths)
&amp;lt;+895&amp;gt;:	je     0x4010b1 &amp;lt;main()+865&amp;gt;     =&amp;gt; Equal null: Move to next (never taken)
&amp;lt;+897&amp;gt;:	mov    0x80(%rsp),%rsi           %rsi &amp;lt;- &amp;amp;l_us.zstring
&amp;lt;+905&amp;gt;:	mov    (%rbx),%rdi               %rdi &amp;lt;- &amp;amp;src_i-&amp;gt;province.zstring
&amp;lt;+908&amp;gt;:	mov    %rcx,%rdx                 %rdx &amp;lt;- src_i-&amp;gt;province.len()
&amp;lt;+911&amp;gt;:	mov    %rcx,(%rsp)               TEMP0 &amp;lt;- %rcx
&amp;lt;+915&amp;gt;:	callq  0x400cd0 &amp;lt;memcmp@plt&amp;gt;     Compare string contents HEAP STRING REFERENCE (for string &amp;gt; 15 chars)
&amp;lt;+920&amp;gt;:	test   %eax,%eax                 (%eax != 0 =&amp;gt; not equal)
&amp;lt;+922&amp;gt;:	mov    (%rsp),%rcx               %rcx &amp;lt;- TEMP0
&amp;lt;+926&amp;gt;:	jne    0x400fa8 &amp;lt;main()+600&amp;gt;     Not equal: Build result

// src_i-&amp;gt;province == l_us: increment and check src_i, loop to process new value
&amp;lt;+932&amp;gt;:	add    $0x28,%rbx                src_i++
&amp;lt;+936&amp;gt;:	cmp    %rbx,%r13                 src_i ==? src.end()
&amp;lt;+939&amp;gt;:	jne    0x4010ba &amp;lt;main()+874&amp;gt;     Not equal =&amp;gt; Go to next
[/code]

The above is the main loop body.  We're not done though, as there are these two external branch targets 317 bytes later:

[code gutter=&quot;false&quot;]
// RT.province.zstring &amp;lt;- T1.province.zstring (Short string optimization)
&amp;lt;+1256&amp;gt;:	mov    0xb0(%rsp),%rax           %rax &amp;lt;- zstring[0:7]
&amp;lt;+1264&amp;gt;:	mov    0xb8(%rsp),%rdx           %rdx &amp;lt;- zstring[8:15]
&amp;lt;+1272&amp;gt;:	mov    %rax,0xe0(%rsp)           RT.province.zstring &amp;lt;- (%rax, %rdx)
&amp;lt;+1280&amp;gt;:	mov    %rdx,0xe8(%rsp)
&amp;lt;+1288&amp;gt;:	jmpq   0x401002 &amp;lt;main()+690&amp;gt;

// Align next branch target
&amp;lt;+1293&amp;gt;:	nopl   (%rax)

// res_i-&amp;gt;province.zstring &amp;lt;- RT.province.zstring (Short string optimization)
&amp;lt;+1296&amp;gt;:	mov    0xe0(%rsp),%rsi           %rsi &amp;lt;- zstring[0:7]
&amp;lt;+1304&amp;gt;:	mov    0xe8(%rsp),%rdi           %rdi &amp;lt;- zstring[8:15]
&amp;lt;+1312&amp;gt;:	mov    %rsi,0x10(%rax)           res_i-&amp;gt;province.zstring &amp;lt;- (%rsi, %rdi)
&amp;lt;+1316&amp;gt;:	mov    %rdi,0x18(%rax)
&amp;lt;+1320&amp;gt;:	jmpq   0x40105d &amp;lt;main()+781&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Whoa, that’s a lot more code than &lt;a href=&quot;/2017/05/02/performance-of-the-stl-idiom-for-list-comprehension-introduction/&quot;&gt;the basic C++ version generated&lt;/a&gt;! Just over 3.4 times more code, in fact. As well as 2.3 times more stack storage for local variables and temporaries.&lt;/p&gt;

&lt;p&gt;The increased stack storage indicates the key contributor to the increased code size:  There are a lot more local variables and temporaries in this version. Given that these locals typically include a &lt;code class=&quot;highlighter-rouge&quot;&gt;std::string&lt;/code&gt; member, there is a lot of code managing that complex type. The basic version uses one 4-byte temporary for the result of the squared integer value, while the &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt; idiom generates one 8-byte temporary to save a register and 128 bytes of temporary values (&lt;code class=&quot;highlighter-rouge&quot;&gt;l_us&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;T1&lt;/code&gt;, and &lt;code class=&quot;highlighter-rouge&quot;&gt;RT&lt;/code&gt;).&lt;/p&gt;

&lt;p&gt;The temporaries increase register pressure, as well. In the basic version, &lt;code class=&quot;highlighter-rouge&quot;&gt;src_i&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;res_i&lt;/code&gt;, the iterators for &lt;code class=&quot;highlighter-rouge&quot;&gt;src&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;res&lt;/code&gt;, are both in registers, as is &lt;code class=&quot;highlighter-rouge&quot;&gt;src.end()&lt;/code&gt;, used in the loop termination test.  The &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt; version uses all of these but also dedicates registers for temporaries &lt;code class=&quot;highlighter-rouge&quot;&gt;RT&lt;/code&gt; (the result of the lambda, of type &lt;code class=&quot;highlighter-rouge&quot;&gt;optional&amp;lt;pair&amp;gt;&lt;/code&gt;) and &lt;code class=&quot;highlighter-rouge&quot;&gt;T1&lt;/code&gt; (the temporary &lt;code class=&quot;highlighter-rouge&quot;&gt;ppair&lt;/code&gt; created to pass to the &lt;code class=&quot;highlighter-rouge&quot;&gt;RT&lt;/code&gt; constructor). In fact, the register pressure is strong enough that the register holding iterator &lt;code class=&quot;highlighter-rouge&quot;&gt;res_i&lt;/code&gt; is refreshed from local storage in Line 721.&lt;/p&gt;

&lt;p&gt;Temporary &lt;code class=&quot;highlighter-rouge&quot;&gt;T1&lt;/code&gt; seems to enjoy the odd &lt;a href=&quot;https://www.youtube.com/watch?v=MlrsqGal64w&quot;&gt;semi-existence of Eric the Half-a-Bee&lt;/a&gt;, constructed in Lines &lt;code class=&quot;highlighter-rouge&quot;&gt;600–642&lt;/code&gt; but never in fact destroyed. Instead its values are simply moved whole-cloth into temporary result &lt;code class=&quot;highlighter-rouge&quot;&gt;RT&lt;/code&gt; in Lines &lt;code class=&quot;highlighter-rouge&quot;&gt;649–713&lt;/code&gt; and the branch target Lines &lt;code class=&quot;highlighter-rouge&quot;&gt;1256–1288&lt;/code&gt;, without any destructor code generated.  This is distinctly different from &lt;code class=&quot;highlighter-rouge&quot;&gt;RT&lt;/code&gt;, which is move-constructed into the element of &lt;code class=&quot;highlighter-rouge&quot;&gt;res&lt;/code&gt; referenced by iterator &lt;code class=&quot;highlighter-rouge&quot;&gt;res_i&lt;/code&gt; (held in register &lt;code class=&quot;highlighter-rouge&quot;&gt;%rax&lt;/code&gt;) in Lines &lt;code class=&quot;highlighter-rouge&quot;&gt;721–828&lt;/code&gt;.  In this sequence, Lines &lt;code class=&quot;highlighter-rouge&quot;&gt;800–828&lt;/code&gt; implement the assignment of the null string to &lt;code class=&quot;highlighter-rouge&quot;&gt;RT.province&lt;/code&gt;, as required by the standard.  Later, Lines &lt;code class=&quot;highlighter-rouge&quot;&gt;847–860&lt;/code&gt; implement the destructor &lt;code class=&quot;highlighter-rouge&quot;&gt;RT.province.~string()&lt;/code&gt;.  Neither of these steps, the assignment of the null string nor the destructor, is generated for &lt;code class=&quot;highlighter-rouge&quot;&gt;T1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For the potentially slowest operations, references to the heap causing cache misses, the two implementations are identical, making the same sequence of references to the elements of &lt;code class=&quot;highlighter-rouge&quot;&gt;src&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;res&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The compiler has done a marvellous job of collapsing function calls.  The &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt; idiom uses only a single stack frame, the same as the basic code. Techniques of function inlining have successfully collapsed all the layers of function call imposed by the Standard Library’s abstractions.  This is no small feat: In the unoptimized (&lt;code class=&quot;highlighter-rouge&quot;&gt;-O0&lt;/code&gt;) version of the machine code, the deepest call stack has eight levels, as reported by gdb.&lt;/p&gt;

&lt;h2&gt;The costs of so many temporaries and parameters&lt;/h2&gt;

&lt;p&gt;But the many layers of function abstraction obstruct the optimizer in another way: Each layer requires that a parameter be passed, whether by move- or copy-construction or by reference.  I considered this problem when comparing &lt;a href=&quot;/2017/03/07/three-idioms-for-appending-values-a-damaging-decision/&quot;&gt;different idioms for appending values&lt;/a&gt;.  Consider the steps initiated by the body of the loop in &lt;code class=&quot;highlighter-rouge&quot;&gt;std::transform&lt;/code&gt;, the following expression:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res_i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lambda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;// Using my names for the iterators
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;where &lt;code class=&quot;highlighter-rouge&quot;&gt;__result&lt;/code&gt; is an iterator of type &lt;code class=&quot;highlighter-rouge&quot;&gt;opt_back_insert_iterator&amp;lt;vector&amp;lt;optional&amp;lt;ppair&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The lambda function terminates with the statement&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;to compute the result of &lt;code class=&quot;highlighter-rouge&quot;&gt;lambda(*src_i)&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;In &lt;code class=&quot;highlighter-rouge&quot;&gt;libstdc++&lt;/code&gt; 6.2, the &lt;code class=&quot;highlighter-rouge&quot;&gt;return&amp;lt;&lt;/code&gt; statement initiates the following cascade of function calls:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;The temporary &lt;code class=&quot;highlighter-rouge&quot;&gt;ppair&lt;/code&gt; is &lt;a href=&quot;http://en.cppreference.com/w/cpp/language/aggregate_initialization&quot;&gt;aggregate-initialized&lt;/a&gt;.  This in turn requires
copy-constructing the &lt;code class=&quot;highlighter-rouge&quot;&gt;std::string&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt; components of the &lt;code class=&quot;highlighter-rouge&quot;&gt;ppair&lt;/code&gt; at &lt;code class=&quot;highlighter-rouge&quot;&gt;*src_i&lt;/code&gt;. Move constructors cannot be used because the value in &lt;code class=&quot;highlighter-rouge&quot;&gt;src&lt;/code&gt; must not be
modified.&lt;/li&gt;
  &lt;li&gt;The temporary &lt;code class=&quot;highlighter-rouge&quot;&gt;oppair&lt;/code&gt; (of &lt;code class=&quot;highlighter-rouge&quot;&gt;optional&amp;lt;ppair&amp;gt;&lt;/code&gt; type) is explicitly constructed using the Standard Library
&lt;a href=&quot;http://en.cppreference.com/w/cpp/utility/optional/optional&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;optional&amp;lt;ppair&amp;gt;::optional(ppair&amp;amp;&amp;amp; p)&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The function &lt;code class=&quot;highlighter-rouge&quot;&gt;opt_back_insert_iterator&amp;lt;vector&amp;lt;optional&amp;lt;ppair&amp;gt;&amp;gt;&amp;gt;::operator=(optional&amp;lt;ppair&amp;gt;&amp;amp;&amp;amp;t)&lt;/code&gt; is invoked.&lt;/li&gt;
  &lt;li&gt;This invokes the move constructor &lt;code class=&quot;highlighter-rouge&quot;&gt;optional&amp;lt;ppair&amp;gt;::optional(optional&amp;amp;&amp;amp;)&lt;/code&gt; to construct the parameter.&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;highlighter-rouge&quot;&gt;optional&lt;/code&gt; move constructor in turn invokes the move constructor for &lt;code class=&quot;highlighter-rouge&quot;&gt;std::string&lt;/code&gt; and copies the &lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt; value.&lt;/li&gt;
  &lt;li&gt;The rvalue has its member function &lt;code class=&quot;highlighter-rouge&quot;&gt;optional&amp;lt;pair&amp;gt;::value()&lt;/code&gt; invoked, which returns an rvalue reference to the &lt;code class=&quot;highlighter-rouge&quot;&gt;pair&lt;/code&gt; constructed in the first step.&lt;/li&gt;
  &lt;li&gt;The constructed rvalue reference is move-constructed into the parameter for &lt;code class=&quot;highlighter-rouge&quot;&gt;vector&amp;lt;ppair&amp;gt;::push_back(ppair&amp;amp;&amp;amp;)&lt;/code&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;vector&amp;lt;ppair&amp;gt;::push_back(ppair&amp;amp;&amp;amp;)&lt;/code&gt; simply calls
&lt;code class=&quot;highlighter-rouge&quot;&gt;vector&amp;lt;ppair&amp;gt;::emplace_back(ppair&amp;amp;&amp;amp;)&lt;/code&gt;, which constructs the &lt;code class=&quot;highlighter-rouge&quot;&gt;ppair&lt;/code&gt; value
in the element at &lt;code class=&quot;highlighter-rouge&quot;&gt;res.end()&lt;/code&gt;, incrementing the end marker.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Ultimately, all this machinery is invoked to do a near-trivial operation: Copy a &lt;code class=&quot;highlighter-rouge&quot;&gt;std::string&lt;/code&gt; and an &lt;code class=&quot;highlighter-rouge&quot;&gt;int&lt;/code&gt; from an element of &lt;code class=&quot;highlighter-rouge&quot;&gt;src&lt;/code&gt; to an element of &lt;code class=&quot;highlighter-rouge&quot;&gt;res&lt;/code&gt;.  The core C++ language and the Standard Library introduce many features in hope of allowing the programmer to write at the abstract level and have the code compile to the simple level.  But given all the above layers, I am unsurprised that gcc 6.2 could not eliminate them all. The optimizer successfully compressed the hierarchy function calls into a single stack frame but could not compress the hierarchy of constructors, leaving residue like the unnecessary &lt;code class=&quot;highlighter-rouge&quot;&gt;T1&lt;/code&gt; temporary. How much did this extra code affected performance?  In the next post, I will begin presenting microbenchmarks comparing the basic and the &lt;code class=&quot;highlighter-rouge&quot;&gt;transform&lt;/code&gt; implementations of the filter-and-transform algorithm.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Performance of the STL idiom for list comprehension: Introduction</title>
   <link href="/2017/05/02/performance-of-the-stl-idiom-for-list-comprehension-introduction/"/>
   <updated>2017-05-02T00:00:00-07:00</updated>
   <id>/2017/05/02/performance-of-the-stl-idiom-for-list-comprehension-introduction</id>
   <content type="html">&lt;p&gt;In my &lt;a href=&quot;/2017/03/26/a-single-stl-statement-equivalent-to-the-basic-python-list-comprehension/&quot;&gt;last post&lt;/a&gt;, I promised to consider the machine code generated from the STL idiom equivalent to a basic Python list comprehension. As I proceeded, the project expanded to a broader analysis of the idiom’s performance. I am shocked at how much effort this project took.  I have spent much of the last five weeks generating and reading the output from g++ 6.2.  So. Many. Alternatives.  In this post, I’ll describe my baseline for comparison and the criteria I’ll use. In future posts, I’ll present the results.&lt;/p&gt;

&lt;p&gt;All performance analyses are fraught. Conference speakers frequently argue that the gold standard is to run your actual code on your actual data, or as close to actual code and data as you can get. I think this claim is overly strong, but whatever its merits, by design this method by provides no general comparison of two approaches to writing code, only specific results for your context.&lt;/p&gt;

&lt;p&gt;My focus for this series has been more general, on combining the standard algorithms and lambda expressions to create C++ expressions that approximate the concision of basic Python list comprehensions. The design of the C++ language and the STL components of the Standard Library purports to support abstractions that can be compiled to efficient object code. In principle, you get the benefits of abstraction with the efficiency of more concrete, machine-specific code. The general idiom for &lt;code&gt;std::transform()&lt;/code&gt; that I presented in the last post had its share of abstractions: the transform algorithm itself, the &lt;code&gt;std::optional&lt;/code&gt; type, and a custom &lt;a href=&quot;http://en.cppreference.com/w/cpp/concept/OutputIterator&quot;&gt;&lt;code&gt;OutputIterator&lt;/code&gt;&lt;/a&gt; to conditionally append values.  What price do we pay for all that abstraction? And how might we best estimate the price?&lt;/p&gt;

&lt;p&gt;In this series, I will address these questions using two approaches: Analysis of the generated code and microbenchmarks.  The machine code is the definitive indicator of how well the compiler was able to infer the simple structure underlying the abstractions and generate code for that essential structure. Microbenchmarks indicate how well the compiler was able to organize that structure into an operation sequence that executes efficiently on a specific microarchitecture and memory hierarchy.  There are other stories, aspects that these approaches miss, but together these approaches capture many important aspects of performance.&lt;/p&gt;

&lt;h2&gt;Criteria for analysis of generated machine code&lt;/h2&gt;

&lt;p&gt;The criteria for quality of generated code are various and potentially contradictory.  The most obvious criterion, code length, is only the most indirect approximation of execution efficiency. Execution time is heavily influenced by locality of reference, given the roughly &lt;a href=&quot;https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html&quot;&gt;100-fold penalty&lt;/a&gt; of accessing main memory instead of L1 cache. Locality of reference can be improved both by tightening the range of locations accessed by the code and by making such accesses more amenable to hardware prefetch.&lt;/p&gt;

&lt;p&gt;Furthermore, the proper focus of the analysis is the loop code. Assuming the idiom transforms long sequences, the bulk of its time will be consumed by the loop. Accordingly, I’ll emphasize the following metrics when assessing the machine code for the &lt;code&gt;transform&lt;/code&gt; loop:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Number of instruction cache lines to represent the code. For loops such as the code of interest in this analysis, the lines will be cache-resident for every iteration after the first, so their access cost will be typically not be a major factor, although if one or more external routines are called mid-loop, these lines could be flushed and require reloading for the next iteration.&lt;/li&gt;
&lt;li&gt;Number of data cache lines accessed for local values. As with the instruction cache lines, for a loop these lines will typically be cache-resident for every iteration except the first and so their access cost will not contribute substantially to performance. Note: In the rest of this series, I will use &quot;cache&quot; to refer to the data cache and &quot;instruction cache&quot; in those few places I want to refer to the instruction cache.
&lt;/li&gt;
&lt;li&gt;Number of heap allocations and deallocations, each of which will typically require access to multiple lines not currently in the cache. This count is an indirect measure of the cost of those main memory accesses.
&lt;/li&gt;
&lt;li&gt;Number of data cache lines accessed for values on the heap. Unlike accesses to local variables, accesses to heap values have a far higher likelihood of requiring access to main memory. 
&lt;/li&gt;
&lt;li&gt;Predictability of data accesses for hardware prefetch. This feature can partially mitigate the cost of heap accesses. If the hardware prefetch unit can load heap data into the cache before the references occur, a stall can be averted.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I will assume that instruction and data cache lines are 64 bytes, the typical size for processors implementing the x86_64 instruction set. The number of cache lines required for a block of data or instructions ranges from &lt;code&gt;ceil(size/64)–ceil(size/64)+1&lt;/code&gt;, depending upon the block’s alignment.&lt;/p&gt;

&lt;h3&gt;Factors contributing to these metrics&lt;/h3&gt;

&lt;p&gt;The metrics listed above are influenced by the algorithm, the encoding in C++, the library implementation of the data types, and the compiler code generator. My focus in these posts is to compare two C++ encodings of the same algorithm, one using the STL paradigm of standard algorithms and iterators, the other using basic C++ facilities (but still using the Standard Library string and vector classes). Thus the effects of the algorithm are held constant. The effects of the encoding in C++ and the efficiency of its generated code are direct questions in this work.&lt;/p&gt;

&lt;p&gt;Finally, the library implementation of the data types is orthogonal to the above.  As we will see, the choice of data type has major effects on the generated code, the pattern of cache misses, and its execution speed. In short, the question “Can the compiler generate as efficient code for the transform idiom as for the idiom using basic control structures?” depends strongly on &lt;em&gt;what&lt;/em&gt; is being transformed. A source vector whose province names are represented using &lt;code&gt;char const *&lt;/code&gt; null-terminated strings is easier for the optimizer than a source vector whose province names are represented using &lt;code&gt;std::string&lt;/code&gt; instances as implemented by &lt;code&gt;libstdc++&lt;/code&gt; 6.2, and both generate substantially different code from say, Version 4.x of the same library, which lacked a short-string optimization.&lt;/p&gt;

&lt;p&gt;Due to the strong effects of data type implementation, I will analyze and benchmark versions of the two idioms operating on different data types. Initially, I will use the type I presented in the earlier posts, a &lt;code&gt;std::pair&amp;lt;std::string,int&amp;gt;&lt;/code&gt;. In future posts, I will extend the analysis to pairs of other types.&lt;/p&gt;

&lt;h3&gt;Implementation of &lt;code&gt;std::string&lt;/code&gt; in &lt;code&gt;libstsdc++&lt;/code&gt; 6.2&lt;/h3&gt;

&lt;p&gt;As we will see, the implementation of &lt;code&gt;std::string&lt;/code&gt; has a large effect on the efficiency of the code and even of the optimizer’s ability to compile down the &lt;code&gt;std::transform&lt;/code&gt; and &lt;code&gt;std::optional&amp;lt;&amp;gt;&lt;/code&gt; abstractions. To understand the machine code and estimate its accesses to main memory, we need to understand the string implementation in the library.&lt;/p&gt;

&lt;p&gt;The 64-bit-address implementation of &lt;code&gt;std::string&lt;/code&gt; in &lt;code&gt;libstdc++&lt;/code&gt; 6.2 represents a string using a combination of a 32-byte data type handle and an optional heap block. The handle has four fields:&lt;/p&gt;

&lt;table&gt;
&lt;caption&gt;Fields for &lt;code&gt;std::string&lt;/code&gt; in &lt;code&gt;libstdc++&lt;/code&gt; 6.2
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;td&gt;Hex offset
&lt;/td&gt;
&lt;td&gt;Name used in this series
&lt;/td&gt;
&lt;td&gt;Field name in library code
&lt;/td&gt;
&lt;td&gt;Purpose
&lt;/td&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right;&quot;&gt;&lt;code&gt;0x0&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;str_buff&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;_M_p&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Pointer to string body, either &lt;code&gt;_M_local_buf&lt;/code&gt; or heap buffer&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right;&quot;&gt;&lt;code&gt;0x8&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;size&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;_M_string_length&lt;/code&gt;&lt;/td&gt;&lt;td&gt;String length, not counting null terminator&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right;&quot;&gt;&lt;code&gt;0x10&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;zstring&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;_M_local_buf&lt;/code&gt;&lt;/td&gt;&lt;td&gt;String body for strings &amp;lt; 16 characters (null-terminated; union with &lt;code&gt;_M_allocated_capacity&lt;/code&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&quot;text-align:right;&quot;&gt;&lt;code&gt;0x10&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;capacity&lt;/code&gt;&lt;/td&gt;&lt;td&gt;&lt;code&gt;_M_allocated_capacity&lt;/code&gt;&lt;/td&gt;&lt;td&gt;Capacity of heap buffer, if allocated (union with &lt;code&gt;_M_local_buf&lt;/code&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The handle includes an 8-byte pointer to the string body, which is null-terminated, and an 8-byte count of the characters (not including the terminating null).&lt;/p&gt;

&lt;p&gt;Strings of less than 16 characters are directly stored in the remaining 16 bytes of the handle. For these strings, the pointer at the head of the handle points to the first of these bytes.  Strings of 16 or more characters are stored in a heap-allocated block, which can be larger than the string.  The pointer in the handle indicates the first byte of this block, while the second half of the handle includes an 8-byte count of the heap block capacity.&lt;/p&gt;

&lt;p&gt;This structure is designed to minimize heap accesses and by implication cache misses. It supports a fast check for string inequality: If two strings have unequal lengths, which can be determined simply by looking at the handle, there is no need to access the heap values. If two strings are the same length and less than 16 characters, their bodies can be compared with a fast access to the string handle, but strings of equal length greater than or equal to 16 characters require access to heap values, typically requiring two or more cache lines to be loaded.&lt;/p&gt;

&lt;p&gt;Move constructors and move assignments are fast for all strings, even those whose bodies are on the heap, as the operation only requires copying the fields in the handle.&lt;/p&gt;

&lt;p&gt;Copy constructors and copy assignments are fast for &lt;em&gt;short&lt;/em&gt; strings, as the operation simply copies the local values in the handles. For longer strings, however, both operations will require an expensive heap allocation, potentially incurring multiple cache line loads. Once this has completed, the actual copy operations should access the already-loaded lines.&lt;/p&gt;

&lt;h2&gt;The comparison baseline&lt;/h2&gt;

&lt;p&gt;The original idiom embedded conditionals into abstractions (the &lt;code&gt;std::transform&lt;/code&gt; algorithm, the &lt;code&gt;std::optional&lt;/code&gt; type, and the &lt;code&gt;opt_back_insert_iterator&lt;/code&gt;) to allow a filter-and-transform algorithm to be expressed declaratively.  The baseline comparison exposes the conditionals directly as standard C++ control structures. Here is the filter-and-transform algorithm implemented using basic control structures:&lt;/p&gt;

&lt;!-- highlight=&quot;7,8,9&quot; --&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;us&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This version does a range &lt;code&gt;for&lt;/code&gt; over &lt;code&gt;src&lt;/code&gt; and an &lt;code&gt;if&lt;/code&gt; to select the elements to add to &lt;code&gt;res&lt;/code&gt;.  The &lt;code&gt;for&lt;/code&gt; index is by reference and &lt;code&gt;res&lt;/code&gt; is extended using &lt;code&gt;vector::emplace_back()&lt;/code&gt;, minimizing intermediate copies. The code isn’t particularly long and is arguably simpler than the transform idiom, at least if you have never seen the transform before.&lt;/p&gt;

&lt;h2&gt;Machine code for the basic C++&lt;/h2&gt;

&lt;p&gt;Here is the annotated &lt;code&gt;gdb&lt;/code&gt; disassembly of the  machine code generated from &lt;code&gt;-O2&lt;/code&gt; for the loop (Lines 7–9, highlighted) of the basic C++ source presented above.  The code was generated by g++ 6.2 and its associated version of &lt;code&gt;libstdc++&lt;/code&gt;, compiled with only the &lt;code&gt;-g -O2&lt;/code&gt; options, for 64-bit Ubuntu 16.04. I found that using &lt;code&gt;-O3&lt;/code&gt; optimization increased code length substantially (40% more bytes). I will include the &lt;code&gt;-O3&lt;/code&gt; in the benchmarks but use the shorter &lt;code&gt;-O2&lt;/code&gt; output for annotation.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;// LOOP
// 654 - 536 = 118 bytes = 2-3 instruction cache lines
// All (non-terminating) branches are local to loop body

// Register usage
// %rbx == src_i
// %r13 == res_i
// %r14 == src.end()

// Local variables
// Range for local variables used in loop: 0x70 = 112 bytes = 2-3 data cache
//   lines
// (includes 0xc+0x8+0x8 = 0x1c = 28 bytes = 0-1 extra cache lines for
//   alignment padding)
// Local variable offsets (hexadecimal) from %rsp:
//  c Rvalue SQUARE (value ^ 2)
// 10 src
//   10 begin()
//   18 end()
//   20 cap_end() Pointer to byte following the reserved capacity
// 30 res
//   30 begin()
//   38 end()
//   40 cap_end() Pointer to byte following the reserved capacity
// 50 us
//   50 str_buff
//   58 size
//   60 Union
//      zstring 16-byte buffer for null-terminated strings of length &amp;lt; 16
//      capacity 8-byte size of heap buffer for strings of length &amp;gt;= 16

// Heap references (arrays for src and res, strings longer than 15 chars)
// src and res: Single pass in monotonically-increasing order
// (data prefetching should work)
// strings: single memcpy call for every string &amp;gt; 15 chars
// (most likely two distinct heap locations = 2 data cache lines)
//          When us.len &amp;gt; 15:
//            single memcmp call for every string of same length as us
//            (most likely two distinct heap locations = 2 data cache lines)

// rvalue SQUARE &amp;lt;- src_i-&amp;gt;value ^ 2
&amp;lt;+536&amp;gt;:	mov    0x20(%rbx),%eax          
&amp;lt;+539&amp;gt;:	imul   %eax,%eax                 %eax &amp;lt;- src_i-&amp;gt;value ^ 2
&amp;lt;+542&amp;gt;:	cmp    %r13,0x40(%rsp)           res_i ==? res.cap_end()
&amp;lt;+547&amp;gt;:	mov    %eax,0xc(%rsp)            SQUARE &amp;lt;- value ^ 2
&amp;lt;+551&amp;gt;:	je     0x4010fe &amp;lt;main()+942&amp;gt;     Jump if need to extend res (never taken in this idiom)
&amp;lt;+557&amp;gt;:	test   %r13,%r13
&amp;lt;+560&amp;gt;:	je     0x400fa6 &amp;lt;main()+598&amp;gt;     Jump if res has not been allocated (never taken in this idiom)
// *res_i &amp;lt;- (src_i-&amp;gt;province, rvalue SQUARE)
&amp;lt;+562&amp;gt;:	lea    0x10(%r13),%rax           %rax &amp;lt;- &amp;amp; res_i-&amp;gt;province.zstring
&amp;lt;+566&amp;gt;:	mov    %r13,%rdi                 %rdi &amp;lt;- &amp;amp; res_i-&amp;gt;province
&amp;lt;+569&amp;gt;:	mov    %rax,0x0(%r13)            res_i-&amp;gt;str_buff &amp;lt;- &amp;amp; res_i-&amp;gt;province.zstring
&amp;lt;+573&amp;gt;:	mov    (%rbx),%rsi               %rsi &amp;lt;- src_i-&amp;gt;province.str_buff
&amp;lt;+576&amp;gt;:	lea    (%rsi,%rbp,1),%rdx        %rdx &amp;lt;- src_i-&amp;gt;province.str_buff + src_i-&amp;gt;province.size+1
&amp;lt;+580&amp;gt;:	callq  std::string::_M_construct&amp;lt;char*&amp;gt;(char*, char*, std::forward_iterator_tag) HEAP STRING REFERENCE (for string &amp;gt; 15 chars)
&amp;lt;+585&amp;gt;:	mov    0xc(%rsp),%eax
&amp;lt;+589&amp;gt;:	mov    %eax,0x20(%r13)           res_i-&amp;gt;value &amp;lt;- SQUARE

// Increment res_i, src_i, check strings, take branches
&amp;lt;+593&amp;gt;:	mov    0x38(%rsp),%r13           (Unnecessary load, %r13 already contains res_i)
&amp;lt;+598&amp;gt;:	add    $0x28,%r13                res_i++  
&amp;lt;+602&amp;gt;:	mov    %r13,0x38(%rsp)           res.end() &amp;lt;- res_i

&amp;lt;+607&amp;gt;:	add    $0x28,%rbx                src_i++
&amp;lt;+611&amp;gt;:	cmp    %rbx,%r14                 src_i == src.end()
&amp;lt;+614&amp;gt;:	je     0x400fe0 &amp;lt;main()+656&amp;gt;     At end, start sort
&amp;lt;+616&amp;gt;:	mov    0x8(%rbx),%rbp            %rbp &amp;lt;- src_i-&amp;gt;province.size
&amp;lt;+620&amp;gt;:	cmp    0x58(%rsp),%rbp           us.size ==? src_i-&amp;gt;province.size
&amp;lt;+625&amp;gt;:	jne    0x400f68 &amp;lt;main()+536&amp;gt;     Jump if strings different sizes
&amp;lt;+627&amp;gt;:	test   %rbp,%rbp
&amp;lt;+630&amp;gt;:	je     0x400faf &amp;lt;main()+607&amp;gt;     Go to next src_i if src_i-&amp;gt;province.size == 0
&amp;lt;+632&amp;gt;:	mov    0x50(%rsp),%rsi           %rsi &amp;lt;- us.str_buff
&amp;lt;+637&amp;gt;:	mov    (%rbx),%rdi               %rdi &amp;lt;- src_i-&amp;gt;province.str_buff
&amp;lt;+640&amp;gt;:	mov    %rbp,%rdx                 %rdx &amp;lt;- src_i-&amp;gt;province.size
&amp;lt;+643&amp;gt;:	callq  0x400cd0 &amp;lt;memcmp@plt&amp;gt;     Compare string contents HEAP STRING REFERENCE (for string &amp;gt; 15 chars)
&amp;lt;+648&amp;gt;:	test   %eax,%eax
&amp;lt;+650&amp;gt;:	jne    0x400f68 &amp;lt;main()+536&amp;gt;     Strings not equal: Store value
&amp;lt;+652&amp;gt;:	jmp    0x400faf &amp;lt;main()+607&amp;gt;     Strings equal: Go to next value
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The code is annotated by lines beginning with &lt;code&gt;//&lt;/code&gt; and comments starting in Column 41, many of which require horizontal scrolling to read completely.&lt;/p&gt;

&lt;p&gt;The generated code is short and straightforward, requiring 2–3 lines of the instruction cache.  Other than branches to terminate the loop, all conditionals in the loop body branch to locations within the body.&lt;/p&gt;

&lt;p&gt;The local variables require only 112 bytes, 2–3 data cache lines. These lines are likely to be loaded during the first iteration and remain in the cache for the loop duration.&lt;/p&gt;

&lt;p&gt;Heap references have the greatest potential to slow down the code, as they may require access to locations that have not been recently accessed, causing last-level cache misses.&lt;/p&gt;

&lt;p&gt;For the two vectors, whose elements are stored in blocks on the heap, the machine code makes the fewest possible such accesses, walking through them in a single pass each, a pattern amenable to hardware prefetch.&lt;/p&gt;

&lt;p&gt;As described above, the &lt;code&gt;std::string&lt;/code&gt; types can incur multiple cache misses, depending upon the lengths of the strings and how many long strings have the same length but different contents.  In every case, the above code makes the minimum such accesses.&lt;/p&gt;

&lt;p&gt;This baseline demonstrates that code for the filter-and-transform algorithm using basic C++ control structures and the Standard Library string and vector can generate straightforward code.  Indeed, most of the complexity in the above performance analysis is the complexity of the performance of the &lt;code&gt;std::string &lt;/code&gt; type. This complexity stems in turn from &lt;em&gt;optimizations&lt;/em&gt; in the string algorithms.  As we will see, using &lt;code&gt;char const *&lt;/code&gt; types generates simpler code but it can produce more cache misses. But before we consider alternative data types, we need to explore the code produced by the &lt;code&gt;std::transform&lt;/code&gt; idiom for the data types used in the baseline. Spoiler: It’s more complex.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>A single STL statement equivalent to the basic Python list comprehension</title>
   <link href="/2017/03/26/a-single-stl-statement-equivalent-to-the-basic-python-list-comprehension/"/>
   <updated>2017-03-26T00:00:00-07:00</updated>
   <id>/2017/03/26/a-single-stl-statement-equivalent-to-the-basic-python-list-comprehension</id>
   <content type="html">&lt;p&gt;In &lt;a href=&quot;/2017/03/21/the-limits-of-list-comprehensions/&quot;&gt;the last post&lt;/a&gt;, I described the structure of the basic Python list comprehension&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[expression1(var) for var in expression2 if condition(var)]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;and lamented that all the straightforward translations to the STL algorithms required two statements, one for the filter and one for the computation.&lt;/p&gt;

&lt;!--more--&gt;
&lt;p&gt;These “straightforward” translations use the &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/transform&quot;&gt;std::transform()&lt;/a&gt; algorithm, which seemingly enforces a one-to-one mapping from source to sink.  But this one-to-one mapping is not really enforced by the algorithm but instead by the insertion iterator for the sink. If the inserter would only output items that passed the filter, the basic Python list comprehension could be accomplished in a single STL &lt;code&gt;transform()&lt;/code&gt;. To produce this, the filter expression, a C++ lambda, must communicate to the insertion iterator whether a value has passed the filter. The iterator would only insert passed values.&lt;/p&gt;

&lt;p&gt;We can use the C++ 17 &lt;a href=&quot;http://en.cppreference.com/w/cpp/utility/optional&quot;&gt;&lt;code&gt;std::optional&lt;/code&gt;&lt;/a&gt; type (available in earlier versions of the language via &lt;a href=&quot;http://www.boost.org/doc/libs/1_63_0/libs/optional/doc/html/index.html&quot;&gt;&lt;code&gt;boost::optional&lt;/code&gt;&lt;/a&gt;) as the link between the filter and iterator. In addition, we need a version of &lt;a href=&quot;http://en.cppreference.com/w/cpp/iterator/back_insert_iterator&quot;&gt;&lt;code&gt;back_insert_iterator()&lt;/code&gt;&lt;/a&gt; that accepts an &lt;code&gt;optional&lt;/code&gt; value and only performs a &lt;code&gt;push_back()&lt;/code&gt; when its argument contains a value. I built one starting from &lt;a href=&quot;http://stackoverflow.com/questions/18728257/back-emplacer-implementation-default-operator-vs-universal-reference-version&quot;&gt;Andre Tomazo’s &lt;code&gt;back_emplace_iterator()&lt;/code&gt;&lt;/a&gt; (code provided in the Appendix).&lt;/p&gt;

&lt;p&gt;With these tools, the list comprehension from the last post&lt;/p&gt;

&lt;!-- highlight=&quot;2,3&quot; --&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lst&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'US'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'NB'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'US'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'NB'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;can be written in the STL as&lt;/p&gt;

&lt;!-- highlight=&quot;2,30,31,32,33,34,35,36,37,38,39,40&quot; --&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;(&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;NB&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;NB&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The second line defines a convenient alias for &lt;code&gt;optional&lt;/code&gt;, &lt;code&gt;oppair&lt;/code&gt;.  The lines corresponding to the list comprehension, Lines 30–40, no longer have a &lt;code&gt;std::copy_if()&lt;/code&gt; statement but only a &lt;code&gt;std::transform()&lt;/code&gt;. The sink for the transform is now an &lt;code&gt;opt_back_insert_iterator&lt;/code&gt; and the filter lambda returns an &lt;code&gt;oppair&lt;/code&gt; that indicates whether the value passed the filter.&lt;/p&gt;

&lt;p&gt;Once a programmer has acquired the &lt;code&gt;transform/opt_back_insert_iterator&lt;/code&gt; idiom, a given use only requires them to derive the lambda combining the filter and and computation. The lambda is essentially the Python list comprehension annotated with types.&lt;/p&gt;

&lt;p&gt;This idiom allows you to write C++ expressions equivalent to basic
list comprehensions with about the same complexity. There is a lot of
boilerplate the in C++ code—the definition of
&lt;code&gt;opt_back_insert_iterator&lt;/code&gt;, the call to
&lt;code&gt;res.reserve()&lt;/code&gt;, and the elaborate
&lt;code&gt;std::transform()&lt;/code&gt; call—that is automatically provided by
Python, but that code is the same for any use.  All the customization
is contained in the lambda. The programmer does have to choose between
the various &lt;a href=&quot;/2017/03/07/three-idioms-for-appending-values-a-damaging-decision/&quot;&gt;approaches
to building the result vector&lt;/a&gt;, though the reserve/insert-back one used here is a good default.&lt;/p&gt;

&lt;p&gt;The method has introduced many abstractions: the algorithm, the lambda, the &lt;code&gt;optional&lt;/code&gt; type, the inserter template.  Do these bloat the code or can the compiler reduce them to their basic constructs? And how does the generated code compare with the code generated from a basic &lt;code&gt;for&lt;/code&gt; loop?  It depends upon the values we are passing through the expression. I will explore the generated machine code in the next post.&lt;/p&gt;

&lt;h2&gt;Appendix: Full code&lt;/h2&gt;

&lt;p&gt;The full code for the above program, including the definition of &lt;code&gt;opt_back_insert_iterator()&lt;/code&gt;. Take care when using this code with Standard Library implementations, such as libstdc++ 6.2, that do not support the &lt;code&gt;has_type()&lt;/code&gt; member of &lt;code&gt;optional&lt;/code&gt;. In that case, the &lt;code&gt;operator=()&lt;/code&gt; member function template simply requires a type that supports both a boolean conversion and a &lt;code&gt;value()&lt;/code&gt; member. This may include types that are not implementations of some optional type.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/*
  Example of passing optional values to OutputIterator 
 */&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;algorithm&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;iterator&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;tuple&amp;gt;
#include &amp;lt;vector&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;experimental/optional&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
  Class opt_back_insert_iterator derived from Andre Tomazos's
  back_emplace_iterator():
  http://stackoverflow.com/questions/18728257/back-emplacer-implementation-default-operator-vs-universal-reference-version

  with following changes:
  1. operator=() expects an optional&amp;lt;&amp;gt; type and uses push_back() only when
     argument contains an actual value.
  2. Deprecated (as of C++ 17) std::iterator derivation replaced by
     explicit using declarations.
  3. Typedefs converted to using declarations.
  4. &quot;class&quot; in template parameters replaced with &quot;typename&quot;
  5. Formatting slightly modified.

  libstdc++ 6.2 implementation of optional&amp;lt;&amp;gt; does not have &quot;has_value()&quot; member.
  When full C++17 implementation is available, undefine
  OPT_BACK_INSERT_NO_HAS_VALUE.
 */&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#define OPT_BACK_INSERT_NO_HAS_VALUE
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#ifdef OPT_BACK_INSERT_NO_HAS_VALUE
#define HAS_VALUE(t) (bool(t))
#else
#define HAS_VALUE(t) (t.has_value())
#endif
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_back_insert_iterator&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;protected&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterator_category&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_iterator_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pointer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;difference_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;container_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;explicit&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;opt_back_insert_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_not_self&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;enable_if&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;
      &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_same&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;opt_back_insert_iterator&lt;/span&gt;
       &lt;span class=&quot;o&quot;&gt;&amp;gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;&amp;gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_not_self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opt_back_insert_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;amp;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;HAS_VALUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;// ========================================
&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opt_back_insert_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opt_back_insert_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opt_back_insert_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;kr&quot;&gt;inline&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_insert_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;opt_back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_insert_iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Container&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optional&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;(&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;NB&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;NB&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;oppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>The limits of list comprehensions</title>
   <link href="/2017/03/21/the-limits-of-list-comprehensions/"/>
   <updated>2017-03-21T00:00:00-07:00</updated>
   <id>/2017/03/21/the-limits-of-list-comprehensions</id>
   <content type="html">&lt;p&gt;I’ve spent my recent posts unfavourably comparing the STL design of containers/iterators/algorithms with Python list comprehensions and their close relatives in Haskell.  This is an unfairly restrictive way to view the STL design, which addresses a wider range of use cases than the ones addressed by list comprehensions.  But it is also unfair in that it ignores the limitations of list comprehensions themselves, limitations avoided by the more general structure provided by the STL.  In this post, I’ll start from the other direction, considering the inherent limitations of Python list comprehensions. This in turn leads to an idiom in the STL that in fact provides virtually all the functionality of basic list comprehensions, with only slightly more complex syntax.&lt;/p&gt;

&lt;h2&gt;The general and basic forms of Python list comprehensions&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://docs.python.org/3/reference/expressions.html#displays-for-lists-sets-and-dictionaries&quot;&gt;full form of Python list comprehensions&lt;/a&gt; is complex, permitting &lt;a href=&quot;https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions&quot;&gt;many forms of nesting&lt;/a&gt;. For this post, I’m going to focus on the most basic form, &lt;code&gt;[expression1 for var in expression2 if condition(var)]&lt;/code&gt;, where &lt;code&gt;expression2&lt;/code&gt; evaluates to an iterator and &lt;code&gt;expression1&lt;/code&gt; is some function of &lt;code&gt;var&lt;/code&gt;.  I won’t consider the cases where there are multiple &lt;code&gt;for ... if ... &lt;/code&gt; on the right, nor the cases where &lt;code&gt;expression1&lt;/code&gt; is itself a list comprehension.&lt;/p&gt;

&lt;p&gt;I am also not going to consider Python’s syntactically similar &lt;a href=&quot;https://docs.python.org/3/reference/expressions.html#generator-expressions&quot;&gt;generator expressions&lt;/a&gt;, which only compute elements on demand, handling very long and infinite streams.  This is not how the &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm&quot;&gt;STL algorithms&lt;/a&gt; work, which all require the complete evaluation of their range, corresponding to list comprehensions.&lt;/p&gt;

&lt;p&gt;Within those restrictions, the basic Python list comprehension has this structure:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;for each element returned by an iterator
  if the element passes the filter
    compute a function of the element
    append the computed value to the result list
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This structure is broadly useful but its element-at-a-time structure has a fundamental limitation:  You have to leave the paradigm whenever you have an operation on two or more values from the iterator.  The classic algorithm requiring such an operation is sorting, which must test pairs of values.&lt;/p&gt;

&lt;p&gt;It turns out that use cases that require you to filter, sort, and then filter again are rather specialized. The Python example that I wrote for this post wound up being so contrived that I won’t bother to include it here.  I suspect the primary use cases for filter/sort/filter lie in database operations, where the intermediate sort step is required to efficiently scan key lists along indices, producing more efficient access to external storage. Intermediate sort steps seem far less useful for the cases considered in this post, where the entire data structure is already in memory.&lt;/p&gt;

&lt;h2&gt;If needed, sorting commonly precedes or follows a list comprehension&lt;/h2&gt;

&lt;p&gt;A far more common use case requires the filtering and computation to be performed in one step, with the sorting done either before or after. For example,  given a list of pairs whose first value is an abbreviation for either a Canadian province or &lt;code&gt;US&lt;/code&gt; for the USA and whose second value is an amount, &lt;code&gt;func()&lt;/code&gt; filters out the US amounts and returns the squares of the Canadian amounts, sorted by province and squared amount:&lt;/p&gt;

&lt;!-- highlight=&quot;2,3&quot; --&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lst&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lst&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'US'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sorted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;__name__&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'__main__'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;func&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'NB'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'US'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'NB'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'BC'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The per-pair processing is handled well by the list comprehension (Line 2), with the sort done (Line 3) on the computed result.  The same effect can be accomplished via the considerably more prolix STL sequence (equivalent code highlighted)&lt;/p&gt;

&lt;!-- highlight=&quot;29,30,31,32,33,34,35,36,37,38,39&quot; --&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;(&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;empty&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;NB&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;NB&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;BC&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy_if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
    &lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;US&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;plist&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ppair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;second&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The STL version uses the &lt;a href=&quot;/2017/03/09/a-simpler-fourth-idiom-for-appending/&quot;&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;reserve/back_inserter&lt;/code&gt; approach&lt;/a&gt; to building the temporary &lt;code&gt;t1&lt;/code&gt; and the result &lt;code&gt;res&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The primary source of the extra length of the STL algorithm is the requirement for separate &lt;code&gt;copy_if&lt;/code&gt; and &lt;code&gt;transform&lt;/code&gt; steps. This separation is necessitated by the &lt;code&gt;transform&lt;/code&gt; algorithm’s requirement that it produce exactly one transformed result for every element in the source.  By contrast, the Python list comprehension’s &lt;code&gt;if&lt;/code&gt; filter allows its result to have fewer elements than its source.&lt;/p&gt;

&lt;p&gt;Although it is not obvious, there &lt;em&gt;is&lt;/em&gt; a way to combine the filter and computation in the STL &lt;code&gt;transform&lt;/code&gt; function, giving a one-line transform that produces fewer elements than its sink.  The trick is that the filter isn’t located in the lambda expression—at least not entirely.  I’ll present that solution in my next post.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>A simpler, fourth idiom for appending</title>
   <link href="/2017/03/09/a-simpler-fourth-idiom-for-appending/"/>
   <updated>2017-03-09T00:00:00-08:00</updated>
   <id>/2017/03/09/a-simpler-fourth-idiom-for-appending</id>
   <content type="html">&lt;p&gt;This morning, I realized that there is a fourth approach to appending items to a vector that combines &lt;a href=&quot;/2017/03/07/three-idioms-for-appending-values-a-damaging-decision/&quot;&gt;elements of the first and third&lt;/a&gt;.  I’m embarrassed to have missed this one because it is a longstanding, well-understood approach that’s particularly applicable to the kinds of “list comprehension algorithms” I’m considering in this series.&lt;/p&gt;

&lt;p&gt;Reviewing the output of the first method, a large proportion of the extra effort is due to the incremental &lt;em&gt;allocation&lt;/em&gt; of the vector’s data member, where the values are actually stored. In some use cases, this is the best you can do because you do not know in advance how large the result is going to be. However, in the case considered in our examples, we know exactly how many elements the result will have:  exactly as many elements as the source vector.  In such cases, we can pre-allocate a storage block of the right size and then the back insertions simply consist of moving the values into that allocated space, with no reallocations to expand the vector. This was a crucial part of the efficiency of the third idiom, using &lt;code&gt;emplace_back()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This approach simply adds one line to the first idiom:&lt;/p&gt;

&lt;!-- highlight=&quot;2&quot;--&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;Coll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c4&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This code performs considerably fewer operations than the first idiom:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;New collection c4
[Vector allocates space for at least 5 values, c4[0] to c4[4]]

// Append C(0, 0)
Basic constructor for T0
Move constructor for c4[0] from T0
Destructor for T0

// Append C(1, 1)
Basic constructor for T0
Move constructor for c4[1] from T0
Destructor for T0

// Append C(2, 2)
Basic constructor for T0
Move constructor for c4[2] from T0
Destructor for T0

// Append C(3, 3)
Basic constructor for T0
Move constructor for c4[3] from T0
Destructor for T0

// Append C(4, 4)
Basic constructor for T0
Move constructor for c4[4] from T0
Destructor for T0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;We have completely eliminated the allocate/copy/deallocate sequences. We always have to construct the value, so the only extra work performed relative to the third, &lt;code&gt;emplace_back()&lt;/code&gt;-based, idiom is the move-assign from the temporary value and its destruction.  Both of these are likely to be fast. The move will be fast for objects that are small or implemented as small handles to a larger heap data object, though it will be slower for objects that contain a large amount of data directly.  The destructor will typically be fast or even nonexistent, a simple pop of the stack pointer.&lt;/p&gt;

&lt;p&gt;This method also has the substantial advantage of neatly fitting as a sink for a standard algorithm, unlike the third idiom, which was incompatible with the standard algorithms and required reconstructing them from &lt;code&gt;for&lt;/code&gt; loops and basic logic. For the case where the exact size of the result is known in advance, this idiom is likely preferable to the &lt;code&gt;emplace_back()&lt;/code&gt; approach.&lt;/p&gt;

&lt;h2&gt;Applying this pattern for filters&lt;/h2&gt;

&lt;p&gt;Unlike the &lt;code&gt;std::transform&lt;/code&gt; algorithm in the above example, there are algorithms where we do not know the number of results in advance. Consider &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/copy&quot;&gt;&lt;code&gt;std::copy_if()&lt;/code&gt;&lt;/a&gt;. We know the maximum number of results, which can never be larger than the source, but the actual size is determined by the number of elements for which the filter returns &lt;code&gt;true&lt;/code&gt;. If we’re willing to over-reserve space, we can just use the above approach and accept that capacity may exceed size, perhaps significantly. This problem also exists for the &lt;code&gt;emplace_back()&lt;/code&gt; approach, whose efficiency also depended upon pre-reservation.&lt;/p&gt;

&lt;p&gt;C++11 added the &lt;a href=&quot;http://en.cppreference.com/w/cpp/container/vector/shrink_to_fit&quot;&gt;&lt;code&gt;std::vector::shrink_to_fit()&lt;/code&gt;&lt;/a&gt; function, which potentially eliminates the extra space after the &lt;code&gt;copy_if()&lt;/code&gt; completes, but the standard gives implementers wide latitude:  The function could do nothing at all, shrink the vector’s data in place, or allocate-and-copy into a smaller region. Whether it provides a real performance improvement will be specific to your application and library.&lt;/p&gt;

&lt;h2&gt;Reconsidering my critique of the STL design in light of this idiom&lt;/h2&gt;

&lt;p&gt;I ended the last post by carping on the decision load imposed by the STL design on programmers, who have to choose amongst multiple idioms, each of which exceeds the others by at least one criterion. The addition of this idiom simplifies the choice substantially. For many, many use cases, I would choose this idiom.&lt;/p&gt;

&lt;p&gt;But not for all cases. Large &lt;a href=&quot;http://en.cppreference.com/w/cpp/concept/PODType&quot;&gt;&lt;code&gt;PODType&lt;/code&gt;&lt;/a&gt; objects are best handled via &lt;code&gt;emplace_back()&lt;/code&gt;, which never copies or moves the value. Objects whose constructors and destructors perform expensive resource reservation / release pairs are also be better-suited to &lt;code&gt;emplace_back()&lt;/code&gt;—though I cannot think of many actual use cases where large numbers of such objects are going to be stored in a vector.&lt;/p&gt;

&lt;p&gt;In short, the pre-reserve/back_insert approach is appropriate for a wide range of use cases, making it a useful default idiom. Programmers must still take care to avoid it in those cases where it will be substantially more inefficient than the &lt;code&gt;emplace_back()&lt;/code&gt; idiom.&lt;/p&gt;

&lt;p&gt;The larger point remains, although its severity is tempered: By exposing so many decisions to the programmer, the C++ language and its Standard Library increase the effort required to solve common tasks. Whether the potential gains in efficiency and robustness are worth the extra effort remains an open question.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Three idioms for appending values&mdash;a damaging decision?</title>
   <link href="/2017/03/07/three-idioms-for-appending-values-a-damaging-decision/"/>
   <updated>2017-03-07T00:00:00-08:00</updated>
   <id>/2017/03/07/three-idioms-for-appending-values-a-damaging-decision</id>
   <content type="html">&lt;p&gt;&lt;b&gt;Update:&lt;/b&gt; See also the &lt;a href=&quot;/2017/03/09/a-simpler-fourth-idiom-for-appending/&quot;&gt;next post&lt;/a&gt;, which adds a fourth idiom and mitigates some of the criticisms in the conclusion of this post.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;/2017/02/22/iterators-a-failure-case/&quot;&gt;STL code for squaring the positive values&lt;/a&gt;, included the following lines to create the intermediate result &lt;code&gt;t1&lt;/code&gt; containing the positive values of the original list &lt;code&gt;a&lt;/code&gt;:&lt;/p&gt;

&lt;!--more--&gt;
&lt;!-- highlight=&quot;1,4&quot; --&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;copy_if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
         &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
         &lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This is a typical idiom when writing sequences of STL transformations. It declares an empty vector in Line 1 then appends new values to it via a &lt;a href=&quot;http://en.cppreference.com/w/cpp/iterator/back_inserter&quot;&gt;&lt;code&gt;back_inserter()&lt;/code&gt;&lt;/a&gt; adaptor (Line 4).&lt;/p&gt;

&lt;p&gt;As an idiom, this works well. It fits the STL pattern for algorithms&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;algorithm (start, end, sink [, other options])
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;that we use in the sequence and the &lt;code&gt;back_inserter()&lt;/code&gt; adapter can be applied to a &lt;code&gt;std::vector&lt;/code&gt;, &lt;code&gt;std::deque&lt;/code&gt;, or &lt;code&gt;std::list&lt;/code&gt;. But the idiom also has some problems:  For some kinds of objects, it may waste a lot of CPU time on unnecessary operations. It can also fragment the heap.&lt;/p&gt;

&lt;p&gt;There are in fact three distinct idioms that you might use to build the temporary result, of increasing efficiency. Unfortunately, the most efficient idiom does not fit the above pattern for using the STL algorithms. Instead, the programmer must construct their algorithm from a &lt;code&gt;for&lt;/code&gt; loop and basic code. As of C++ 2017, There is no way in the Standard Library to combine the standard algorithms with the most efficient idiom for constructing results.&lt;/p&gt;

&lt;h2&gt;Allocation, initialization, and assignment&lt;/h2&gt;

&lt;p&gt;To understand the different idioms for building a result in a collection, we have to first distinguish storage duration and variable lifetime. As I mentioned several posts ago, I am planning a whole series on how C++ approaches these topics, differentiating that approach from the ones taken by managed languages. I don’t need to go into as much detail for this post, so I’ll focus the discussion on the specific points necessary to describe the stages for values being appended to STL collections.&lt;/p&gt;

&lt;p&gt;C++ carefully distinguishes the storage management from the object life cycle. Storage management has two steps and is performed &lt;em&gt;by the collection&lt;/em&gt; as its capacity requirements expand and contract:&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;Allocation&lt;/dt&gt;
&lt;dd&gt;A block of raw, uninitialized bytes is reserved by the collection, typically from the C++ runtime via &lt;a href=&quot;http://en.cppreference.com/w/cpp/memory/new/operator_new&quot;&gt;operator &lt;code&gt;new()&lt;/code&gt;&lt;/a&gt;.  The C++ runtime in turn requests large blocks of memory from the operating system. 
&lt;/dd&gt;
&lt;dt&gt;Deallocation&lt;/dt&gt;
&lt;dd&gt;A block of previously-allocated bytes is returned, typically to the C++ runtime via &lt;a href=&quot;http://en.cppreference.com/w/cpp/memory/new/operator_delete&quot;&gt;operator &lt;code&gt;delete()&lt;/code&gt;&lt;/a&gt;. The runtime typically retains the storage for potential reallocation, returning it to the operating system when the application terminates.
&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Allocation and deallocation deal simply in raw bytes that have no meaning in the language. Only object values have meaning. Values appended to a collection have a distinct life cycle, with steps occurring in the following order:&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;Initialization&lt;/dt&gt;
&lt;dd&gt;When a value is appended to the collection it is built in storage that has been allocated by the collection but not yet used to store a value.  The value is built by the constructor for the object's class.
&lt;/dd&gt;
&lt;dt&gt;Assignment&lt;/dt&gt;
&lt;dd&gt;If the value can be accessed via a non-&lt;code&gt;const&lt;/code&gt; type, it may be overwritten via an assignment.
&lt;/dd&gt;
&lt;dt&gt;Destruction&lt;/dt&gt;
&lt;dd&gt;When the collection is destroyed, it destroys all the values it holds, calling the destructor for each value.  The value destructor in turn releases any resources that value holds.
&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;This simple model is sufficient to describe the case of interest here, where values are appended to a collection in a single pass, perhaps to be read back as input in a subsequent pass. More complicated uses, such as erasing objects from a collection, require a more sophisticated description.&lt;/p&gt;

&lt;h2&gt;A class with a transparent life cycle&lt;/h2&gt;

&lt;p&gt;To compare the different idioms for appending results, we need to make the above stages visible.  The following class instruments its member functions to print a message whenever an instance is created, assigned, or deleted:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Basic constructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Copy constructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; from &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// Replace above with this to test with only move constructor
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;//C (const C&amp;amp; c) = delete;
&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Move constructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; from &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Default constructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Copy assignment for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; from &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Move assignment for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; from &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Destructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;temps_del&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;friend&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The class simply stores two integers, &lt;code&gt;m1&lt;/code&gt; and &lt;code&gt;m2&lt;/code&gt;.  Its member functions call instrumentation functions &lt;code&gt;collection_name()&lt;/code&gt; and &lt;code&gt;temp_del&lt;/code&gt;, which track details of the allocations.  The full code for this post, including instrumentation, is presented in the appendix.&lt;/p&gt;

&lt;p&gt;Let’s see what happens when we use different idioms to append instances of this class to a &lt;code&gt;std::vector&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;Incremental append: Multiple allocations, multiple per-item operations&lt;/h2&gt;

&lt;p&gt;Consider a simple case where we want to use a vector &lt;code&gt;init&lt;/code&gt; containing the integers 0 through 4, inclusive, to build a &lt;code&gt;vector&lt;/code&gt;, using the &lt;code&gt;back_inserter()&lt;/code&gt; approach:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
           &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Here is an annotated sequence of the constructions, copies, and destructions required to append the five instances of &lt;code&gt;C&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;New collection c1
// Append C(0, 0)
Basic constructor for T0
[vector allocates space for C value, c1[0]]
Move constructor for c1[0] from T0
Destructor for T0

// Append C(1, 1)
Basic constructor for T0
[Vector allocates space for C values, c1[0]' to c1[1]']
Move constructor for c1[1]' from T0
Copy constructor for c1[0]' from c1[0]
Destructor for c1[0]
Destructor for T0
[Space for c1[0] deallocated]

// Append C(2, 2)
Basic constructor for T0
[Vector allocates space for C values, c1[0]'' to c[3]'']
Move constructor for c1[2]'' from T0
Copy constructor for c1[0]'' from c1[0]'
Copy constructor for c1[1]'' from c1[1]'
Destructor for c1[0]'
Destructor for c1[1]'
[Space for c1[0]' to c1[1]' deallocated]
Destructor for T0

// Append C(3, 3)
Basic constructor for T0
Move constructor for c1[3]'' from T0
Destructor for T0

// Append C(4, 4)
Basic constructor for T0
[Vector allocates space for C values, c1[0]''' to c1[4]''']
Move constructor for c1[4]''' from T0
Copy constructor for c1[0]''' from c1[0]''
Copy constructor for c1[1]''' from c1[1]''
Copy constructor for c1[2]''' from c1[2]''
Copy constructor for c1[3]''' from c1[3]''
Destructor for c1[0]''
Destructor for c1[1]''
Destructor for c1[2]''
Destructor for c1[3]''
[Space for c1[0]'' to c1[3]'' deallocated]
Destructor for T0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Whoa!  That’s a lot of action. Every append requires creating a temporary &lt;code&gt;C&lt;/code&gt; value, &lt;code&gt;T0&lt;/code&gt;, which is destroyed once the append has completed. The vector allocates four progressively larger blocks (enough for 1 C value, 2 C values, 4 C values, and a final block at least 5 C values large) as its required capacity grows. Each time it expands, it copies the old values into the new block, then destroys the originals and deallocates the old block. For this class, the constructors, copies, and destructors are efficient, but they might require substantial CPU time for larger classes. And for any class size, the allocation / deallocation pairs contribute to memory fragmentation. Can we do better?&lt;/p&gt;

&lt;h2&gt;Initialize and assign: Single allocation, two per-item constructions&lt;/h2&gt;

&lt;p&gt;The first idiom required multiple allocations and deletions because we built the vector an item at a time, expanding as more values were added. Given that the number of items of the result will be exactly the number in &lt;code&gt;init&lt;/code&gt;, we could initialize the result vector to its full length and then build the new values there. When we construct the initial vector of five values, however, it will construct default values for every entry. When we build the result, we will be overwriting those default values with an assignment. Here is the code:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The algorithm needs to maintain two iterators, one each for the source &lt;code&gt;init&lt;/code&gt; and the sink &lt;code&gt;c2&lt;/code&gt;, so I chose a &lt;code&gt;for&lt;/code&gt; loop rather than the &lt;code&gt;std::copy&lt;/code&gt; algorithm. With some effort, you could build a custom assign-to-the-end-iterator and use &lt;code&gt;std::copy&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here’s the resulting operation sequence:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[Vector allocates space for at least 5 values, c2[0] to c2[4]]
Default constructor for c2[0]
Default constructor for c2[1]
Default constructor for c2[2]
Default constructor for c2[3]
Default constructor for c2[4]
New collection c2 // The collection is now initialized

// Append C(0, 0)
Basic constructor for T0
Move assignment for c2[0] from T0
Destructor for T0

// Append C(1, 1)
Basic constructor for T0
Move assignment for c2[1] from T0
Destructor for T0

// Append C(2, 2)
Basic constructor for T0
Move assignment for c2[2] from T0
Destructor for T0

// Append C(3, 3)
Basic constructor for T0
Move assignment for c2[3] from T0
Destructor for T0

// Append C(4, 4)
Basic constructor for T0
Move assignment for c2[4] from T0
Destructor for T0
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This idiom requires substantially fewer operations on &lt;code&gt;C&lt;/code&gt; values and has exactly one allocation, of exactly the required size. Because we’re assigning an &lt;a href=&quot;http://en.cppreference.com/w/cpp/language/value_category&quot;&gt;r-value&lt;/a&gt; in Line 4 and class &lt;code&gt;C&lt;/code&gt; includes a &lt;a href=&quot;http://en.cppreference.com/w/cpp/language/move_assignment&quot;&gt;move assignment &lt;/a&gt; member, move assignment is used. For this class whose members are all &lt;code&gt;int&lt;/code&gt;s, there is no performance improvement from move assignment, but it might be much more efficient for instances of a class that owns resources such as dynamic memory.&lt;/p&gt;

&lt;p&gt;This looks like a win, overall. We’ve saved a lot of operations and used the bare minimum of allocations. The “extra” operations left, construction of a default value and move assignment, are both typically fast. The only downside is that we have to maintain two iterators, using a more complex &lt;code&gt;for&lt;/code&gt; or a custom adaptor to subsume the iterator. Is there a way we can do even better?&lt;/p&gt;

&lt;h2&gt;Reserve and emplace: Single allocation, single per-item construction&lt;/h2&gt;

&lt;p&gt;The remaining inefficiency in the second idiom is that we construct a sequence of default values that we never need and will overwrite as soon as the collection is ready. What we really want to do is simpler than that: Have the collection allocate all the storage we need and then construct our values directly in that storage.&lt;/p&gt;

&lt;p&gt;This approach became viable in 2011 with the addition of &lt;em&gt;emplace members&lt;/em&gt; to the STL collections (this feature in turn was enabled by the C++ 2011 core language addition of &lt;a href=&quot;http://en.cppreference.com/w/cpp/language/parameter_pack&quot;&gt;template parameter packs&lt;/a&gt;). In particular, the&lt;code class=&quot;highlighter-rouge&quot;&gt; emplace_back()&lt;/code&gt; member constructs a value directly after the last value in the collection. If there is allocated space available after the last value, the appended value is simply constructed there, but if the vector is full, the same allocate-copy-deallocate sequence as the first method must be used.&lt;/p&gt;

&lt;p&gt;This suggests the following pattern:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;reserve space in the vector sufficient to hold all items
build the items using emplace_back()
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;In C++:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Once again, rather than build a custom iterator, I have used a &lt;code&gt;for&lt;/code&gt; loop to iterate over the source and used &lt;code&gt;emplace_back()&lt;/code&gt; in the loop body to append to the sink. Here’s the operations this code produces:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;New collection c3
[Vector allocates space for at least 5 values, c3[0] to c3[4]]
Basic constructor for c3[0]
Basic constructor for c3[1]
Basic constructor for c3[2]
Basic constructor for c3[3]
Basic constructor for c3[4]
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Using &lt;code&gt;emplace_back()&lt;/code&gt;, we have built the result using the minimum number of allocations and operations on the &lt;code&gt;C&lt;/code&gt; values. In tradeoff, we can no longer use simple STL algorithms unless we use some form of  &lt;code&gt;back_emplacer&lt;/code&gt; adaptor. Although none is provided in the 2017 STL, Andre Tomazos has &lt;a href=&quot;http://stackoverflow.com/questions/18728257/back-emplacer-implementation-default-operator-vs-universal-reference-version&quot;&gt;presented a solution&lt;/a&gt; in a Stack Overflow discussion.&lt;/p&gt;

&lt;h2&gt;Explicit storage management increases programmer load&lt;/h2&gt;

&lt;p&gt;The current version of the STL forces programmers to make a Faustian choice when implementing list comprehension-style algorithms: Use the simple, well-supported longstanding approach and accept potential inefficiencies, or use the more recent emplace members, gaining efficiency at some cost in code complexity.  The biggest cost of all of this is the decision itself. Where the Python or Haskell programmer simply specifies list operations, the C++ programmer must stop for every sink, whether an intermediate result or the final value, and choose an append idiom.&lt;/p&gt;

&lt;p&gt;As I noted in an earlier post, it is not clear to me that good modern compilers, whether static or just-in-time, cannot produce equally efficient code from list comprehensions as a C++ compiler produces from the more complex STL approach. I have the sad suspicion that this is a case where C++’s emphasis on explicit storage management increases programmer load for little to no efficiency benefit.&lt;/p&gt;

&lt;h2&gt;Appendix: Full source&lt;/h2&gt;

&lt;p&gt;Here is the full source from which the annotated operation displays were produced. The instrumentation code is just functional enough to produce useful results with one specific compiler and library release. It is far from general code. Specific caveats about the instrumentation code:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The actual output from this code is more raw than the annotated versions given above. I derived the presentation versions from the output of this code.
&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;is_stack()&lt;/code&gt; function is highly specific to the implementation and specific runtime options such as stack size. It is nothing close to general production use.
&lt;/li&gt;
&lt;li&gt;The instrumentation functions call &lt;code&gt;std::vector::data()&lt;/code&gt; during updates to the vector. The function's behaviour in such cases is undefined. For this compiler and library version, it returned the address of the old allocation. In other circumstances, it might behave differently.
&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cm&quot;&gt;/*
  Demonstration of different approaches to building a vector.
 */&lt;/span&gt;

&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;algorithm&amp;gt;
#include &amp;lt;cassert&amp;gt;
#include &amp;lt;iostream&amp;gt;
#include &amp;lt;list&amp;gt;
#include &amp;lt;sstream&amp;gt;
#include &amp;lt;string&amp;gt;
#include &amp;lt;vector&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;experimental/iterator&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostringstream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;experimental&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;make_ostream_joiner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps_del&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
  Class to make creation, assignment, and destruction visible.
 */&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Basic constructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Copy constructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; from &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;// Replace above with this to test with only move constructor
&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;//C (const C&amp;amp; c) = delete;
&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Move constructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; from &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Default constructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Copy assignment for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; from &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Move assignment for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot; from &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Destructor for &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;temps_del&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;friend&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ostream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;C (&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;)&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Coll&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
  Instrumentation to attribute locations to owning collection.
  One-off code---specific to this demonstration and tool chain.
 */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;ostringstream&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Cpair&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Coll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Cpair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colls&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;struct&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Tpair&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tpair&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;temps_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;find_if&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
		 &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;colls_add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Coll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;colls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Cpair&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;coll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;New collection &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, base &quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;coll&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;temps_add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;temps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;push_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Tpair&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
  Highly specific to implementation, memory model, and so forth!
 */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;bool&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;is_stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;reinterpret_cast&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;unsigned&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mh&quot;&gt;0x700'000'000'000UL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;temps_del&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;is_stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;temps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;erase&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;temps_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps_find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;T&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;temps_add&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;collection_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;colls&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;capacity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;[&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;]&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
	&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;?&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; [&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;to_string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;]&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temps_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;cm&quot;&gt;/*
  Demonstrate three ways to build a result vector.
 */&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;constexpr&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;generate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mutable&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Source vector: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_ostream_joiner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Default vector, back_inserter:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Coll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;colls_add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;c1&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
	     &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Result: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_ostream_joiner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Default values of required length, assigned&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Coll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;colls_add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;c2&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;();&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Result: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_ostream_joiner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Reserved vector, emplace_back&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;Coll&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;colls_add&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;c3&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reserve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;());&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;emplace_back&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;Result: &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_ostream_joiner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Destructors called as collections go out of scope:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Iterators aren’t the problem, they just enable it</title>
   <link href="/2017/03/03/iterators-arent-the-problem-they-just-enable-it/"/>
   <updated>2017-03-03T00:00:00-08:00</updated>
   <id>/2017/03/03/iterators-arent-the-problem-they-just-enable-it</id>
   <content type="html">&lt;p&gt;The post presenting the &lt;a href=&quot;/2017/02/22/iterators-a-failure-case/&quot;&gt;failure case for iterators&lt;/a&gt; contrasted this simple Python list comprehension:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;with its C++ equivalent using the STL:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;copy_if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
               &lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The list comprehension reduces the notation to the essentials of the algorithm: The source &lt;code&gt;a&lt;/code&gt; and sink &lt;code&gt;res&lt;/code&gt; are each mentioned once, while the code presents the transformations of an individual value &lt;code&gt;i&lt;/code&gt; on its way from source to sink.&lt;/p&gt;

&lt;p&gt;By contrast, the STL version obscures the transformation of &lt;code&gt;i&lt;/code&gt;, reducing it to the parameter of two lambda expressions. The bulk of the C++ code is concerned with the source, sink, and the intermediate result &lt;code&gt;t1&lt;/code&gt;. For each step, the programmer must specify the start and end of the range, decide whether the range is immutable (&lt;code&gt;cbegin()/cend()&lt;/code&gt;) or mutable (&lt;code&gt;begin()/end()&lt;/code&gt;), the class of transformation (&lt;code&gt;copy_if&lt;/code&gt; or &lt;code&gt;transform&lt;/code&gt;), the specifics of the transformation (via lambda expressions for the filter and and the square), and the extension strategy for the sink for each transformation (in this case, a &lt;code&gt;back_inserter&lt;/code&gt;). That’s a lot of details. Indeed, the actual transformations performed, so elegantly phrased in the list comprehension, are secondary in the STL version, for which the &lt;em&gt;traversal mechanics&lt;/em&gt; are the primary focus.&lt;/p&gt;

&lt;p&gt;The classic defence of designs requiring detailed specification of the mechanics is that they permit more efficient code. Certainly the STL version permits gcc 6.2 to generate great code (see the post linked above). It is much harder to determine whether the list comprehension will &lt;em&gt;inevitably&lt;/em&gt; generate less efficient code. In statically-typed languages such as Haskell, the compiler has the same type information about the source and sink as C++. In just-in-time compiled languages such as JavaScript, the compiler can generate code for the source and sink types actually encountered in program runs. In both cases, the compiler has greater flexibility in how intermediate results are stored than the C++ compiler because the intermediate representation is left entirely to the compiler rather than specified by the programmer. I wouldn’t bet against a modern compiler to generate as efficient code for the list comprehension as the C++ compiler generates for the STL version.&lt;/p&gt;

&lt;p&gt;Even for environments in which list comprehensions do not generate comparable code, for small lists the inefficiency is irrelevant outside tight inner loops. If a programmer can whip off simple code to transform small lists in the less-frequent sections of code, they have more time to optimize the code that genuinely slows the system.  Execution efficiency is not an absolute virtue but only a requirement for code that contributes substantively to execution time.&lt;/p&gt;

&lt;p&gt;The STL code is especially inefficient in terms of programmer time. Each decision requires at least momentary attention from the programmer. Each feature that the programmer is required to specify incurs a cognitive load for that decision. Some of those decisions can be subsumed into idioms—for example, always specifying &lt;code&gt;const_iterator&lt;/code&gt;s (via &lt;code&gt;cbegin()/cend()&lt;/code&gt;) for the source range in a &lt;code&gt;copy()&lt;/code&gt; or &lt;code&gt;copy_if()&lt;/code&gt; algorithm, but these idioms are highly local. For example, you must specify regular, mutable iterators (via &lt;code&gt;begin()/end()&lt;/code&gt;) for the range passed to &lt;code&gt;generate()&lt;/code&gt;. Idioms only mitigate the load incurred by all these decisions, they do not eliminate it.&lt;/p&gt;

&lt;p&gt;The decisions required of a programer writing the code are mirrored by the questions that must be answered by any programmer reading the code. Although the process is somewhat different, the result is similar: Code that specifies that many choices is harder to read than code that merely implies them.&lt;/p&gt;

&lt;h2&gt;The complexity arises from &lt;em&gt;designing around&lt;/em&gt; iterators&lt;/h2&gt;

&lt;p&gt;I have framed this discussion in terms of iterators but iterators themselves are not causing the complexity. The &lt;a href=&quot;/2017/02/21/iterators-one-success-story/&quot;&gt;successful case&lt;/a&gt; showed that with the right syntactic sugar, an iterator-based approach could be equivalently clear and terse as the list comprehension approach. But the syntactic sugar of ranged &lt;code&gt;for&lt;/code&gt; only addresses a small set of requirements. The moment we move outside that range, we have to specify traversal rules and containers for intermediate results.&lt;/p&gt;

&lt;p&gt;The complexity of the STL approach arises from the very core of the STL design:  by separating containers from algorithms and linking them via the category of iterators supported by a given container, the design &lt;em&gt;forces&lt;/em&gt; the programmer to consider all three parts. The designer can simplify around the edges but the core complexity remains irreducible. Iterators are a cool idea but designing collections and algorithms around them seems to inevitably make the resulting design complex to use.&lt;/p&gt;

&lt;p&gt;There is one particular piece of the puzzle that is complex enough to warrant its own post. I’ve alluded several times to the choice of how to actually add results to the sinks. This is a use case where C++’s insistence on explicit allocation and construction of values goes from a strength to a liability. I’ll tackle this point in the next post.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The genius insight behind iterators</title>
   <link href="/2017/03/01/the-genius-insight-behind-iterators/"/>
   <updated>2017-03-01T00:00:00-08:00</updated>
   <id>/2017/03/01/the-genius-insight-behind-iterators</id>
   <content type="html">&lt;p&gt;The story so far:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;List comprehensions and related techniques such as LINQ are a widely-used, well-adopted notation. They are part of the current consensus on programming language features.
&lt;/li&gt;
&lt;li&gt;C++ and the STL provide the basic mechanisms for implementing list comprehensions.&lt;/li&gt;
&lt;li&gt;In the simple cases addressed by the C++ ranged &lt;code&gt;for&lt;/code&gt; loop, C++/STL can be as concise as a list comprehension.&lt;/li&gt;
&lt;li&gt;For more complex cases, the C++/STL patterns that address the same use cases as list comprehensions are far more verbose than their Python or Haskell equivalents, introducing many running details and requiring a different focus by the programmer.&lt;/li&gt;
&lt;li&gt;The syntax of C++ lambdas is not the source of this syntactic complexity. Although the full syntax and semantics of lambdas is subtle, the idioms used in actual code (and the examples used to compare with Python list comprehensions) are simple.
&lt;/li&gt;
&lt;li&gt;We need to look at other components of the C++/STL design for sources of the complexity.
&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Several mechanisms are provided by C++/STL (I write it this way to emphasize that it is a combined design of features provided by the core C++ language and by the Standard Template Library) to support this sort of algorithm:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/container&quot;&gt;STL containers&lt;/a&gt; hold data. Different containers support different patterns of efficient access.
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm&quot;&gt;STL algorithms&lt;/a&gt; satisfy commonly-useful requirements for processing collections of data, assuming that the data can be accessed efficiently in one or more patterns.
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/language/range-for&quot;&gt;C++ ranged &lt;code&gt;for&lt;/code&gt; loops&lt;/a&gt; provide a concise notation for the special case of single-pass sequential iteration through any STL container.
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/language/lambda&quot;&gt;C++ lambda expressions&lt;/a&gt; provide a concise notation for customizing algorithms with one-off provisions such as filters, accumulators, and so forth.
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/language/templates&quot;&gt;C++ templates&lt;/a&gt; provide a mechanism for using the access patterns of a collection to select the most appropriate implementation of an algorithm to use with that collection.
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/iterator&quot;&gt;STL iterators&lt;/a&gt; provide specified patterns of efficient access.
&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That last component, iterators, are the STL’s genius contribution to computing. Whether or not you find the C++/STL combination comfortable to use, it is worth learning the approach because it provides a uniquely visible mechanism for a principle connecting data structures and algorithms in any language:&lt;/p&gt;

&lt;p style=&quot;margin-left:2em;&quot;&gt;
Data structures support patterns of efficient access. Algorithms depend upon specific patterns of efficient access. &lt;em&gt;STL iterators are an explicit representation of the access patterns connecting a data structure (container) and an algorithm.&lt;/em&gt;
&lt;/p&gt;

&lt;p&gt;To illustrate this connection, consider the classic binary search algorithm over a collection. As typically presented, this algorithm presupposes constant-time access to a random element with the collection from any other element. In principle, you can run a binary search on a singly-linked list, but the classical performance guarantees of binary search will not be met: The number of element accesses would increase linearly with the size of the array, rather than the predicted logarithmic increase. You might even get fewer element accesses with linear search. The poor performance arises because a singly-linked list does not support efficient constant-time access from any one element to any other. A container that stores its elements contiguously, such as &lt;a href=&quot;http://en.cppreference.com/w/cpp/container/array&quot;&gt;array&lt;/a&gt; or &lt;a href=&quot;http://en.cppreference.com/w/cpp/container/vector&quot;&gt;vector&lt;/a&gt;, is required for the binary search algorithm to achieve its classical guarantees.&lt;/p&gt;

&lt;p&gt;The STL &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/binary_search&quot;&gt;binary search algorithm&lt;/a&gt; takes advantage of iterators to run on both linked lists and vectors.  It uses the most efficient access pattern supported by the container.
I’ll return to this below.&lt;/p&gt;

&lt;p&gt;In discussions of data structures and algorithms, as well as most implementations of them, the access patterns linking the two are left implicit. Making that link explicit was a brilliant insight and a contribution to the computing field from the STL design.&lt;/p&gt;

&lt;h2&gt;The common iterator access patterns&lt;/h2&gt;

&lt;p&gt;Iterators are &lt;a href=&quot;http://en.cppreference.com/w/cpp/iterator&quot;&gt;categorized&lt;/a&gt; according to  the efficient access patterns they support. The full set of categories is complex and their distinctions are subtle; I’ll just list three common ones and summarize each informally.&lt;/p&gt;

&lt;dl&gt;
&lt;dt&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/concept/ForwardIterator&quot;&gt;&lt;code&gt;ForwardIterator&lt;/code&gt;&lt;/a&gt;
&lt;/dt&gt;
&lt;dd&gt;Given an element, access to its immediate successor. If you make a copy of the iterator, the copy will generate the same sequence of accesses as the original. (This last point is a rephrasing of the &quot;multi-pass&quot; requirement.)
&lt;/dd&gt;
&lt;dt&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/concept/BidirectionalIterator&quot;&gt;&lt;code&gt;BidirectionalIterator&lt;/code&gt;&lt;/a&gt;
&lt;/dt&gt;
&lt;dd&gt;Given an element, access to its immediate predecessor &lt;em&gt;and successor&lt;/em&gt;. A copy of the iterator will generate the same sequence of accesses as the original.
&lt;/dd&gt;
&lt;dt&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/concept/RandomAccessIterator&quot;&gt;&lt;code&gt;RandomAccessIterator&lt;/code&gt;&lt;/a&gt;
&lt;/dt&gt;
&lt;dd&gt;Given en element, &lt;em&gt;constant-time&lt;/em&gt; access to &lt;em&gt;any other&lt;/em&gt; element. A copy of the iterator will generate the same sequence of accesses as the original.
&lt;/dd&gt;
&lt;/dl&gt;

&lt;p&gt;Note that &lt;code&gt;ForwardIterator&lt;/code&gt; and &lt;code&gt;BidirectionalIterator&lt;/code&gt; technically only specify which access patterns will be &lt;em&gt;inefficient&lt;/em&gt;: Given an iterator that only supports successor (and predecessor in the bidirectional case), moving more than one element requires iterating through all intervening elements. The efficiency of the basic successor/predecessor operations is determined by the underlying data structure; in all the standard collections it is constant irrespective of the collection size.&lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://en.cppreference.com/w/cpp/iterator&quot;&gt;full list of categories&lt;/a&gt; is longer and the requirements more detailed. The above list captures the common distinctions.&lt;/p&gt;

&lt;h2&gt;Example: The STL Binary search algorithm&lt;/h2&gt;

&lt;p&gt;The performance of the &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/binary_search&quot;&gt;STL binary search algorithm&lt;/a&gt; depends upon the category of iterators that it is passed. Its minimal requirement is a &lt;code&gt;ForwardIterator&lt;/code&gt;, which only supports the basic successor operation and whose copies are guaranteed to produce an identical sequence. This last point is essential for the algorithm to work without access to a predecessor operation: Rather than iterating backward, it retains a copy of the iterator to the lowest point in the search range and iterates &lt;em&gt;forward&lt;/em&gt; from there.&lt;/p&gt;

&lt;p&gt;The binary search algorithm guarantees comparisons proportional to the log of the collection size for any collection supporting &lt;code&gt;ForwardIterator&lt;/code&gt;s or better but the number of &lt;em&gt;element accesses&lt;/em&gt; depends upon the category of iterators provided by the collection. For collections supporting &lt;code&gt;RandomAccessIterator&lt;/code&gt;s, which permit computation of a midpoint iterator in constant time, the algorithm guarantees logarithmic number of element accesses.  However for collections that only support &lt;code&gt;ForwardIterator&lt;/code&gt;s, such as a linked list, the algorithm guarantees accesses proportional &lt;em&gt;linearly&lt;/em&gt; to the collection size. If comparisons are particularly expensive, this may still make &lt;code&gt;binary_search()&lt;/code&gt; more efficient than simple linear search for a linked list, even though both algorithms are linear in number of accesses. (In many cases, the binary search algorithm will require more accesses than linear search, due to its initial scan over all elements, so binary search’s saving in comparison time will have to be particularly big to make it faster.)&lt;/p&gt;

&lt;p&gt;This flexibility is enabled by the C++ template facility. The library selects a different implementation of binary search depending upon the category of iterator that it is passed. The iterator category in turn is determined by the collection, which exports the iterators representing the best access patterns that it supports.&lt;/p&gt;

&lt;p&gt;This design allows the library to choose the best possible algorithm for a given collection, without the programmer explicitly choosing that algorithm:&lt;/p&gt;

&lt;!-- highlight=&quot;18,19&quot; --&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals_v&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;generate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vals_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mutable&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;forward_list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals_l&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vals_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;make_back_inserter_fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vals_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  
  &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vals_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;make_ostream_joiner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vals_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;make_ostream_joiner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binary_search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vals_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;binary_search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vals_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vals_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The highlighted lines are the two calls to &lt;code&gt;std::binary_search()&lt;/code&gt;. The first runs on &lt;code&gt;std::vector vals_v&lt;/code&gt;, which provides &lt;code&gt;RandomAccessIterator&lt;/code&gt; iterators, while the second runs on &lt;code&gt;std::forward_list vals_l&lt;/code&gt;, which provides &lt;code&gt;ForwardIterator&lt;/code&gt; iterators. Assuming the two containers have the same contents, both calls will perform comparable numbers of comparisons (logarithmic in the number of elements) but the call on the &lt;code&gt;forward_list&lt;/code&gt; will perform far more element accesses (linear rather than logarithmic).&lt;/p&gt;

&lt;h2&gt;So why are iterators so tedious to use?&lt;/h2&gt;

&lt;p&gt;Iterators are a method for containers to explicitly represent their favoured access patterns, allowing algorithms to optimize their behaviour for those patterns. This is a genuinely novel idea and one that will change how you program once you have used it enough to be comfortable with it.&lt;/p&gt;

&lt;p&gt;Yet the example &lt;a href=&quot;/2017/02/22/iterators-a-failure-case/&quot;&gt;failure case&lt;/a&gt; highlighted the tediousness of the iterator approach versus the simplicity of list comprehensions. What is the source of the problem? As with so many complexities of C++ code, it stems from the language’s insistence that you state where and how every value is stored. I’ll turn to that topic in the next post.&lt;/p&gt;

&lt;h2&gt;Appendix: &lt;code&gt;class back_inserter_fl&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;The sample program uses a class &lt;code&gt;back_inserter_fl&lt;/code&gt; I wrote, together with a convenience function for creating it, &lt;code&gt;make_back_inserter_fl()&lt;/code&gt;.  The STL &lt;a href=&quot;http://en.cppreference.com/w/cpp/iterator/back_inserter&quot;&gt;&lt;code&gt;std::back_inserter()&lt;/code&gt;&lt;/a&gt; adaptor requires that the underlying container have a &lt;code&gt;push_back()&lt;/code&gt; member.  The &lt;code&gt;forward_list&lt;/code&gt; cannot support such a function because it has no tail pointer. Building a back inserter for a &lt;code&gt;forward_list&lt;/code&gt; is tricky because assignment to the iterator also creates an iterator that will be the location of the next assignment.&lt;/p&gt;

&lt;p&gt;I think the following code is pretty close to meeting all the formal requirements but I have neither checked it nor tested in exhaustively.  I’m including it here for completeness—check carefully before using it in any production code.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;back&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_inserter_fl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterator_category&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward_iterator_tag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pointer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reference&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;difference_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;difference_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;proxy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;public&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;proxy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
	   &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bi_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;fl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fl_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;bi&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bi_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;value_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value_type&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;insert_after&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;bi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_it&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;_L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fl_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
                                &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fl_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;before_begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;default&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;proxy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;proxy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;  &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;operator&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;this&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;private&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;_L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nullptr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iterator&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;it&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;template&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;typename&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_back_inserter_fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward_list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter_fl&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward_list&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;_T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fl&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Lambdas: Typical use cases</title>
   <link href="/2017/02/25/lambdas-typical-use-cases/"/>
   <updated>2017-02-25T00:00:00-08:00</updated>
   <id>/2017/02/25/lambdas-typical-use-cases</id>
   <content type="html">&lt;p&gt;My last post, highlighting the differences between C++ lambdas and the lambdas in languages based upon functional programs, went more deeply into the weeds than I had intended. I realized too late that it cried out for examples.  The rules for declaring free variables (the member variables of the anonymous class) in C++ lambdas can seem contorted but most uses of them fall into one of a few simple types.  In this post, I want to present three simple use cases of C++ lambdas, each demonstrating a different way to use free variables.&lt;/p&gt;

&lt;h2&gt;Copy-constructed constant values&lt;/h2&gt;

&lt;p&gt;Perhaps the most common use of free variables, in all languages, is to pass in some parameters to guide the lambda’s algorithm.  For example, a filter function might be passed parameters specifying the filter range.  Here’s a simple example of a min/max filter over an integer vector:&lt;/p&gt;

&lt;!-- highlight=&quot;5&quot;--&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Copy-construct const values
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filter&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minimum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;copy_if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;minimum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;[=]&lt;/code&gt; lambda prefix specifies that all free variables in the lambda expression are copy-initialized from the surrounding context and never modified in the execution of the filter. The free variables &lt;code&gt;minimum&lt;/code&gt; and &lt;code&gt;maxiumum&lt;/code&gt; are initialized from the function parameters of the same name.&lt;/p&gt;

&lt;p&gt;This pattern is so common that you could spend an entire career and prefix every single lambda you use with the &lt;code&gt;[=]&lt;/code&gt; prefix.&lt;/p&gt;

&lt;h2&gt;Reference mutable variables&lt;/h2&gt;

&lt;p&gt;Another common use case (although less common than copy-constructed immutables) is to update variables in the surrounding context. In this example,&lt;/p&gt;

&lt;!-- highlight=&quot;5&quot;--&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Reference mutable values
&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;accum&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;for_each&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;[&amp;amp;]&lt;/code&gt; lambda prefix specifies that all free variables in the lambda expression will be references to correspondingly-named variables in their surrounding context.  In this case, &lt;code&gt;sum&lt;/code&gt; is used to retain the running accumulated sum across calls of the lambda.  The function then returns the accumulated total.&lt;/p&gt;

&lt;p&gt;By the way, if you actually want to accumulate values, it is preferable to use &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/accumulate&quot;&gt;&lt;code&gt;std::accumulate&lt;/code&gt;&lt;/a&gt; or &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/reduce&quot;&gt;&lt;code&gt;std::reduce&lt;/code&gt;&lt;/a&gt;, which address this requirement directly. In particular, &lt;code&gt;std::reduce&lt;/code&gt; has parallel variants that exploit multi-core and multi-processor architectures.&lt;/p&gt;

&lt;h2&gt;Mutable local variable&lt;/h2&gt;

&lt;p&gt;A less common use case is a lambda that needs a local variable. The lambda syntax permits the declaration of locals that do not correspond to any variables in the containing context. An example of such a case is a function that, given a vector, returns a vector of (index, value) tuples, similar to Python’s &lt;a href=&quot;https://docs.python.org/3/library/functions.html#enumerate&quot;&gt;&lt;code&gt;enumerate&lt;/code&gt;&lt;/a&gt; function:&lt;/p&gt;

&lt;!-- highlight=&quot;6&quot; --&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Mutable local
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec_pair&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vec_pair&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;vec_pair&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;mutable&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_tuple&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ind&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The &lt;code&gt;[ind=0]&lt;/code&gt; lambda prefix defines a local variable &lt;code&gt;ind&lt;/code&gt; whose type and initial value is determined by &lt;code&gt;=0&lt;/code&gt;. &lt;code&gt;ind&lt;/code&gt; is a member variable of the lambda object, unneeded outside that context. Note that unlike the other two cases, there is no variable &lt;code&gt;ind&lt;/code&gt; declared in the surrounding context. Note also the &lt;code&gt;mutable&lt;/code&gt; declaration; lambdas with private local variables are virtually the only use case that you will need to declare the lambda &lt;code&gt;mutable&lt;/code&gt;. (The use of the &lt;code&gt;mutable&lt;/code&gt; keyword in lambdas is unrelated to its distinct use as a &lt;a href=&quot;http://en.cppreference.com/w/cpp/language/cv&quot;&gt;qualifier for non-static member variables&lt;/a&gt; of a class.)&lt;/p&gt;

&lt;h2&gt;More general cases&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;http://en.cppreference.com/w/cpp/language/lambda&quot;&gt;full lambda syntax&lt;/a&gt; permits far more general definitions of member variables for the lambda object than these simple cases. I believe the overwhelming majority of uses fall into one of these types, though. You can go a long, long time without writing a lambda prefix more complicated than these three cases.&lt;/p&gt;

&lt;h2&gt;Summary&lt;/h2&gt;

&lt;p&gt;Although the full syntax of C++ lambdas is complex, nearly all use cases fall in one of a small set of simple cases. The syntax allows these cases to be expressed concisely, in a context (expressions) where concision is a real benefit. It does take some time to become sufficiently familiar with the possibilities to take advantage of these simple cases, though.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Lambdas: Sweet, sweet syntactic sugar</title>
   <link href="/2017/02/23/lambdas-sweet-sweet-syntactic-sugar/"/>
   <updated>2017-02-23T00:00:00-08:00</updated>
   <id>/2017/02/23/lambdas-sweet-sweet-syntactic-sugar</id>
   <content type="html">&lt;p&gt;&lt;b&gt;Update:&lt;/b&gt; The &lt;a href=&quot;/2017/02/25/lambdas-typical-use-cases/&quot;&gt;next post&lt;/a&gt; provides recipes for common use cases of lambdas.  If parts of this post seem too abstract, you might find the examples in the next post clarify things.&lt;/p&gt;

&lt;p&gt;STL iterators and algorithms really can’t be discussed without also talking about lambdas. Although the STL design predates the introduction of lambdas by almost two decades, the introduction of lambdas in C++ 2011 improved the usability of STL algorithms substantially.  I don’t have statistics but I presume that the STL algorithms now receive substantially more use due to the greater simplicity of passing callbacks as lambdas rather than instances of named classes. Lambdas are purely a matter of convenience—they introduce nothing to the language that you couldn’t do before—but by making common use cases more convenient, they effectively extend the range of use cases where calling a standard algorithm makes sense.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;Programmers accustomed to languages like Python, JavaScript, or Scheme might counter that C++ lambdas retain an awkward complexity compared to the corresponding facilities in the other languages. What’s up with the by-value and by-reference free variables, and the &lt;code&gt;mutable&lt;/code&gt; keyword?  Scheme gets on fine without those. Ah, [and here the Python/JavaScript/Scheme … programmer smiles good-naturedly at their benighted C++-using colleague] it’s just that C++ programmers seem to &lt;em&gt;revel&lt;/em&gt; in a foolish complexity. But [shrug] what can you do?&lt;/p&gt;

&lt;p&gt;I’m not ready—yet—to defend or critique the concrete syntax of C++ lambdas but I think we need to understand that a C++ lambda has been delegated a greater responsibility by the core language than a Scheme lambda.  Where lambdas in Python, JavaScript and Scheme all define &lt;em&gt;anonymous functions&lt;/em&gt;, lambdas in C++ define &lt;em&gt;an instance of an anonymous callable class&lt;/em&gt;.  The same issues must arise in Java and C#, though I am unfamiliar with the specifics of their solutions. Analyzing the design of C++ lambdas will help us understand a deep distinction between it (and its object-oriented cousins Java and C#) and languages like Python, JavaScript, and Scheme.&lt;/p&gt;

&lt;h2&gt;Who builds the closure: The language or a class constructor?&lt;/h2&gt;

&lt;p&gt;Consider the Python lambda expression&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Variable &lt;code&gt;i&lt;/code&gt; is a parameter, while &lt;code&gt;c&lt;/code&gt; is a free variable.  Whenever a language permits lambdas—indeed, whenever a language permits defining functions of any sort inside another function—its designers have to make two decisions regarding free variables:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What is their scope?&lt;/li&gt;
&lt;li&gt;How are they bound to values at runtime?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Scheme was one of the first languages to recognize the depth of these questions and to answer them in a coordinated, elegant way. In fact, the designers consider these choices to be so foundational to the language that the &lt;em&gt;first substantive paragraph&lt;/em&gt; of the language’s defining document reads, &lt;a href=&quot;https://docs.racket-lang.org/r6rs/r6rs-std/r6rs-Z-H-4.html&quot;&gt;in its entirety&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
Following Algol, Scheme is a statically scoped programming language. Each use of a variable is associated with a lexically apparent binding of that variable.
&lt;/blockquote&gt;

&lt;p&gt;Python adopts the same rules, so I’ll illustrate with Python code:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;What value will this print?  It depends upon whether the free &lt;code&gt;c&lt;/code&gt; in the lambda expression binds to the parameter &lt;code&gt;c&lt;/code&gt; (line 1), whose value is 2, or the global &lt;code&gt;c&lt;/code&gt; (line 5), whose value is 1. Python uses Scheme’s notion of “lexically apparent binding”, binding the free &lt;code&gt;c&lt;/code&gt; to the parameter &lt;code&gt;c&lt;/code&gt; and printing &lt;code&gt;0, 2, 4, 6&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;This choice makes &lt;a href=&quot;https://en.wikipedia.org/wiki/Higher-order_function&quot;&gt;higher-order functions&lt;/a&gt; more useful but it complicates the language runtime. In particular, local variables can no longer be stored on a stack and require more elaborate storage management.&lt;/p&gt;

&lt;p&gt;If your spidey-sense tingled at the phrase, “more elaborate storage management”, you have a strong intuition for C++. The language’s designers are unlikely to adopt a semantics that presumes “elaborate storage management”. But the choice is much broader than just lambda semantics; it is a choice of whether the binding of names to values is handled by the language or the programmer.&lt;/p&gt;

&lt;p&gt;(&lt;strong&gt;Aside:&lt;/strong&gt; A couple of notes about Python: First, Python lambdas are deliberately restricted compared to those of every other language I describe here. Those restrictions don’t limit them in the context here of list comprehensions and higher-order list functions such as &lt;a href=&quot;https://docs.python.org/3/library/functions.html#map&quot;&gt;&lt;code&gt;map&lt;/code&gt;&lt;/a&gt;.  Second, Python’s name-value binding is a hybrid of object-oriented and functional. Scheme represents a purer exemplar of what I describe but fewer people know that language. Again, within the context of list comprehensions, Python’s free variable bindings exemplify the differences I describe here, even if the overall language does not.)&lt;/p&gt;

&lt;p&gt;In programming language theory, the data structure binding names to values is called an environment. In Scheme, Haskell, and other languages with a strong functional programming basis, the environment is managed by the language and programmers never explicitly work with them. Environments have no names and you cannot manipulate them directly.  But the programmer has to understand them enough to make sense of free variable bindings.&lt;/p&gt;

&lt;p&gt;When a function result is a function value that includes free variables, the result refers to an environment that defines the values bound to those free variables. The environment (at least the part representing bindings of the free variables) must be retained at least as long as the function value exists. The (function value, environment) pair is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Closure_(computer_programming)&quot;&gt;closure&lt;/a&gt;. A simple stack regime is insufficient to represent closures because the environment bindings in the closure have to persist even after the function that created those bindings has completed and returned to its caller.&lt;/p&gt;

&lt;p&gt;Unlike languages with a strong functional basis, C++ reifies its environments as member variables of an object. Rather than defining a function and using a closure to complete that definition via an environment binding the free variables, C++ uses &lt;em&gt;callable objects&lt;/em&gt;. Where a Python lambda binds its free variables to the lexically nearest variables, carrying the resulting environment in a closure, a C++ lambda is an object with member variables providing the values of all free variables in the lambda expression. This fits more naturally within an object-oriented language:  Rather than invisible environments whose presence is only indicated by the meaning they provide a function value, we have object instances like any other.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;A C++ lambda expression defines a new, unnamed class and instantiates a single object of that class.&lt;/em&gt;  The class has a single member function, the function body of the lambda. The prefix to the lambda defines the member variables of the class. This is the source of the extra complexity in C++ lambda syntax compared to Python/JavaScript/Scheme: In addition to defining a function, the C++ lambda has to define the member variables providing values for any free variables in the function body and specify how they are to be initialized.&lt;/p&gt;

&lt;h2&gt;Defining a lambda object in C++&lt;/h2&gt;

&lt;p&gt;Here’s how the Python functions defined above could be defined in C++:&lt;/p&gt;

&lt;!-- highlight=&quot;2&quot; --&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;foo&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;foo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;

  &lt;span class=&quot;n&quot;&gt;copy&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_ostream_joiner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&quot;, &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;));&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;cout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;sc&quot;&gt;'\n'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;(The &lt;a href=&quot;http://en.cppreference.com/w/cpp/experimental/ostream_joiner&quot;&gt;&lt;code&gt;ostream_joiner&lt;/code&gt;&lt;/a&gt; in Line 11 is a C++ 2017 feature that is a close analogue of Python’s &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#str.join&quot;&gt;&lt;code&gt;str.join()&lt;/code&gt;&lt;/a&gt; function.)&lt;/p&gt;

&lt;p&gt;Let’s highlight the lambda in Line 2:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Where the Python lambda uses the rules of Python environments to bind the free &lt;code&gt;c&lt;/code&gt; to the parameter &lt;code&gt;c&lt;/code&gt;, the C++ lambda prefix &lt;code&gt;[c]&lt;/code&gt; specifies that the callable object will have a member variable &lt;code&gt;c&lt;/code&gt; with the following properties:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;c&lt;/code&gt; in the lambda will be copy-constructed (the default) from the lexically closest &lt;code&gt;c&lt;/code&gt;, namely the function parameter, taking whatever value the parameter has at the time the lambda is built.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;c&lt;/code&gt; will be &lt;code&gt;const&lt;/code&gt; (the default).&lt;/li&gt;
&lt;li&gt;The free variable &lt;code&gt;c&lt;/code&gt; in the function &lt;em&gt;body&lt;/em&gt; refers to the &lt;em&gt;member&lt;/em&gt; &lt;code&gt;c&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Given that the sole purpose of the lambda object’s member variables is to provide bindings for free variables in the function body, the lambda syntax only supports a subset of member variable definitions most useful for this purpose. You can specify that the member variables are either copy-initialized or by-reference. By default, all copy-initialized values are &lt;code&gt;const&lt;/code&gt;, but if any need to be updated, declaring the lambda &lt;code&gt;mutable&lt;/code&gt; makes them &lt;em&gt;all&lt;/em&gt; mutable. Member variables that are references are always mutable as long as the values they reference are.&lt;/p&gt;

&lt;p&gt;A lambda object whose member variables are all copy-constructed is self-contained and can have arbitrary lifetime; it can persist long after the original sources of its member variables have been deallocated.  Lambda objects with member reference variables can only have lifetime within the lifetimes of all of the variables that it refers to. Consult the reference for &lt;a href=&quot;http://en.cppreference.com/w/cpp/language/lambda&quot;&gt;lambda expressions&lt;/a&gt; for the details.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;The greater complexity of C++ lambda syntax is due to its more complicated semantics.  More than defining a function, you are defining a class and the initialization of its member variables. The concrete syntax for lambdas aims to provide a concise way to specify the kinds of classes most likely to be used to construct anonymous, callable objects. Understanding that it’s simply an alternate style of class definition gives it all more sense.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Iterators: A failure case</title>
   <link href="/2017/02/22/iterators-a-failure-case/"/>
   <updated>2017-02-22T00:00:00-08:00</updated>
   <id>/2017/02/22/iterators-a-failure-case</id>
   <content type="html">&lt;p&gt;In my first post on iterators, I presented a case where they work well.  In this post, I’ll present a clear failure and begin discussing why the deep structure of the design leads to this failure.&lt;/p&gt;

&lt;p&gt;Consider the simple Python list comprehension:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Given a list of numbers &lt;code&gt;a&lt;/code&gt;, this constructs a numeric list &lt;code&gt;res&lt;/code&gt; containing the squares of all positive values in &lt;code&gt;a&lt;/code&gt;. Comparable facilities exist in &lt;a href=&quot;https://wiki.haskell.org/List_comprehension&quot;&gt;Haskell&lt;/a&gt; and other languages.&lt;/p&gt;

&lt;p&gt;At first glance, the C++ STL has all the facilities to do this in a slightly different way:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/iterator&quot;&gt;iterators&lt;/a&gt; allow us to walk through a collection (the Python list is most closely matched by the STL &lt;code&gt;vector&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm/copy&quot;&gt;std::copy_if()&lt;/a&gt; allows us to copy only elements that satisfy a given criterion&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.cppreference.com/w/cpp/language/lambda&quot;&gt;lambda expressions&lt;/a&gt; allow us to define on-the-fly callable objects to square a value and to implement the &quot;greater-than-zero&quot; criterion&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;And in fact these are sufficient to replicate the functionality of the Python expression.  But Oh the syntax!&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;copy_if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cbegin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;back_inserter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
               &lt;span class=&quot;p&quot;&gt;[](&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;});&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;There’s really no way to claim that this is close to the clarity and concision of its equivalent Python or Haskell expressions. And we’ll see in future posts that along the way, we have to make subtle decisions about storage allocation (the &lt;a href=&quot;http://en.cppreference.com/w/cpp/iterator/back_inserter&quot;&gt;&lt;code&gt;back_inserter()&lt;/code&gt;&lt;/a&gt; adaptors are only one of three contending approaches with different tradeoffs).&lt;/p&gt;

&lt;p&gt;Furthermore, I wouldn’t expect anyone familiar with list comprehensions to be able to see that the C++ code implemented the same algorithm.  There’s so much stuff idiosyncratic to the STL:  &lt;code&gt;cbegin()/cend()&lt;/code&gt;, &lt;code&gt;back_inserter()&lt;/code&gt;, and the arcane syntax of C++ lambdas (you &lt;em&gt;did&lt;/em&gt; recognize that &lt;code&gt;[](auto i) { .... }&lt;/code&gt; is a lambda-expression, right?). Whereas a non-C++ programmer could likely recognize the gist of the ranged-&lt;code&gt;for&lt;/code&gt; used in the last post, there is no way they could understand this algorithm without specific knowledge of C++ and the STL.&lt;/p&gt;

&lt;p&gt;Most distracting of all is how the STL foregrounds the intermediate results. In the Python expression, the only names are the source, the sink, and the local scalar representing an element being processed, whereas the STL code forces us to define the intermediate vector &lt;code&gt;t1&lt;/code&gt; and constantly reference all three vectors (&lt;code&gt;a&lt;/code&gt;, &lt;code&gt;t1&lt;/code&gt;, &lt;code&gt;res&lt;/code&gt;) in the expression.&lt;/p&gt;

&lt;p&gt;The Python code focuses on the essential algorithm: The source and sink are each mentioned once, while the rest of the expression shows how a given element is transformed along the way.  This focus is lost completely in the C++ version, with its constant restatement of the underlying vectors containing the values.&lt;/p&gt;

&lt;p&gt;So from a notational standpoint, this approach isn’t up to contemporary standards. The code gcc 6.2 produces, on the other hand, is clean and tight. As with the example in the last post, the optimizer can recognize that the iterators are walking through contiguous blocks of memory and generate simple indirect references. It’s all inline, as well. The only function called in the sequence is a utility to construct values in the result vector, potentially expanding its allocation as necessary. Of particular note is that both lambda expressions have been completely inlined, generating two and one instruction each, respectively. Once again template specialization has allowed abstract source code to produce terse object code.&lt;/p&gt;

&lt;p&gt;I can personally attest that this approach is learnable:  I was able to write this example without consulting a single reference and compile it the first time. But rather than a testimony to the design, this may just indicate that I’ve &lt;a href=&quot;https://en.wikipedia.org/wiki/Stockholm_syndrome&quot;&gt;fallen in love with my kidnappers&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;In the next posts, I want to consider to what degree the notational flaws in this approach are readily correctable. In the last example, the syntactic sugar of ranged-&lt;code&gt;for&lt;/code&gt; simplified the notation, bringing it closer to contemporary practice in other languages and making the code more robust. How much can this code be simplified by a few notational improvements and how much is inherent to the whole STL design? I’ll start by comparing C++ lambdas to their counterparts in other languages.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Iterators: One success story</title>
   <link href="/2017/02/21/iterators-one-success-story/"/>
   <updated>2017-02-21T00:00:00-08:00</updated>
   <id>/2017/02/21/iterators-one-success-story</id>
   <content type="html">
&lt;p&gt;Iterators intrigue me because they seem to bring to C++ facilities that I’ve found congenial in other languages. I’ve spent some time in Haskell and a lot of time in Python, which both support &lt;a href=&quot;https://docs.python.org/3/tutorial/datastructures.html#list-comprehensions&quot;&gt;list comprehensions&lt;/a&gt;. I’ve also enjoyed the limited amount of C# &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/bb397933.aspx&quot;&gt;Language-Integrated Query (LINQ)&lt;/a&gt; programming that I’ve done.&lt;/p&gt;

&lt;p&gt;Yet when I come to actually use the STL iterators, it feels awkward and requires much more text than achieving comparable results using list comprehensions or LINQ. Some of that may be simple unfamiliarity but that is itself a problem: A good design will allow me to apply patterns I’ve learned in other languages.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;But it’s more than unfamiliarity.  I’ve practiced implementing functions in the C++ STL and found that simple Python expressions such as&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;have to be turned inside-out and sprawl across multiple lines when written in the STL. (I’ll give details in a later post.) The STL appears essentially much more verbose.&lt;/p&gt;

&lt;p&gt;I think it’s also significant that, despite the STL’s design being 20 years old, no other mainstream language has adopted it. Deep down, Python’s list comprehensions are in fact constructed from similar mechanisms, &lt;a href=&quot;https://docs.python.org/3/library/stdtypes.html#iterator-types&quot;&gt;iterator types&lt;/a&gt; and &lt;a href=&quot;https://docs.python.org/3/glossary.html#term-generator-expression&quot;&gt;generator expressions&lt;/a&gt;, but the underlying memory management is completely different.&lt;/p&gt;

&lt;p&gt;So I want to spend some posts exploring the strengths and weaknesses of STL iterators. And I want to begin with one of its great successes, a success that became available with the &lt;a href=&quot;http://en.cppreference.com/w/cpp/language/range-for&quot;&gt;range-based &lt;code&gt;for&lt;/code&gt;&lt;/a&gt; feature of C++ 2011.&lt;/p&gt;

&lt;h2&gt;A case where iterators work well&lt;/h2&gt;

&lt;p&gt;Consider the following C program:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#define LEN 3
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The loop simply walks a pointer &lt;code&gt;p&lt;/code&gt; over the length of array &lt;code&gt;a&lt;/code&gt;, summing the values in &lt;code&gt;sum&lt;/code&gt;. (Note: The above code is so simple that the optimizer does something much simpler. The Appendix to this post shows the actual code necessary to fake out the optimizer and get the compiler to generate the code I’m describing. I’m displaying the simpler code here because it presents the essential loop.)  The resulting loop code (from gcc 6.2) is as simple as it gets:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  xorl	%eax, %eax
L3:
  addl	(%edx), %eax
  addl	$4, %edx
  cmpl	%esi, %edx
  jne	.L3
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Register &lt;code&gt;edx&lt;/code&gt; is pointer &lt;code&gt;p&lt;/code&gt;, incrementing through the array.  Register &lt;code&gt;eax&lt;/code&gt; is &lt;code&gt;sum&lt;/code&gt;, while register &lt;code&gt;esi&lt;/code&gt; contains the address &lt;code&gt;a+LEN&lt;/code&gt;. This is the most efficient scalar code possible for the loop (though it could likely be improved by using the x86 &lt;a href=&quot;https://en.wikipedia.org/wiki/Advanced_Vector_Extensions&quot;&gt;vector instructions&lt;/a&gt; or your processor’s equivalent).&lt;/p&gt;

&lt;p&gt;Here is the same algorithm using the C++ STL library and a range-based &lt;code&gt;for&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;array&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;This version generates equivalent loop code (though with different register assignments) as the C program, despite its more abstract presentation.  In fact, C++ will generate equivalent code to C’s pointer-based program for a loop over a &lt;code&gt;std::vector&lt;/code&gt; as well:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;vector&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;vector&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;};&lt;/span&gt;

  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;Where the &lt;code&gt;std::array&lt;/code&gt; collection is just mild syntactic sugar over a foundational C/C++ array, a &lt;code&gt;std::vector&lt;/code&gt; is a more powerful collection, expanding in size as new elements are appended. Yet a loop over a vector generates just as efficient code as the far more explicit, pointer-oriented code in C.&lt;/p&gt;

&lt;p&gt;Iterators link the STL collections and ranged for (and all the algorithms in the &lt;a href=&quot;http://en.cppreference.com/w/cpp/algorithm&quot;&gt;algorithms library&lt;/a&gt;).  A collection provides a suite of iterators according to a standardized interface and the ranged for simply calls those iterators. Template specialization allows the library to specify efficient, pointer-based iteration over collections for which that makes sense.&lt;/p&gt;

&lt;p&gt;This is a real benefit of STL iterators: We specify an abstract interface to every STL collection and for those collections represented by a contiguous block of elements, such as &lt;code&gt;std::array&lt;/code&gt; or &lt;code&gt;std::vector&lt;/code&gt;, we get code every bit as efficient as the best that we can get from any language. For collections based on non-contiguous representations, such as &lt;code&gt;std::map&lt;/code&gt; or &lt;code&gt;std::unordered_map&lt;/code&gt;, the same ranged-for can be used but will generate the more complex traversal code required for a binary tree or hash table, respectively.&lt;/p&gt;

&lt;p&gt;Once we have iterators, a tweak to the concrete syntax of the core language provided a concise form for iterating over a collection, the ranged &lt;code&gt;for&lt;/code&gt;. This loop is more robust than the C &lt;code&gt;for&lt;/code&gt; loop, as the start and end points of the loop are generated by the collection.  By contrast, the C loop (and the pre-2011 &lt;code&gt;for&lt;/code&gt; loop in C++) requires us to correctly specify the end point of the array, with no provision for the compiler to cross-check.&lt;/p&gt;

&lt;p&gt;This is an unequivocal win for the iterator design. In future posts, I’ll consider functional requirements where it becomes far less successful.&lt;/p&gt;

&lt;h2&gt;Appendix&lt;/h2&gt;

&lt;p&gt;The C program given above in fact generates the following object code:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  .cfi_startproc
  movl	$15, %eax
  ret
  .cfi_endproc
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The smarty-pants optimizer has recognized that the loop is completely specified and has precomputed its result (the value 15) at compile-time.  To generate an actual runtime loop, we have to make the array larger and read it from input:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;stdio.h&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;cp&quot;&gt;#define LEN 10
&lt;/span&gt;
&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt;

  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scanf&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;%d&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]);&lt;/span&gt;

  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LEN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;The resulting loop generates the code given in the body of this post.&lt;/p&gt;

&lt;p&gt;A similar problem arises with the C++ code. Here is the version that prevents the optimizer from eliminating the loop:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;cp&quot;&gt;#include &amp;lt;array&amp;gt;
#include &amp;lt;iostream&amp;gt;
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;using&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;main&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{};&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;amp;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;auto&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
</content>
 </entry>
 

</feed>
