<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <meta name="description" content="Blog for A. E. Kirkpatrick and  Kirkpatrick Computing Services">
  <meta name="author" content="Arthur E. Kirkpatrick">
  <meta name="copyright" content="Arthur E. Kirkpatrick, 2018, 2019, 2020">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Exploring distributed algorithm failures using TLA Toolbox &middot; All my marbles in one place
    
  </title>

  <!-- Google Analytics -->
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-66576928-4', 'auto');
  ga('send', 'pageview');
  </script>

  <!-- CSS -->
  <link rel="stylesheet" href="/public/css/poole.css">
  <link rel="stylesheet" href="/public/css/syntax.css">
  <link rel="stylesheet" href="/public/css/hyde.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">

  <!-- Begin Jekyll SEO tag v2.2.3 -->
<meta property="og:title" content="Exploring distributed algorithm failures using TLA Toolbox" />
<meta name="author" content="Ted Kirkpatrick" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="First in a series on using the TLA Toolbox to explore the failure tolerance of distributed algorithms. The next post has not been written." />
<meta property="og:description" content="First in a series on using the TLA Toolbox to explore the failure tolerance of distributed algorithms. The next post has not been written." />
<meta property="og:site_name" content="All my marbles in one place" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-10-31T00:00:00-07:00" />
<script type="application/ld+json">
{"@context":"http://schema.org","@type":"BlogPosting","headline":"Exploring distributed algorithm failures using TLA Toolbox","author":{"@type":"Person","name":"Ted Kirkpatrick"},"datePublished":"2018-10-31T00:00:00-07:00","dateModified":"2018-10-31T00:00:00-07:00","description":"First in a series on using the TLA Toolbox to explore the failure tolerance of distributed algorithms. The next post has not been written.","mainEntityOfPage":{"@type":"WebPage","@id":"/2018/10/31/exploring-distributed-algorithm-failures-using-tla-toolbox/"},"url":"/2018/10/31/exploring-distributed-algorithm-failures-using-tla-toolbox/"}</script>
<!-- End Jekyll SEO tag -->

</head>


  <body class="theme-base-0c layout-reverse">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/">
          All my marbles in one place
        </a>
      </h1>
      <p class="lead">A blog about course design, data display, C++, and Python.  Yes, these are related, at least as I see them.</p>
    </div>

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/">Home</a>

      

      
      
        
          
        
      
        
          
            <a class="sidebar-nav-item" href="/about/">About</a>
          
        
      
        
      
        
          
            <a class="sidebar-nav-item" href="/comment-policy/">Comment policy</a>
          
        
      
        
          
            <a class="sidebar-nav-item" href="/credits/">Credits</a>
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

    
        <div class="sidebar-tags">
        Tags:<br/>
        
	   
	    <a href="/tag/C++/">C++</a>,
	  
        
	   
	    <a href="/tag/Python/">Python</a>,
	  
        
	   
	    <a href="/tag/Course design/">Course design</a>,
	  
        
	   
	    <a href="/tag/Big data/">Big data</a>,
	  
        
	   
	    <a href="/tag/Soft skills/">Soft skills</a>,
	  
        
	   
	    <a href="/tag/Statistics/">Statistics</a>,
	  
        
	   
	    <a href="/tag/Experimental design/">Experimental design</a>,
	  
        
	   
	    <a href="/tag/Rhetoric/">Rhetoric</a>,
	  
        
	   
	    <a href="/tag/Admin/">Admin</a>,
	  
        
	  	    
            <a href="/tag/Distributed systems/">Distributed systems</a>
          
        
	</div>
      

    </nav>

    <p>&copy; 2020. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="post">
  <h1 class="post-title">Exploring distributed algorithm failures using TLA Toolbox</h1>
  <span class="post-date">31 Oct 2018
  
    <span class="tag-block">Tags: 
    
      
      <a href="/tag/Distributed systems">Distributed systems</a>
      
    
    </span>
  
  </span>
  
  <p><em>First in a series on using the TLA Toolbox to explore the failure
 tolerance of distributed algorithms. The next post has not been written.</em></p>

<p>I have wanted to write a series about Leslie Lamport’s
<a href="https://lamport.azurewebsites.net/tla/toolbox.html">TLA Toolbox</a> for
some time. For years, I’ve been following the growing use of formal
and semi-formal methods in software development, including such tools
as <a href="https://lamport.azurewebsites.net/tla/toolbox.html">Alloy</a>,
<a href="https://coq.inria.fr/">Coq</a>,
<a href="http://spinroot.com/spin/whatispin.html">Spin</a>, and
<a href="https://isabelle.in.tum.de/">Isabelle</a>. And that’s just a taste of
what’s on offer—consider the tools Byron Cook lists at the end of
his talk on
<a href="http://www0.cs.ucl.ac.uk/staff/b.cook/CAV18_invited.pdf">formal verification of security at Amazon Web Services</a>.</p>

<p>Of the tools I have explored, the TLA language and the TLC model
checker represent a fascinating design point:</p>

<ul>
  <li>simple enough to pick up
quickly,</li>
  <li>focused enough that they do their job well without diluting
that focus by attempting too much, and</li>
  <li>powerful enough to apply to
questions of interest in a production environment.</li>
</ul>

<p>Lamport has
<a href="https://amturing.acm.org/award_winners/lamport_1205376.cfm">devoted his career</a>
to developing provably correct distributed algorithms and the Toolbox
distills this experience into executable form. The rest of us, those
who haven’t won a Turing award, can use the wisdom embedded in these
tools to approach that level of performance.</p>

<h2 id="focusing-on-failure-tolerance-of-distribute-algorithms">Focusing on failure tolerance of distribute algorithms</h2>

<p>Despite my interest in the Toolbox, I have held off writing anything
about it because so much has already been written.  In fact, the
newcomer is held back by the sheer number of tutorials and references
available at the Toolbox site alone, let alone the others around the
Web.  There seemed no point in duplicating what was already so
well-described elsewhere.</p>

<p>In recent months however, I have found a novel angle for approaching
the Toolbox, using it to study the failure tolerance of distributed
algorithms. This is a slippery topic, yet of growing
importance. Modern service-oriented designs,
<a href="/2018/10/13/data-engineering-design-space/">running on cloud data centres</a>,
are expected to be
<a href="https://www.oreilly.com/ideas/chaos-engineering">resilient in the face of failure</a>. The
most basic form of this resilience is that the service must run on
multiple instances and continue when a subset of those instances
fails. A necessary condition of a resilient service is that its
algorithm is designed to be replicated and resilient in the event of
failure of one or more instances.</p>

<p>Notably, Lamport has contributed one of the oldest and most famous
resilient algorithms, Paxos. Opinions vary on how easy Paxos is
to understand: Lamport
<a href="https://www.microsoft.com/en-us/research/publication/paxos-made-simple/">considers it simple</a>,
others see it as at least <a href="http://paxos.systems/">moderately complex</a>,
while still others emphasize the substantial extra work required to
<a href="http://www.scs.stanford.edu/~dm/home/papers/paxos.pdf">make it practical</a>
and
<a href="https://ai.google/research/pubs/pub33002">make it production-ready</a>. And
all these articles focus on understanding the cases where at least a
majority of the instances run without failure.  What of the cases where
one instance crashes (which the algorithm should handle) or where so many
instances crash that it cannot proceed?</p>

<h2 id="the-benefits-of-model-checking">The benefits of model checking</h2>

<p>Model checking can help tackle the challenge of understanding whether
a distributed algorithm proceeds or fails in the presence of failed
instances. A model checker lets you explore the behaviours of an
algorithm. You can, for example:</p>

<ul>
  <li>Ensure that all behaviours up to a certain length conform to a
requirement or trace out a counterexample behaviour that violates
the requirement;</li>
  <li>Remove a necessary subtlety of the algorithm and demonstrate that
the simplified algorithm no longer meets a requirement; or</li>
  <li>Demonstrate that an algorithm fails a requirement
outside its original intent (for example, that an algorithm designed
under an assumption of a perfect network fails when the network
drops messages).</li>
</ul>

<p>A model checker run is a superpowered version of a regular test run.
Where a test run simply demonstrates a single behaviour, a model
checker run tests all behaviours up to some maximum length. Although
such runs are less complete than proofs (a proof is valid for all
behaviours, regardless of length), runs of a model checker are far
more complete than a single run of the program. With a model checker,
the designer can see the implications of a change on a wide range
of behaviours in a short time. The method does not provide 100% confidence in
your conclusions but it provides far more confidence than mere runs of the
program could ever provide.</p>

<h2 id="and-the-horror-the-horror">… and the horror, the horror!</h2>

<p>However useful a model checker can be, I worry that I violate the
express wishes of the TLA team when I apply their Toolbox to
investigate failure tolerance, which typically requires
writing liveness properties in moderately complex formulas of temporal logic. In
<a href="https://lamport.azurewebsites.net/tla/book.html"><em>The TLA Book</em></a>,
Lamport advocates focusing instead on <em>safety</em> properties, which can typically
be written in propositional logic, avoiding liveness properties and the more
complicated temporal logic they require:</p>

<blockquote>
  <p>Experience shows that most of the benefit from writing and using a
specification comes from the safety part … [W]hen looking for
errors, most of your effort should be devoted to examining the
safety part … The unbridled use of temporal logic produces
formulas that are hard to understand. (p. 116)</p>
</blockquote>

<p>I am unsure whether Lamport would consider my use of temporal logic in
the following posts “well-bridled” but I do believe that such formulas
are more important now that liveness properties have become more
prominent. It is not enough that a system in production ensure that at
most one process is in a critical section at a given time (a safety
property).  The system must also ensure that processes attempting to
enter that critical section are admitted without undue delay (a
liveness property). As
<a href="https://ai.google/research/pubs/pub40801">Dean and Barroso</a> argue,</p>

<blockquote>
  <p>Just as fault-tolerant computing aims to create a reliable whole out
of less reliable parts, we suggest that large online services need
to create a predictably responsive whole out of less predictable
parts. [Abstract]</p>
</blockquote>

<p>These guarantees are ultimately probabilistic and as such, they cannot
be tested by model checking, which is fundamentally logical.  Yet
model checking can test the logical properties standing as
<em>prerequisites</em> to acceptable latency distributions.  An algorithm that
halts when an instance crashes or becomes partitioned can never
provide acceptable latencies in the long tail.  The tests described in
this series are insufficient to guarantee success but their <em>failure</em>
guarantees the design will be inadequate in the face of some types of
failure.</p>

<h2 id="what-we-stand-to-learn-and-not-learn">What we stand to learn and not learn</h2>

<p>Taking all this together, using TLA to explore a distributed algorithm’s
responses to failure offers several lessons:</p>

<ul>
  <li>A tool for understanding a slippery property of increasing
importance in actual systems</li>
  <li>Practice at intermediate-level use of the Toolbox, beyond the simple
cases used in most tutorials</li>
  <li>A deeper understanding of model checking more generally.</li>
</ul>

<p>It is also important to bear in mind what the method will not do:</p>

<ul>
  <li>It will not consider more complex failure scenarios, such as
“Byzantine” cases, where a buggy or compromised instance actively
subverts the system.</li>
  <li>It will not consider the distribution of response latencies.</li>
  <li>It will not consider probabilistic failures such as a fractional
loss rate of messages on the network.</li>
  <li>The size of the spaces searchable using practical resources
will be smaller for the more complex temporal formulas required for
liveness than for the simpler predicate logic formulas commonly used
for checking safety.</li>
  <li>For the sorts of long-running algorithms we will consider, model
checking can not provide the complete guarantees of a mathematical
proof.</li>
</ul>

<p>Despite these limitations, the approach remains useful and fun. I’ll
start by considering a simpler algorithm than Paxos,
<a href="https://www.microsoft.com/en-us/research/publication/time-clocks-ordering-events-distributed-system/">Lamport’s 1978 distributed mutual exclusion algorithm</a>. This
algorithm was designed under an assumption of perfect instances
running on a perfect network, so it’s a good case for analyzing its
response to instance failure.  Even this simple algorithm will provide
fodder for a whole series of posts.</p>


</div>




<div id="disqus_thread"></div>
<script>

var disqus_config = function () {
this.page.url = "http://kirkpatricktech.com/2018/10/31/exploring-distributed-algorithm-failures-using-tla-toolbox/";
//this.page.identifier = "/2018/10/31/exploring-distributed-algorithm-failures-using-tla-toolbox";
};

(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://kirkpatricktech-com.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

    </div>

  </body>
</html>
